{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8919792d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-20T06:06:18.309331Z",
     "iopub.status.busy": "2025-08-20T06:06:18.309041Z",
     "iopub.status.idle": "2025-08-20T06:06:23.806119Z",
     "shell.execute_reply": "2025-08-20T06:06:23.805386Z"
    },
    "papermill": {
     "duration": 5.511034,
     "end_time": "2025-08-20T06:06:23.807611",
     "exception": false,
     "start_time": "2025-08-20T06:06:18.296577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        os.path.join(dirname, filename)\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bfe9145",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T06:06:23.828871Z",
     "iopub.status.busy": "2025-08-20T06:06:23.828293Z",
     "iopub.status.idle": "2025-08-20T06:06:24.097148Z",
     "shell.execute_reply": "2025-08-20T06:06:24.096500Z"
    },
    "papermill": {
     "duration": 0.280962,
     "end_time": "2025-08-20T06:06:24.099132",
     "exception": false,
     "start_time": "2025-08-20T06:06:23.818170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEMOTION Labels Dataset:\n",
      "   Unnamed: 0    image_name  \\\n",
      "0           0   image_1.jpg   \n",
      "1           1  image_2.jpeg   \n",
      "2           2   image_3.JPG   \n",
      "3           3   image_4.png   \n",
      "4           4   image_5.png   \n",
      "\n",
      "                                            text_ocr  \\\n",
      "0  LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...   \n",
      "1  The best of #10 YearChallenge! Completed in le...   \n",
      "2  Sam Thorne @Strippin ( Follow Follow Saw every...   \n",
      "3              10 Year Challenge - Sweet Dee Edition   \n",
      "4  10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...   \n",
      "\n",
      "                                      text_corrected      humour  \\\n",
      "0  LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...   hilarious   \n",
      "1  The best of #10 YearChallenge! Completed in le...   not_funny   \n",
      "2  Sam Thorne @Strippin ( Follow Follow Saw every...  very_funny   \n",
      "3              10 Year Challenge - Sweet Dee Edition  very_funny   \n",
      "4  10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...   hilarious   \n",
      "\n",
      "           sarcasm       offensive      motivational overall_sentiment  \n",
      "0          general   not_offensive  not_motivational     very_positive  \n",
      "1          general   not_offensive      motivational     very_positive  \n",
      "2    not_sarcastic   not_offensive  not_motivational          positive  \n",
      "3  twisted_meaning  very_offensive      motivational          positive  \n",
      "4     very_twisted  very_offensive  not_motivational           neutral  \n",
      "\n",
      "MEMOTION Reference Dataset:\n",
      "   Unnamed: 0                                      original_name  \\\n",
      "0           0                                 10_year_2r94rv.jpg   \n",
      "1           1          10_year_10-year-challenge_1547788782.jpeg   \n",
      "2           2  10_year_10yearchallenge-5c75f8b946e0fb0001edc7...   \n",
      "3           3  10_year_10-year-challenge-sweet-dee-edition-40...   \n",
      "4           4  10_year_10-year-challenge-with-no-filter-47-hi...   \n",
      "\n",
      "                                           image_url    image_name  \n",
      "0                   https://i.imgflip.com/2r94rv.jpg   image_1.jpg  \n",
      "1  https://spiderimg.amarujala.com/assets/images/...  image_2.jpeg  \n",
      "2  https://www.lifewire.com/thmb/8wNfd94_meE9X2cp...   image_3.JPG  \n",
      "3  https://pics.conservativememes.com/10-year-cha...   image_4.png  \n",
      "4  https://pics.me.me/10-year-challenge-with-no-f...   image_5.png  \n",
      "\n",
      "MUStARD Dataset:\n",
      "                                      1_60_utterance 1_60_speaker  \\\n",
      "0  It's just a privilege to watch your mind at work.      SHELDON   \n",
      "\n",
      "                                        1_60_context 1_60_context_speakers  \\\n",
      "0  [I never would have identified the fingerprint...    [LEONARD, SHELDON]   \n",
      "\n",
      "  1_60_show  1_60_sarcasm                                     1_70_utterance  \\\n",
      "0       BBT          True  I don't think I'll be able to stop thinking ab...   \n",
      "\n",
      "  1_70_speaker                                       1_70_context  \\\n",
      "0        PENNY  [This is one of my favorite places to kick bac...   \n",
      "\n",
      "                               1_70_context_speakers  ...  \\\n",
      "0  [HOWARD, PENNY, HOWARD, HOWARD, HOWARD, PENNY,...  ...   \n",
      "\n",
      "                                       2_608_context  \\\n",
      "0  [Did I go to this school?, Hey, there's Missy ...   \n",
      "\n",
      "             2_608_context_speakers 2_608_show 2_608_sarcasm  \\\n",
      "0  [CHANDLER, ROSS, CHANDLER, ROSS]    FRIENDS          True   \n",
      "\n",
      "                           2_524_utterance 2_524_speaker  \\\n",
      "0  Yes and we are \"very\" excited about it.      CHANDLER   \n",
      "\n",
      "                                       2_524_context  2_524_context_speakers  \\\n",
      "0  [Anyway, if you don't feel like being alone to...                  [ROSS]   \n",
      "\n",
      "  2_524_show 2_524_sarcasm  \n",
      "0    FRIENDS          True  \n",
      "\n",
      "[1 rows x 4140 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Define paths\n",
    "memotion_labels_path = \"/kaggle/input/memotion-dataset-7k/memotion_dataset_7k/labels.csv\"\n",
    "memotion_reference_path = \"/kaggle/input/memotion-dataset-7k/memotion_dataset_7k/reference.csv\"\n",
    "mustard_json_path = \"/kaggle/input/mustard-multimodal-sarcasm-detection-dataset/sarcasm_data.json\"\n",
    "\n",
    "# Load MEMOTION datasets\n",
    "memotion_labels_df = pd.read_csv(memotion_labels_path)\n",
    "memotion_reference_df = pd.read_csv(memotion_reference_path)\n",
    "\n",
    "# Load MUStARD dataset\n",
    "with open(mustard_json_path, 'r') as f:\n",
    "    mustard_data = json.load(f)\n",
    "mustard_df = pd.json_normalize(mustard_data, sep='_')\n",
    "\n",
    "# Display basic info\n",
    "print(\"MEMOTION Labels Dataset:\")\n",
    "print(memotion_labels_df.head())\n",
    "\n",
    "print(\"\\nMEMOTION Reference Dataset:\")\n",
    "print(memotion_reference_df.head())\n",
    "\n",
    "print(\"\\nMUStARD Dataset:\")\n",
    "print(mustard_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8efd3ad",
   "metadata": {
    "papermill": {
     "duration": 0.009931,
     "end_time": "2025-08-20T06:06:24.119647",
     "exception": false,
     "start_time": "2025-08-20T06:06:24.109716",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " Hierarchical Cross-Modal Incongruity and Emotion-Aware Sarcasm Detection (HCI-EASD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b81d2da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T06:06:24.141000Z",
     "iopub.status.busy": "2025-08-20T06:06:24.140700Z",
     "iopub.status.idle": "2025-08-20T06:46:49.713757Z",
     "shell.execute_reply": "2025-08-20T06:46:49.712748Z"
    },
    "papermill": {
     "duration": 2425.58564,
     "end_time": "2025-08-20T06:46:49.715060",
     "exception": false,
     "start_time": "2025-08-20T06:06:24.129420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-20 06:06:39.981409: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1755670000.164493      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1755670000.217222      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Starting comprehensive HCI-EASD training and evaluation...\n",
      "Starting HCI-EASD Model Training...\n",
      "============================================================\n",
      "Loading datasets...\n",
      "Loaded 6992 samples from Memotion dataset\n",
      "Loaded 690 samples from MUStARD dataset\n",
      "Total dataset size: 7682\n",
      "Sarcastic samples: 345\n",
      "Non-sarcastic samples: 7337\n",
      "Train set: 5377 samples\n",
      "Validation set: 1152 samples\n",
      "Test set: 1153 samples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70c18dfe774941a39561d44e2468e3ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52a87709fd0746bd8ee5a776afe300b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d4d62fb28e647e3a923c25fa16eba38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2137a91452fe40dcbedefdc485070068",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing HCI-EASD model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c823b3cf81d24562a25240b9d40a6a3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 112MB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c301c45bce642da9cde6e5676d95450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49045a8092f04b41bc5dbae8898efe11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/329M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4776442649c9473891b4081128f6d6aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/294 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a77b8b2f11024a949de0186c3b7c9c85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/329M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4707a7aae2984ffc82279e31c0496dc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c3ea397ce894b2aa221fb8bb3ec4620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd174d0a3aeb47489532d0b8ca6df7b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aadecd385e6a41a1a16685be73db873f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 136,978,307\n",
      "Trainable parameters: 136,978,307\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10:   0%|          | 0/337 [00:00<?, ?it/s]\u001b[AYou seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "\n",
      "Epoch 1/10:   0%|          | 0/337 [00:03<?, ?it/s, Loss=0.5587, Avg Loss=0.5587]\u001b[A\n",
      "Epoch 1/10:   0%|          | 1/337 [00:03<19:48,  3.54s/it, Loss=0.5587, Avg Loss=0.5587]\u001b[A\n",
      "Epoch 1/10:   0%|          | 1/337 [00:04<19:48,  3.54s/it, Loss=0.2993, Avg Loss=0.4290]\u001b[A\n",
      "Epoch 1/10:   1%|          | 2/337 [00:04<09:57,  1.78s/it, Loss=0.2993, Avg Loss=0.4290]\u001b[A\n",
      "Epoch 1/10:   1%|          | 2/337 [00:04<09:57,  1.78s/it, Loss=0.2595, Avg Loss=0.3725]\u001b[A\n",
      "Epoch 1/10:   1%|          | 3/337 [00:04<06:48,  1.22s/it, Loss=0.2595, Avg Loss=0.3725]\u001b[A\n",
      "Epoch 1/10:   1%|          | 3/337 [00:05<06:48,  1.22s/it, Loss=0.1035, Avg Loss=0.3052]\u001b[A\n",
      "Epoch 1/10:   1%|          | 4/337 [00:05<05:21,  1.03it/s, Loss=0.1035, Avg Loss=0.3052]\u001b[A\n",
      "Epoch 1/10:   1%|          | 4/337 [00:05<05:21,  1.03it/s, Loss=0.2546, Avg Loss=0.2951]\u001b[A\n",
      "Epoch 1/10:   1%|▏         | 5/337 [00:05<04:34,  1.21it/s, Loss=0.2546, Avg Loss=0.2951]\u001b[A\n",
      "Epoch 1/10:   1%|▏         | 5/337 [00:06<04:34,  1.21it/s, Loss=0.1056, Avg Loss=0.2635]\u001b[A\n",
      "Epoch 1/10:   2%|▏         | 6/337 [00:06<04:02,  1.36it/s, Loss=0.1056, Avg Loss=0.2635]\u001b[A\n",
      "Epoch 1/10:   2%|▏         | 6/337 [00:06<04:02,  1.36it/s, Loss=0.1088, Avg Loss=0.2414]\u001b[A\n",
      "Epoch 1/10:   2%|▏         | 7/337 [00:06<03:45,  1.47it/s, Loss=0.1088, Avg Loss=0.2414]\u001b[A\n",
      "Epoch 1/10:   2%|▏         | 7/337 [00:07<03:45,  1.47it/s, Loss=0.0951, Avg Loss=0.2231]\u001b[A\n",
      "Epoch 1/10:   2%|▏         | 8/337 [00:07<03:30,  1.56it/s, Loss=0.0951, Avg Loss=0.2231]\u001b[A\n",
      "Epoch 1/10:   2%|▏         | 8/337 [00:08<03:30,  1.56it/s, Loss=0.0351, Avg Loss=0.2023]\u001b[A\n",
      "Epoch 1/10:   3%|▎         | 9/337 [00:08<03:21,  1.63it/s, Loss=0.0351, Avg Loss=0.2023]\u001b[A\n",
      "Epoch 1/10:   3%|▎         | 9/337 [00:08<03:21,  1.63it/s, Loss=0.0245, Avg Loss=0.1845]\u001b[A\n",
      "Epoch 1/10:   3%|▎         | 10/337 [00:08<03:15,  1.67it/s, Loss=0.0245, Avg Loss=0.1845]\u001b[A\n",
      "Epoch 1/10:   3%|▎         | 10/337 [00:09<03:15,  1.67it/s, Loss=0.0174, Avg Loss=0.1693]\u001b[A\n",
      "Epoch 1/10:   3%|▎         | 11/337 [00:09<03:11,  1.70it/s, Loss=0.0174, Avg Loss=0.1693]\u001b[A\n",
      "Epoch 1/10:   3%|▎         | 11/337 [00:09<03:11,  1.70it/s, Loss=0.0157, Avg Loss=0.1565]\u001b[A\n",
      "Epoch 1/10:   4%|▎         | 12/337 [00:09<03:08,  1.73it/s, Loss=0.0157, Avg Loss=0.1565]\u001b[A\n",
      "Epoch 1/10:   4%|▎         | 12/337 [00:10<03:08,  1.73it/s, Loss=0.0075, Avg Loss=0.1450]\u001b[A\n",
      "Epoch 1/10:   4%|▍         | 13/337 [00:10<03:08,  1.72it/s, Loss=0.0075, Avg Loss=0.1450]\u001b[A\n",
      "Epoch 1/10:   4%|▍         | 13/337 [00:10<03:08,  1.72it/s, Loss=0.0959, Avg Loss=0.1415]\u001b[A\n",
      "Epoch 1/10:   4%|▍         | 14/337 [00:10<03:05,  1.74it/s, Loss=0.0959, Avg Loss=0.1415]\u001b[A\n",
      "Epoch 1/10:   4%|▍         | 14/337 [00:11<03:05,  1.74it/s, Loss=0.0049, Avg Loss=0.1324]\u001b[A\n",
      "Epoch 1/10:   4%|▍         | 15/337 [00:11<03:09,  1.70it/s, Loss=0.0049, Avg Loss=0.1324]\u001b[A\n",
      "Epoch 1/10:   4%|▍         | 15/337 [00:12<03:09,  1.70it/s, Loss=0.0032, Avg Loss=0.1243]\u001b[A\n",
      "Epoch 1/10:   5%|▍         | 16/337 [00:12<03:09,  1.69it/s, Loss=0.0032, Avg Loss=0.1243]\u001b[A\n",
      "Epoch 1/10:   5%|▍         | 16/337 [00:12<03:09,  1.69it/s, Loss=0.0030, Avg Loss=0.1172]\u001b[A\n",
      "Epoch 1/10:   5%|▌         | 17/337 [00:12<03:06,  1.72it/s, Loss=0.0030, Avg Loss=0.1172]\u001b[A\n",
      "Epoch 1/10:   5%|▌         | 17/337 [00:13<03:06,  1.72it/s, Loss=0.0966, Avg Loss=0.1161]\u001b[A\n",
      "Epoch 1/10:   5%|▌         | 18/337 [00:13<03:03,  1.74it/s, Loss=0.0966, Avg Loss=0.1161]\u001b[A\n",
      "Epoch 1/10:   5%|▌         | 18/337 [00:13<03:03,  1.74it/s, Loss=0.0022, Avg Loss=0.1101]\u001b[A\n",
      "Epoch 1/10:   6%|▌         | 19/337 [00:13<03:01,  1.76it/s, Loss=0.0022, Avg Loss=0.1101]\u001b[A\n",
      "Epoch 1/10:   6%|▌         | 19/337 [00:14<03:01,  1.76it/s, Loss=0.0022, Avg Loss=0.1047]\u001b[A\n",
      "Epoch 1/10:   6%|▌         | 20/337 [00:14<02:59,  1.76it/s, Loss=0.0022, Avg Loss=0.1047]\u001b[A\n",
      "Epoch 1/10:   6%|▌         | 20/337 [00:14<02:59,  1.76it/s, Loss=0.0013, Avg Loss=0.0998]\u001b[A\n",
      "Epoch 1/10:   6%|▌         | 21/337 [00:14<03:00,  1.75it/s, Loss=0.0013, Avg Loss=0.0998]\u001b[A\n",
      "Epoch 1/10:   6%|▌         | 21/337 [00:15<03:00,  1.75it/s, Loss=0.3123, Avg Loss=0.1094]\u001b[A\n",
      "Epoch 1/10:   7%|▋         | 22/337 [00:15<03:00,  1.75it/s, Loss=0.3123, Avg Loss=0.1094]\u001b[A\n",
      "Epoch 1/10:   7%|▋         | 22/337 [00:16<03:00,  1.75it/s, Loss=0.4232, Avg Loss=0.1231]\u001b[A\n",
      "Epoch 1/10:   7%|▋         | 23/337 [00:16<03:00,  1.74it/s, Loss=0.4232, Avg Loss=0.1231]\u001b[A\n",
      "Epoch 1/10:   7%|▋         | 23/337 [00:16<03:00,  1.74it/s, Loss=0.0772, Avg Loss=0.1211]\u001b[A\n",
      "Epoch 1/10:   7%|▋         | 24/337 [00:16<02:59,  1.75it/s, Loss=0.0772, Avg Loss=0.1211]\u001b[A\n",
      "Epoch 1/10:   7%|▋         | 24/337 [00:17<02:59,  1.75it/s, Loss=0.0008, Avg Loss=0.1163]\u001b[A\n",
      "Epoch 1/10:   7%|▋         | 25/337 [00:17<02:58,  1.75it/s, Loss=0.0008, Avg Loss=0.1163]\u001b[A\n",
      "Epoch 1/10:   7%|▋         | 25/337 [00:17<02:58,  1.75it/s, Loss=0.0699, Avg Loss=0.1145]\u001b[A\n",
      "Epoch 1/10:   8%|▊         | 26/337 [00:17<02:58,  1.74it/s, Loss=0.0699, Avg Loss=0.1145]\u001b[A\n",
      "Epoch 1/10:   8%|▊         | 26/337 [00:18<02:58,  1.74it/s, Loss=0.0021, Avg Loss=0.1104]\u001b[A\n",
      "Epoch 1/10:   8%|▊         | 27/337 [00:18<02:57,  1.75it/s, Loss=0.0021, Avg Loss=0.1104]\u001b[A\n",
      "Epoch 1/10:   8%|▊         | 27/337 [00:18<02:57,  1.75it/s, Loss=0.0063, Avg Loss=0.1067]\u001b[A\n",
      "Epoch 1/10:   8%|▊         | 28/337 [00:18<02:55,  1.76it/s, Loss=0.0063, Avg Loss=0.1067]\u001b[A\n",
      "Epoch 1/10:   8%|▊         | 28/337 [00:19<02:55,  1.76it/s, Loss=0.0008, Avg Loss=0.1030]\u001b[A\n",
      "Epoch 1/10:   9%|▊         | 29/337 [00:19<02:55,  1.76it/s, Loss=0.0008, Avg Loss=0.1030]\u001b[A\n",
      "Epoch 1/10:   9%|▊         | 29/337 [00:20<02:55,  1.76it/s, Loss=0.0318, Avg Loss=0.1006]\u001b[A\n",
      "Epoch 1/10:   9%|▉         | 30/337 [00:20<02:52,  1.78it/s, Loss=0.0318, Avg Loss=0.1006]\u001b[A\n",
      "Epoch 1/10:   9%|▉         | 30/337 [00:20<02:52,  1.78it/s, Loss=0.0535, Avg Loss=0.0991]\u001b[A\n",
      "Epoch 1/10:   9%|▉         | 31/337 [00:20<02:52,  1.77it/s, Loss=0.0535, Avg Loss=0.0991]\u001b[A\n",
      "Epoch 1/10:   9%|▉         | 31/337 [00:21<02:52,  1.77it/s, Loss=0.0229, Avg Loss=0.0967]\u001b[A\n",
      "Epoch 1/10:   9%|▉         | 32/337 [00:21<02:53,  1.76it/s, Loss=0.0229, Avg Loss=0.0967]\u001b[A\n",
      "Epoch 1/10:   9%|▉         | 32/337 [00:21<02:53,  1.76it/s, Loss=0.0189, Avg Loss=0.0944]\u001b[A\n",
      "Epoch 1/10:  10%|▉         | 33/337 [00:21<02:52,  1.76it/s, Loss=0.0189, Avg Loss=0.0944]\u001b[A\n",
      "Epoch 1/10:  10%|▉         | 33/337 [00:22<02:52,  1.76it/s, Loss=0.0041, Avg Loss=0.0917]\u001b[A\n",
      "Epoch 1/10:  10%|█         | 34/337 [00:22<02:52,  1.76it/s, Loss=0.0041, Avg Loss=0.0917]\u001b[A\n",
      "Epoch 1/10:  10%|█         | 34/337 [00:22<02:52,  1.76it/s, Loss=0.0388, Avg Loss=0.0902]\u001b[A\n",
      "Epoch 1/10:  10%|█         | 35/337 [00:22<02:51,  1.76it/s, Loss=0.0388, Avg Loss=0.0902]\u001b[A\n",
      "Epoch 1/10:  10%|█         | 35/337 [00:23<02:51,  1.76it/s, Loss=0.0020, Avg Loss=0.0878]\u001b[A\n",
      "Epoch 1/10:  11%|█         | 36/337 [00:23<02:51,  1.76it/s, Loss=0.0020, Avg Loss=0.0878]\u001b[A\n",
      "Epoch 1/10:  11%|█         | 36/337 [00:24<02:51,  1.76it/s, Loss=0.0336, Avg Loss=0.0863]\u001b[A\n",
      "Epoch 1/10:  11%|█         | 37/337 [00:24<02:51,  1.75it/s, Loss=0.0336, Avg Loss=0.0863]\u001b[A\n",
      "Epoch 1/10:  11%|█         | 37/337 [00:24<02:51,  1.75it/s, Loss=0.0098, Avg Loss=0.0843]\u001b[A\n",
      "Epoch 1/10:  11%|█▏        | 38/337 [00:24<02:51,  1.75it/s, Loss=0.0098, Avg Loss=0.0843]\u001b[A\n",
      "Epoch 1/10:  11%|█▏        | 38/337 [00:25<02:51,  1.75it/s, Loss=0.1250, Avg Loss=0.0853]\u001b[A\n",
      "Epoch 1/10:  12%|█▏        | 39/337 [00:25<02:50,  1.75it/s, Loss=0.1250, Avg Loss=0.0853]\u001b[A\n",
      "Epoch 1/10:  12%|█▏        | 39/337 [00:25<02:50,  1.75it/s, Loss=0.0908, Avg Loss=0.0855]\u001b[A\n",
      "Epoch 1/10:  12%|█▏        | 40/337 [00:25<02:49,  1.75it/s, Loss=0.0908, Avg Loss=0.0855]\u001b[A\n",
      "Epoch 1/10:  12%|█▏        | 40/337 [00:26<02:49,  1.75it/s, Loss=0.0372, Avg Loss=0.0843]\u001b[A\n",
      "Epoch 1/10:  12%|█▏        | 41/337 [00:26<02:49,  1.75it/s, Loss=0.0372, Avg Loss=0.0843]\u001b[A\n",
      "Epoch 1/10:  12%|█▏        | 41/337 [00:26<02:49,  1.75it/s, Loss=0.0354, Avg Loss=0.0831]\u001b[A\n",
      "Epoch 1/10:  12%|█▏        | 42/337 [00:26<02:48,  1.75it/s, Loss=0.0354, Avg Loss=0.0831]\u001b[A\n",
      "Epoch 1/10:  12%|█▏        | 42/337 [00:27<02:48,  1.75it/s, Loss=0.0237, Avg Loss=0.0817]\u001b[A\n",
      "Epoch 1/10:  13%|█▎        | 43/337 [00:27<02:48,  1.75it/s, Loss=0.0237, Avg Loss=0.0817]\u001b[A\n",
      "Epoch 1/10:  13%|█▎        | 43/337 [00:28<02:48,  1.75it/s, Loss=0.0551, Avg Loss=0.0811]\u001b[A\n",
      "Epoch 1/10:  13%|█▎        | 44/337 [00:28<02:47,  1.75it/s, Loss=0.0551, Avg Loss=0.0811]\u001b[A\n",
      "Epoch 1/10:  13%|█▎        | 44/337 [00:28<02:47,  1.75it/s, Loss=0.0115, Avg Loss=0.0796]\u001b[A\n",
      "Epoch 1/10:  13%|█▎        | 45/337 [00:28<02:47,  1.75it/s, Loss=0.0115, Avg Loss=0.0796]\u001b[A\n",
      "Epoch 1/10:  13%|█▎        | 45/337 [00:29<02:47,  1.75it/s, Loss=0.0277, Avg Loss=0.0785]\u001b[A\n",
      "Epoch 1/10:  14%|█▎        | 46/337 [00:29<02:47,  1.74it/s, Loss=0.0277, Avg Loss=0.0785]\u001b[A\n",
      "Epoch 1/10:  14%|█▎        | 46/337 [00:29<02:47,  1.74it/s, Loss=0.0476, Avg Loss=0.0778]\u001b[A\n",
      "Epoch 1/10:  14%|█▍        | 47/337 [00:29<02:48,  1.73it/s, Loss=0.0476, Avg Loss=0.0778]\u001b[A\n",
      "Epoch 1/10:  14%|█▍        | 47/337 [00:30<02:48,  1.73it/s, Loss=0.0018, Avg Loss=0.0762]\u001b[A\n",
      "Epoch 1/10:  14%|█▍        | 48/337 [00:30<02:46,  1.73it/s, Loss=0.0018, Avg Loss=0.0762]\u001b[A\n",
      "Epoch 1/10:  14%|█▍        | 48/337 [00:30<02:46,  1.73it/s, Loss=0.0008, Avg Loss=0.0747]\u001b[A\n",
      "Epoch 1/10:  15%|█▍        | 49/337 [00:30<02:46,  1.73it/s, Loss=0.0008, Avg Loss=0.0747]\u001b[A\n",
      "Epoch 1/10:  15%|█▍        | 49/337 [00:31<02:46,  1.73it/s, Loss=0.0132, Avg Loss=0.0734]\u001b[A\n",
      "Epoch 1/10:  15%|█▍        | 50/337 [00:31<02:45,  1.73it/s, Loss=0.0132, Avg Loss=0.0734]\u001b[A\n",
      "Epoch 1/10:  15%|█▍        | 50/337 [00:32<02:45,  1.73it/s, Loss=0.0548, Avg Loss=0.0731]\u001b[A\n",
      "Epoch 1/10:  15%|█▌        | 51/337 [00:32<02:45,  1.73it/s, Loss=0.0548, Avg Loss=0.0731]\u001b[A\n",
      "Epoch 1/10:  15%|█▌        | 51/337 [00:32<02:45,  1.73it/s, Loss=0.0310, Avg Loss=0.0723]\u001b[A\n",
      "Epoch 1/10:  15%|█▌        | 52/337 [00:32<02:44,  1.73it/s, Loss=0.0310, Avg Loss=0.0723]\u001b[A\n",
      "Epoch 1/10:  15%|█▌        | 52/337 [00:33<02:44,  1.73it/s, Loss=0.0009, Avg Loss=0.0709]\u001b[A\n",
      "Epoch 1/10:  16%|█▌        | 53/337 [00:33<02:43,  1.73it/s, Loss=0.0009, Avg Loss=0.0709]\u001b[A\n",
      "Epoch 1/10:  16%|█▌        | 53/337 [00:33<02:43,  1.73it/s, Loss=0.0195, Avg Loss=0.0700]\u001b[A\n",
      "Epoch 1/10:  16%|█▌        | 54/337 [00:33<02:43,  1.73it/s, Loss=0.0195, Avg Loss=0.0700]\u001b[A\n",
      "Epoch 1/10:  16%|█▌        | 54/337 [00:34<02:43,  1.73it/s, Loss=0.0495, Avg Loss=0.0696]\u001b[A\n",
      "Epoch 1/10:  16%|█▋        | 55/337 [00:34<02:45,  1.71it/s, Loss=0.0495, Avg Loss=0.0696]\u001b[A\n",
      "Epoch 1/10:  16%|█▋        | 55/337 [00:34<02:45,  1.71it/s, Loss=0.0917, Avg Loss=0.0700]\u001b[A\n",
      "Epoch 1/10:  17%|█▋        | 56/337 [00:34<02:43,  1.71it/s, Loss=0.0917, Avg Loss=0.0700]\u001b[A\n",
      "Epoch 1/10:  17%|█▋        | 56/337 [00:35<02:43,  1.71it/s, Loss=0.0086, Avg Loss=0.0689]\u001b[A\n",
      "Epoch 1/10:  17%|█▋        | 57/337 [00:35<02:43,  1.71it/s, Loss=0.0086, Avg Loss=0.0689]\u001b[A\n",
      "Epoch 1/10:  17%|█▋        | 57/337 [00:36<02:43,  1.71it/s, Loss=0.0667, Avg Loss=0.0689]\u001b[A\n",
      "Epoch 1/10:  17%|█▋        | 58/337 [00:36<02:42,  1.72it/s, Loss=0.0667, Avg Loss=0.0689]\u001b[A\n",
      "Epoch 1/10:  17%|█▋        | 58/337 [00:36<02:42,  1.72it/s, Loss=0.0677, Avg Loss=0.0689]\u001b[A\n",
      "Epoch 1/10:  18%|█▊        | 59/337 [00:36<02:41,  1.72it/s, Loss=0.0677, Avg Loss=0.0689]\u001b[A\n",
      "Epoch 1/10:  18%|█▊        | 59/337 [00:37<02:41,  1.72it/s, Loss=0.0061, Avg Loss=0.0678]\u001b[A\n",
      "Epoch 1/10:  18%|█▊        | 60/337 [00:37<02:40,  1.73it/s, Loss=0.0061, Avg Loss=0.0678]\u001b[A\n",
      "Epoch 1/10:  18%|█▊        | 60/337 [00:37<02:40,  1.73it/s, Loss=0.1090, Avg Loss=0.0685]\u001b[A\n",
      "Epoch 1/10:  18%|█▊        | 61/337 [00:37<02:40,  1.72it/s, Loss=0.1090, Avg Loss=0.0685]\u001b[A\n",
      "Epoch 1/10:  18%|█▊        | 61/337 [00:38<02:40,  1.72it/s, Loss=0.0529, Avg Loss=0.0682]\u001b[A\n",
      "Epoch 1/10:  18%|█▊        | 62/337 [00:38<02:39,  1.72it/s, Loss=0.0529, Avg Loss=0.0682]\u001b[A\n",
      "Epoch 1/10:  18%|█▊        | 62/337 [00:39<02:39,  1.72it/s, Loss=0.0082, Avg Loss=0.0673]\u001b[A\n",
      "Epoch 1/10:  19%|█▊        | 63/337 [00:39<02:39,  1.72it/s, Loss=0.0082, Avg Loss=0.0673]\u001b[A\n",
      "Epoch 1/10:  19%|█▊        | 63/337 [00:39<02:39,  1.72it/s, Loss=0.0013, Avg Loss=0.0663]\u001b[A\n",
      "Epoch 1/10:  19%|█▉        | 64/337 [00:39<02:38,  1.72it/s, Loss=0.0013, Avg Loss=0.0663]\u001b[A\n",
      "Epoch 1/10:  19%|█▉        | 64/337 [00:40<02:38,  1.72it/s, Loss=0.0135, Avg Loss=0.0654]\u001b[A\n",
      "Epoch 1/10:  19%|█▉        | 65/337 [00:40<02:37,  1.72it/s, Loss=0.0135, Avg Loss=0.0654]\u001b[A\n",
      "Epoch 1/10:  19%|█▉        | 65/337 [00:40<02:37,  1.72it/s, Loss=0.1341, Avg Loss=0.0665]\u001b[A\n",
      "Epoch 1/10:  20%|█▉        | 66/337 [00:40<02:37,  1.72it/s, Loss=0.1341, Avg Loss=0.0665]\u001b[A\n",
      "Epoch 1/10:  20%|█▉        | 66/337 [00:41<02:37,  1.72it/s, Loss=0.0009, Avg Loss=0.0655]\u001b[A\n",
      "Epoch 1/10:  20%|█▉        | 67/337 [00:41<02:36,  1.72it/s, Loss=0.0009, Avg Loss=0.0655]\u001b[A\n",
      "Epoch 1/10:  20%|█▉        | 67/337 [00:41<02:36,  1.72it/s, Loss=0.0112, Avg Loss=0.0647]\u001b[A\n",
      "Epoch 1/10:  20%|██        | 68/337 [00:41<02:36,  1.72it/s, Loss=0.0112, Avg Loss=0.0647]\u001b[A\n",
      "Epoch 1/10:  20%|██        | 68/337 [00:42<02:36,  1.72it/s, Loss=0.0120, Avg Loss=0.0639]\u001b[A\n",
      "Epoch 1/10:  20%|██        | 69/337 [00:42<02:36,  1.71it/s, Loss=0.0120, Avg Loss=0.0639]\u001b[A\n",
      "Epoch 1/10:  20%|██        | 69/337 [00:43<02:36,  1.71it/s, Loss=0.0427, Avg Loss=0.0636]\u001b[A\n",
      "Epoch 1/10:  21%|██        | 70/337 [00:43<02:36,  1.71it/s, Loss=0.0427, Avg Loss=0.0636]\u001b[A\n",
      "Epoch 1/10:  21%|██        | 70/337 [00:43<02:36,  1.71it/s, Loss=0.0325, Avg Loss=0.0632]\u001b[A\n",
      "Epoch 1/10:  21%|██        | 71/337 [00:43<02:35,  1.72it/s, Loss=0.0325, Avg Loss=0.0632]\u001b[A\n",
      "Epoch 1/10:  21%|██        | 71/337 [00:44<02:35,  1.72it/s, Loss=0.0223, Avg Loss=0.0626]\u001b[A\n",
      "Epoch 1/10:  21%|██▏       | 72/337 [00:44<02:34,  1.72it/s, Loss=0.0223, Avg Loss=0.0626]\u001b[A\n",
      "Epoch 1/10:  21%|██▏       | 72/337 [00:44<02:34,  1.72it/s, Loss=0.0743, Avg Loss=0.0628]\u001b[A\n",
      "Epoch 1/10:  22%|██▏       | 73/337 [00:44<02:33,  1.72it/s, Loss=0.0743, Avg Loss=0.0628]\u001b[A\n",
      "Epoch 1/10:  22%|██▏       | 73/337 [00:45<02:33,  1.72it/s, Loss=0.0331, Avg Loss=0.0624]\u001b[A\n",
      "Epoch 1/10:  22%|██▏       | 74/337 [00:45<02:34,  1.70it/s, Loss=0.0331, Avg Loss=0.0624]\u001b[A\n",
      "Epoch 1/10:  22%|██▏       | 74/337 [00:46<02:34,  1.70it/s, Loss=0.0504, Avg Loss=0.0622]\u001b[A\n",
      "Epoch 1/10:  22%|██▏       | 75/337 [00:46<02:33,  1.71it/s, Loss=0.0504, Avg Loss=0.0622]\u001b[A\n",
      "Epoch 1/10:  22%|██▏       | 75/337 [00:46<02:33,  1.71it/s, Loss=0.0134, Avg Loss=0.0616]\u001b[A\n",
      "Epoch 1/10:  23%|██▎       | 76/337 [00:46<02:33,  1.70it/s, Loss=0.0134, Avg Loss=0.0616]\u001b[A\n",
      "Epoch 1/10:  23%|██▎       | 76/337 [00:47<02:33,  1.70it/s, Loss=0.0158, Avg Loss=0.0610]\u001b[A\n",
      "Epoch 1/10:  23%|██▎       | 77/337 [00:47<02:32,  1.71it/s, Loss=0.0158, Avg Loss=0.0610]\u001b[A\n",
      "Epoch 1/10:  23%|██▎       | 77/337 [00:47<02:32,  1.71it/s, Loss=0.0383, Avg Loss=0.0607]\u001b[A\n",
      "Epoch 1/10:  23%|██▎       | 78/337 [00:47<02:32,  1.70it/s, Loss=0.0383, Avg Loss=0.0607]\u001b[A\n",
      "Epoch 1/10:  23%|██▎       | 78/337 [00:48<02:32,  1.70it/s, Loss=0.0165, Avg Loss=0.0601]\u001b[A\n",
      "Epoch 1/10:  23%|██▎       | 79/337 [00:48<02:31,  1.70it/s, Loss=0.0165, Avg Loss=0.0601]\u001b[A\n",
      "Epoch 1/10:  23%|██▎       | 79/337 [00:48<02:31,  1.70it/s, Loss=0.0542, Avg Loss=0.0601]\u001b[A\n",
      "Epoch 1/10:  24%|██▎       | 80/337 [00:48<02:30,  1.70it/s, Loss=0.0542, Avg Loss=0.0601]\u001b[A\n",
      "Epoch 1/10:  24%|██▎       | 80/337 [00:49<02:30,  1.70it/s, Loss=0.0008, Avg Loss=0.0593]\u001b[A\n",
      "Epoch 1/10:  24%|██▍       | 81/337 [00:49<02:31,  1.69it/s, Loss=0.0008, Avg Loss=0.0593]\u001b[A\n",
      "Epoch 1/10:  24%|██▍       | 81/337 [00:50<02:31,  1.69it/s, Loss=0.0333, Avg Loss=0.0590]\u001b[A\n",
      "Epoch 1/10:  24%|██▍       | 82/337 [00:50<02:31,  1.69it/s, Loss=0.0333, Avg Loss=0.0590]\u001b[A\n",
      "Epoch 1/10:  24%|██▍       | 82/337 [00:50<02:31,  1.69it/s, Loss=0.0406, Avg Loss=0.0588]\u001b[A\n",
      "Epoch 1/10:  25%|██▍       | 83/337 [00:50<02:32,  1.67it/s, Loss=0.0406, Avg Loss=0.0588]\u001b[A\n",
      "Epoch 1/10:  25%|██▍       | 83/337 [00:51<02:32,  1.67it/s, Loss=0.0090, Avg Loss=0.0582]\u001b[A\n",
      "Epoch 1/10:  25%|██▍       | 84/337 [00:51<02:30,  1.68it/s, Loss=0.0090, Avg Loss=0.0582]\u001b[A\n",
      "Epoch 1/10:  25%|██▍       | 84/337 [00:52<02:30,  1.68it/s, Loss=0.0006, Avg Loss=0.0575]\u001b[A\n",
      "Epoch 1/10:  25%|██▌       | 85/337 [00:52<02:30,  1.67it/s, Loss=0.0006, Avg Loss=0.0575]\u001b[A\n",
      "Epoch 1/10:  25%|██▌       | 85/337 [00:52<02:30,  1.67it/s, Loss=0.0156, Avg Loss=0.0570]\u001b[A\n",
      "Epoch 1/10:  26%|██▌       | 86/337 [00:52<02:31,  1.66it/s, Loss=0.0156, Avg Loss=0.0570]\u001b[A\n",
      "Epoch 1/10:  26%|██▌       | 86/337 [00:53<02:31,  1.66it/s, Loss=0.0006, Avg Loss=0.0564]\u001b[A\n",
      "Epoch 1/10:  26%|██▌       | 87/337 [00:53<02:29,  1.67it/s, Loss=0.0006, Avg Loss=0.0564]\u001b[A\n",
      "Epoch 1/10:  26%|██▌       | 87/337 [00:53<02:29,  1.67it/s, Loss=0.0126, Avg Loss=0.0559]\u001b[A\n",
      "Epoch 1/10:  26%|██▌       | 88/337 [00:53<02:29,  1.67it/s, Loss=0.0126, Avg Loss=0.0559]\u001b[A\n",
      "Epoch 1/10:  26%|██▌       | 88/337 [00:54<02:29,  1.67it/s, Loss=0.0010, Avg Loss=0.0553]\u001b[A\n",
      "Epoch 1/10:  26%|██▋       | 89/337 [00:54<02:28,  1.67it/s, Loss=0.0010, Avg Loss=0.0553]\u001b[A\n",
      "Epoch 1/10:  26%|██▋       | 89/337 [00:54<02:28,  1.67it/s, Loss=0.0186, Avg Loss=0.0549]\u001b[A\n",
      "Epoch 1/10:  27%|██▋       | 90/337 [00:54<02:27,  1.68it/s, Loss=0.0186, Avg Loss=0.0549]\u001b[A\n",
      "Epoch 1/10:  27%|██▋       | 90/337 [00:55<02:27,  1.68it/s, Loss=0.0205, Avg Loss=0.0545]\u001b[A\n",
      "Epoch 1/10:  27%|██▋       | 91/337 [00:55<02:26,  1.68it/s, Loss=0.0205, Avg Loss=0.0545]\u001b[A\n",
      "Epoch 1/10:  27%|██▋       | 91/337 [00:56<02:26,  1.68it/s, Loss=0.0061, Avg Loss=0.0540]\u001b[A\n",
      "Epoch 1/10:  27%|██▋       | 92/337 [00:56<02:25,  1.68it/s, Loss=0.0061, Avg Loss=0.0540]\u001b[A\n",
      "Epoch 1/10:  27%|██▋       | 92/337 [00:56<02:25,  1.68it/s, Loss=0.0005, Avg Loss=0.0534]\u001b[A\n",
      "Epoch 1/10:  28%|██▊       | 93/337 [00:56<02:25,  1.68it/s, Loss=0.0005, Avg Loss=0.0534]\u001b[A\n",
      "Epoch 1/10:  28%|██▊       | 93/337 [00:57<02:25,  1.68it/s, Loss=0.0185, Avg Loss=0.0530]\u001b[A\n",
      "Epoch 1/10:  28%|██▊       | 94/337 [00:57<02:24,  1.68it/s, Loss=0.0185, Avg Loss=0.0530]\u001b[A\n",
      "Epoch 1/10:  28%|██▊       | 94/337 [00:57<02:24,  1.68it/s, Loss=0.0005, Avg Loss=0.0525]\u001b[A\n",
      "Epoch 1/10:  28%|██▊       | 95/337 [00:57<02:24,  1.68it/s, Loss=0.0005, Avg Loss=0.0525]\u001b[A\n",
      "Epoch 1/10:  28%|██▊       | 95/337 [00:58<02:24,  1.68it/s, Loss=0.1241, Avg Loss=0.0532]\u001b[A\n",
      "Epoch 1/10:  28%|██▊       | 96/337 [00:58<02:23,  1.67it/s, Loss=0.1241, Avg Loss=0.0532]\u001b[A\n",
      "Epoch 1/10:  28%|██▊       | 96/337 [00:59<02:23,  1.67it/s, Loss=0.0309, Avg Loss=0.0530]\u001b[A\n",
      "Epoch 1/10:  29%|██▉       | 97/337 [00:59<02:23,  1.67it/s, Loss=0.0309, Avg Loss=0.0530]\u001b[A\n",
      "Epoch 1/10:  29%|██▉       | 97/337 [00:59<02:23,  1.67it/s, Loss=0.0846, Avg Loss=0.0533]\u001b[A\n",
      "Epoch 1/10:  29%|██▉       | 98/337 [00:59<02:23,  1.67it/s, Loss=0.0846, Avg Loss=0.0533]\u001b[A\n",
      "Epoch 1/10:  29%|██▉       | 98/337 [01:00<02:23,  1.67it/s, Loss=0.0028, Avg Loss=0.0528]\u001b[A\n",
      "Epoch 1/10:  29%|██▉       | 99/337 [01:00<02:23,  1.66it/s, Loss=0.0028, Avg Loss=0.0528]\u001b[A\n",
      "Epoch 1/10:  29%|██▉       | 99/337 [01:00<02:23,  1.66it/s, Loss=0.0736, Avg Loss=0.0530]\u001b[A\n",
      "Epoch 1/10:  30%|██▉       | 100/337 [01:00<02:22,  1.66it/s, Loss=0.0736, Avg Loss=0.0530]\u001b[A\n",
      "Epoch 1/10:  30%|██▉       | 100/337 [01:01<02:22,  1.66it/s, Loss=0.1029, Avg Loss=0.0535]\u001b[A\n",
      "Epoch 1/10:  30%|██▉       | 101/337 [01:01<02:21,  1.67it/s, Loss=0.1029, Avg Loss=0.0535]\u001b[A\n",
      "Epoch 1/10:  30%|██▉       | 101/337 [01:02<02:21,  1.67it/s, Loss=0.0470, Avg Loss=0.0534]\u001b[A\n",
      "Epoch 1/10:  30%|███       | 102/337 [01:02<02:20,  1.67it/s, Loss=0.0470, Avg Loss=0.0534]\u001b[A\n",
      "Epoch 1/10:  30%|███       | 102/337 [01:02<02:20,  1.67it/s, Loss=0.0122, Avg Loss=0.0530]\u001b[A\n",
      "Epoch 1/10:  31%|███       | 103/337 [01:02<02:20,  1.67it/s, Loss=0.0122, Avg Loss=0.0530]\u001b[A\n",
      "Epoch 1/10:  31%|███       | 103/337 [01:03<02:20,  1.67it/s, Loss=0.0701, Avg Loss=0.0532]\u001b[A\n",
      "Epoch 1/10:  31%|███       | 104/337 [01:03<02:19,  1.66it/s, Loss=0.0701, Avg Loss=0.0532]\u001b[A\n",
      "Epoch 1/10:  31%|███       | 104/337 [01:03<02:19,  1.66it/s, Loss=0.0759, Avg Loss=0.0534]\u001b[A\n",
      "Epoch 1/10:  31%|███       | 105/337 [01:03<02:19,  1.66it/s, Loss=0.0759, Avg Loss=0.0534]\u001b[A\n",
      "Epoch 1/10:  31%|███       | 105/337 [01:04<02:19,  1.66it/s, Loss=0.0335, Avg Loss=0.0532]\u001b[A\n",
      "Epoch 1/10:  31%|███▏      | 106/337 [01:04<02:19,  1.65it/s, Loss=0.0335, Avg Loss=0.0532]\u001b[A\n",
      "Epoch 1/10:  31%|███▏      | 106/337 [01:05<02:19,  1.65it/s, Loss=0.0128, Avg Loss=0.0528]\u001b[A\n",
      "Epoch 1/10:  32%|███▏      | 107/337 [01:05<02:18,  1.66it/s, Loss=0.0128, Avg Loss=0.0528]\u001b[A\n",
      "Epoch 1/10:  32%|███▏      | 107/337 [01:05<02:18,  1.66it/s, Loss=0.0760, Avg Loss=0.0531]\u001b[A\n",
      "Epoch 1/10:  32%|███▏      | 108/337 [01:05<02:18,  1.66it/s, Loss=0.0760, Avg Loss=0.0531]\u001b[A\n",
      "Epoch 1/10:  32%|███▏      | 108/337 [01:06<02:18,  1.66it/s, Loss=0.0121, Avg Loss=0.0527]\u001b[A\n",
      "Epoch 1/10:  32%|███▏      | 109/337 [01:06<02:17,  1.65it/s, Loss=0.0121, Avg Loss=0.0527]\u001b[A\n",
      "Epoch 1/10:  32%|███▏      | 109/337 [01:07<02:17,  1.65it/s, Loss=0.0230, Avg Loss=0.0524]\u001b[A\n",
      "Epoch 1/10:  33%|███▎      | 110/337 [01:07<02:17,  1.65it/s, Loss=0.0230, Avg Loss=0.0524]\u001b[A\n",
      "Epoch 1/10:  33%|███▎      | 110/337 [01:07<02:17,  1.65it/s, Loss=0.0016, Avg Loss=0.0520]\u001b[A\n",
      "Epoch 1/10:  33%|███▎      | 111/337 [01:07<02:17,  1.64it/s, Loss=0.0016, Avg Loss=0.0520]\u001b[A\n",
      "Epoch 1/10:  33%|███▎      | 111/337 [01:08<02:17,  1.64it/s, Loss=0.0141, Avg Loss=0.0516]\u001b[A\n",
      "Epoch 1/10:  33%|███▎      | 112/337 [01:08<02:17,  1.63it/s, Loss=0.0141, Avg Loss=0.0516]\u001b[A\n",
      "Epoch 1/10:  33%|███▎      | 112/337 [01:08<02:17,  1.63it/s, Loss=0.0453, Avg Loss=0.0516]\u001b[A\n",
      "Epoch 1/10:  34%|███▎      | 113/337 [01:08<02:17,  1.63it/s, Loss=0.0453, Avg Loss=0.0516]\u001b[A\n",
      "Epoch 1/10:  34%|███▎      | 113/337 [01:09<02:17,  1.63it/s, Loss=0.0130, Avg Loss=0.0512]\u001b[A\n",
      "Epoch 1/10:  34%|███▍      | 114/337 [01:09<02:16,  1.64it/s, Loss=0.0130, Avg Loss=0.0512]\u001b[A\n",
      "Epoch 1/10:  34%|███▍      | 114/337 [01:10<02:16,  1.64it/s, Loss=0.0010, Avg Loss=0.0508]\u001b[A\n",
      "Epoch 1/10:  34%|███▍      | 115/337 [01:10<02:15,  1.64it/s, Loss=0.0010, Avg Loss=0.0508]\u001b[A\n",
      "Epoch 1/10:  34%|███▍      | 115/337 [01:10<02:15,  1.64it/s, Loss=0.0706, Avg Loss=0.0510]\u001b[A\n",
      "Epoch 1/10:  34%|███▍      | 116/337 [01:10<02:14,  1.64it/s, Loss=0.0706, Avg Loss=0.0510]\u001b[A\n",
      "Epoch 1/10:  34%|███▍      | 116/337 [01:11<02:14,  1.64it/s, Loss=0.0339, Avg Loss=0.0508]\u001b[A\n",
      "Epoch 1/10:  35%|███▍      | 117/337 [01:11<02:13,  1.64it/s, Loss=0.0339, Avg Loss=0.0508]\u001b[A\n",
      "Epoch 1/10:  35%|███▍      | 117/337 [01:11<02:13,  1.64it/s, Loss=0.0228, Avg Loss=0.0506]\u001b[A\n",
      "Epoch 1/10:  35%|███▌      | 118/337 [01:11<02:13,  1.64it/s, Loss=0.0228, Avg Loss=0.0506]\u001b[A\n",
      "Epoch 1/10:  35%|███▌      | 118/337 [01:12<02:13,  1.64it/s, Loss=0.0292, Avg Loss=0.0504]\u001b[A\n",
      "Epoch 1/10:  35%|███▌      | 119/337 [01:12<02:12,  1.64it/s, Loss=0.0292, Avg Loss=0.0504]\u001b[A\n",
      "Epoch 1/10:  35%|███▌      | 119/337 [01:13<02:12,  1.64it/s, Loss=0.0751, Avg Loss=0.0506]\u001b[A\n",
      "Epoch 1/10:  36%|███▌      | 120/337 [01:13<02:12,  1.64it/s, Loss=0.0751, Avg Loss=0.0506]\u001b[A\n",
      "Epoch 1/10:  36%|███▌      | 120/337 [01:13<02:12,  1.64it/s, Loss=0.0134, Avg Loss=0.0503]\u001b[A\n",
      "Epoch 1/10:  36%|███▌      | 121/337 [01:13<02:11,  1.64it/s, Loss=0.0134, Avg Loss=0.0503]\u001b[A\n",
      "Epoch 1/10:  36%|███▌      | 121/337 [01:14<02:11,  1.64it/s, Loss=0.0380, Avg Loss=0.0502]\u001b[A\n",
      "Epoch 1/10:  36%|███▌      | 122/337 [01:14<02:11,  1.63it/s, Loss=0.0380, Avg Loss=0.0502]\u001b[A\n",
      "Epoch 1/10:  36%|███▌      | 122/337 [01:14<02:11,  1.63it/s, Loss=0.0008, Avg Loss=0.0498]\u001b[A\n",
      "Epoch 1/10:  36%|███▋      | 123/337 [01:14<02:11,  1.63it/s, Loss=0.0008, Avg Loss=0.0498]\u001b[A\n",
      "Epoch 1/10:  36%|███▋      | 123/337 [01:15<02:11,  1.63it/s, Loss=0.0216, Avg Loss=0.0496]\u001b[A\n",
      "Epoch 1/10:  37%|███▋      | 124/337 [01:15<02:12,  1.61it/s, Loss=0.0216, Avg Loss=0.0496]\u001b[A\n",
      "Epoch 1/10:  37%|███▋      | 124/337 [01:16<02:12,  1.61it/s, Loss=0.0347, Avg Loss=0.0494]\u001b[A\n",
      "Epoch 1/10:  37%|███▋      | 125/337 [01:16<02:10,  1.62it/s, Loss=0.0347, Avg Loss=0.0494]\u001b[A\n",
      "Epoch 1/10:  37%|███▋      | 125/337 [01:16<02:10,  1.62it/s, Loss=0.0335, Avg Loss=0.0493]\u001b[A\n",
      "Epoch 1/10:  37%|███▋      | 126/337 [01:16<02:10,  1.62it/s, Loss=0.0335, Avg Loss=0.0493]\u001b[A\n",
      "Epoch 1/10:  37%|███▋      | 126/337 [01:17<02:10,  1.62it/s, Loss=0.0749, Avg Loss=0.0495]\u001b[A\n",
      "Epoch 1/10:  38%|███▊      | 127/337 [01:17<02:09,  1.62it/s, Loss=0.0749, Avg Loss=0.0495]\u001b[A\n",
      "Epoch 1/10:  38%|███▊      | 127/337 [01:18<02:09,  1.62it/s, Loss=0.0117, Avg Loss=0.0492]\u001b[A\n",
      "Epoch 1/10:  38%|███▊      | 128/337 [01:18<02:08,  1.62it/s, Loss=0.0117, Avg Loss=0.0492]\u001b[A\n",
      "Epoch 1/10:  38%|███▊      | 128/337 [01:18<02:08,  1.62it/s, Loss=0.0007, Avg Loss=0.0488]\u001b[A\n",
      "Epoch 1/10:  38%|███▊      | 129/337 [01:18<02:09,  1.60it/s, Loss=0.0007, Avg Loss=0.0488]\u001b[A\n",
      "Epoch 1/10:  38%|███▊      | 129/337 [01:19<02:09,  1.60it/s, Loss=0.0386, Avg Loss=0.0488]\u001b[A\n",
      "Epoch 1/10:  39%|███▊      | 130/337 [01:19<02:08,  1.61it/s, Loss=0.0386, Avg Loss=0.0488]\u001b[A\n",
      "Epoch 1/10:  39%|███▊      | 130/337 [01:19<02:08,  1.61it/s, Loss=0.0444, Avg Loss=0.0487]\u001b[A\n",
      "Epoch 1/10:  39%|███▉      | 131/337 [01:19<02:07,  1.61it/s, Loss=0.0444, Avg Loss=0.0487]\u001b[A\n",
      "Epoch 1/10:  39%|███▉      | 131/337 [01:20<02:07,  1.61it/s, Loss=0.0167, Avg Loss=0.0485]\u001b[A\n",
      "Epoch 1/10:  39%|███▉      | 132/337 [01:20<02:07,  1.61it/s, Loss=0.0167, Avg Loss=0.0485]\u001b[A\n",
      "Epoch 1/10:  39%|███▉      | 132/337 [01:21<02:07,  1.61it/s, Loss=0.0095, Avg Loss=0.0482]\u001b[A\n",
      "Epoch 1/10:  39%|███▉      | 133/337 [01:21<02:07,  1.61it/s, Loss=0.0095, Avg Loss=0.0482]\u001b[A\n",
      "Epoch 1/10:  39%|███▉      | 133/337 [01:21<02:07,  1.61it/s, Loss=0.0284, Avg Loss=0.0481]\u001b[A\n",
      "Epoch 1/10:  40%|███▉      | 134/337 [01:21<02:06,  1.61it/s, Loss=0.0284, Avg Loss=0.0481]\u001b[A\n",
      "Epoch 1/10:  40%|███▉      | 134/337 [01:22<02:06,  1.61it/s, Loss=0.0119, Avg Loss=0.0478]\u001b[A\n",
      "Epoch 1/10:  40%|████      | 135/337 [01:22<02:05,  1.61it/s, Loss=0.0119, Avg Loss=0.0478]\u001b[A\n",
      "Epoch 1/10:  40%|████      | 135/337 [01:23<02:05,  1.61it/s, Loss=0.0098, Avg Loss=0.0475]\u001b[A\n",
      "Epoch 1/10:  40%|████      | 136/337 [01:23<02:05,  1.61it/s, Loss=0.0098, Avg Loss=0.0475]\u001b[A\n",
      "Epoch 1/10:  40%|████      | 136/337 [01:23<02:05,  1.61it/s, Loss=0.0548, Avg Loss=0.0476]\u001b[A\n",
      "Epoch 1/10:  41%|████      | 137/337 [01:23<02:04,  1.60it/s, Loss=0.0548, Avg Loss=0.0476]\u001b[A\n",
      "Epoch 1/10:  41%|████      | 137/337 [01:24<02:04,  1.60it/s, Loss=0.0003, Avg Loss=0.0472]\u001b[A\n",
      "Epoch 1/10:  41%|████      | 138/337 [01:24<02:03,  1.61it/s, Loss=0.0003, Avg Loss=0.0472]\u001b[A\n",
      "Epoch 1/10:  41%|████      | 138/337 [01:24<02:03,  1.61it/s, Loss=0.0070, Avg Loss=0.0469]\u001b[A\n",
      "Epoch 1/10:  41%|████      | 139/337 [01:24<02:03,  1.60it/s, Loss=0.0070, Avg Loss=0.0469]\u001b[A\n",
      "Epoch 1/10:  41%|████      | 139/337 [01:25<02:03,  1.60it/s, Loss=0.0157, Avg Loss=0.0467]\u001b[A\n",
      "Epoch 1/10:  42%|████▏     | 140/337 [01:25<02:03,  1.60it/s, Loss=0.0157, Avg Loss=0.0467]\u001b[A\n",
      "Epoch 1/10:  42%|████▏     | 140/337 [01:26<02:03,  1.60it/s, Loss=0.0606, Avg Loss=0.0468]\u001b[A\n",
      "Epoch 1/10:  42%|████▏     | 141/337 [01:26<02:02,  1.61it/s, Loss=0.0606, Avg Loss=0.0468]\u001b[A\n",
      "Epoch 1/10:  42%|████▏     | 141/337 [01:26<02:02,  1.61it/s, Loss=0.0869, Avg Loss=0.0471]\u001b[A\n",
      "Epoch 1/10:  42%|████▏     | 142/337 [01:26<02:01,  1.60it/s, Loss=0.0869, Avg Loss=0.0471]\u001b[A\n",
      "Epoch 1/10:  42%|████▏     | 142/337 [01:27<02:01,  1.60it/s, Loss=0.0497, Avg Loss=0.0471]\u001b[A\n",
      "Epoch 1/10:  42%|████▏     | 143/337 [01:27<02:01,  1.60it/s, Loss=0.0497, Avg Loss=0.0471]\u001b[A\n",
      "Epoch 1/10:  42%|████▏     | 143/337 [01:28<02:01,  1.60it/s, Loss=0.0007, Avg Loss=0.0468]\u001b[A\n",
      "Epoch 1/10:  43%|████▎     | 144/337 [01:28<02:00,  1.60it/s, Loss=0.0007, Avg Loss=0.0468]\u001b[A\n",
      "Epoch 1/10:  43%|████▎     | 144/337 [01:28<02:00,  1.60it/s, Loss=0.0670, Avg Loss=0.0469]\u001b[A\n",
      "Epoch 1/10:  43%|████▎     | 145/337 [01:28<02:00,  1.60it/s, Loss=0.0670, Avg Loss=0.0469]\u001b[A\n",
      "Epoch 1/10:  43%|████▎     | 145/337 [01:29<02:00,  1.60it/s, Loss=0.0492, Avg Loss=0.0469]\u001b[A\n",
      "Epoch 1/10:  43%|████▎     | 146/337 [01:29<01:59,  1.60it/s, Loss=0.0492, Avg Loss=0.0469]\u001b[A\n",
      "Epoch 1/10:  43%|████▎     | 146/337 [01:29<01:59,  1.60it/s, Loss=0.0741, Avg Loss=0.0471]\u001b[A\n",
      "Epoch 1/10:  44%|████▎     | 147/337 [01:29<01:59,  1.60it/s, Loss=0.0741, Avg Loss=0.0471]\u001b[A\n",
      "Epoch 1/10:  44%|████▎     | 147/337 [01:30<01:59,  1.60it/s, Loss=0.0074, Avg Loss=0.0469]\u001b[A\n",
      "Epoch 1/10:  44%|████▍     | 148/337 [01:30<01:58,  1.60it/s, Loss=0.0074, Avg Loss=0.0469]\u001b[A\n",
      "Epoch 1/10:  44%|████▍     | 148/337 [01:31<01:58,  1.60it/s, Loss=0.0003, Avg Loss=0.0465]\u001b[A\n",
      "Epoch 1/10:  44%|████▍     | 149/337 [01:31<01:57,  1.60it/s, Loss=0.0003, Avg Loss=0.0465]\u001b[A\n",
      "Epoch 1/10:  44%|████▍     | 149/337 [01:31<01:57,  1.60it/s, Loss=0.0348, Avg Loss=0.0465]\u001b[A\n",
      "Epoch 1/10:  45%|████▍     | 150/337 [01:31<01:57,  1.60it/s, Loss=0.0348, Avg Loss=0.0465]\u001b[A\n",
      "Epoch 1/10:  45%|████▍     | 150/337 [01:32<01:57,  1.60it/s, Loss=0.0104, Avg Loss=0.0462]\u001b[A\n",
      "Epoch 1/10:  45%|████▍     | 151/337 [01:32<01:56,  1.59it/s, Loss=0.0104, Avg Loss=0.0462]\u001b[A\n",
      "Epoch 1/10:  45%|████▍     | 151/337 [01:33<01:56,  1.59it/s, Loss=0.0237, Avg Loss=0.0461]\u001b[A\n",
      "Epoch 1/10:  45%|████▌     | 152/337 [01:33<01:56,  1.59it/s, Loss=0.0237, Avg Loss=0.0461]\u001b[A\n",
      "Epoch 1/10:  45%|████▌     | 152/337 [01:33<01:56,  1.59it/s, Loss=0.0151, Avg Loss=0.0459]\u001b[A\n",
      "Epoch 1/10:  45%|████▌     | 153/337 [01:33<01:55,  1.59it/s, Loss=0.0151, Avg Loss=0.0459]\u001b[A\n",
      "Epoch 1/10:  45%|████▌     | 153/337 [01:34<01:55,  1.59it/s, Loss=0.0698, Avg Loss=0.0460]\u001b[A\n",
      "Epoch 1/10:  46%|████▌     | 154/337 [01:34<01:54,  1.59it/s, Loss=0.0698, Avg Loss=0.0460]\u001b[A\n",
      "Epoch 1/10:  46%|████▌     | 154/337 [01:34<01:54,  1.59it/s, Loss=0.0215, Avg Loss=0.0459]\u001b[A\n",
      "Epoch 1/10:  46%|████▌     | 155/337 [01:34<01:54,  1.59it/s, Loss=0.0215, Avg Loss=0.0459]\u001b[A\n",
      "Epoch 1/10:  46%|████▌     | 155/337 [01:35<01:54,  1.59it/s, Loss=0.0836, Avg Loss=0.0461]\u001b[A\n",
      "Epoch 1/10:  46%|████▋     | 156/337 [01:35<01:53,  1.59it/s, Loss=0.0836, Avg Loss=0.0461]\u001b[A\n",
      "Epoch 1/10:  46%|████▋     | 156/337 [01:36<01:53,  1.59it/s, Loss=0.0924, Avg Loss=0.0464]\u001b[A\n",
      "Epoch 1/10:  47%|████▋     | 157/337 [01:36<01:53,  1.58it/s, Loss=0.0924, Avg Loss=0.0464]\u001b[A\n",
      "Epoch 1/10:  47%|████▋     | 157/337 [01:36<01:53,  1.58it/s, Loss=0.0045, Avg Loss=0.0461]\u001b[A\n",
      "Epoch 1/10:  47%|████▋     | 158/337 [01:36<01:53,  1.58it/s, Loss=0.0045, Avg Loss=0.0461]\u001b[A\n",
      "Epoch 1/10:  47%|████▋     | 158/337 [01:37<01:53,  1.58it/s, Loss=0.0240, Avg Loss=0.0460]\u001b[A\n",
      "Epoch 1/10:  47%|████▋     | 159/337 [01:37<01:53,  1.57it/s, Loss=0.0240, Avg Loss=0.0460]\u001b[A\n",
      "Epoch 1/10:  47%|████▋     | 159/337 [01:38<01:53,  1.57it/s, Loss=0.0776, Avg Loss=0.0462]\u001b[A\n",
      "Epoch 1/10:  47%|████▋     | 160/337 [01:38<01:52,  1.57it/s, Loss=0.0776, Avg Loss=0.0462]\u001b[A\n",
      "Epoch 1/10:  47%|████▋     | 160/337 [01:38<01:52,  1.57it/s, Loss=0.0031, Avg Loss=0.0459]\u001b[A\n",
      "Epoch 1/10:  48%|████▊     | 161/337 [01:38<01:52,  1.57it/s, Loss=0.0031, Avg Loss=0.0459]\u001b[A\n",
      "Epoch 1/10:  48%|████▊     | 161/337 [01:39<01:52,  1.57it/s, Loss=0.0004, Avg Loss=0.0457]\u001b[A\n",
      "Epoch 1/10:  48%|████▊     | 162/337 [01:39<01:51,  1.57it/s, Loss=0.0004, Avg Loss=0.0457]\u001b[A\n",
      "Epoch 1/10:  48%|████▊     | 162/337 [01:40<01:51,  1.57it/s, Loss=0.0004, Avg Loss=0.0454]\u001b[A\n",
      "Epoch 1/10:  48%|████▊     | 163/337 [01:40<01:51,  1.56it/s, Loss=0.0004, Avg Loss=0.0454]\u001b[A\n",
      "Epoch 1/10:  48%|████▊     | 163/337 [01:40<01:51,  1.56it/s, Loss=0.0164, Avg Loss=0.0452]\u001b[A\n",
      "Epoch 1/10:  49%|████▊     | 164/337 [01:40<01:50,  1.56it/s, Loss=0.0164, Avg Loss=0.0452]\u001b[A\n",
      "Epoch 1/10:  49%|████▊     | 164/337 [01:41<01:50,  1.56it/s, Loss=0.0196, Avg Loss=0.0450]\u001b[A\n",
      "Epoch 1/10:  49%|████▉     | 165/337 [01:41<01:49,  1.57it/s, Loss=0.0196, Avg Loss=0.0450]\u001b[A\n",
      "Epoch 1/10:  49%|████▉     | 165/337 [01:41<01:49,  1.57it/s, Loss=0.0594, Avg Loss=0.0451]\u001b[A\n",
      "Epoch 1/10:  49%|████▉     | 166/337 [01:41<01:49,  1.56it/s, Loss=0.0594, Avg Loss=0.0451]\u001b[A\n",
      "Epoch 1/10:  49%|████▉     | 166/337 [01:42<01:49,  1.56it/s, Loss=0.0162, Avg Loss=0.0450]\u001b[A\n",
      "Epoch 1/10:  50%|████▉     | 167/337 [01:42<01:48,  1.56it/s, Loss=0.0162, Avg Loss=0.0450]\u001b[A\n",
      "Epoch 1/10:  50%|████▉     | 167/337 [01:43<01:48,  1.56it/s, Loss=0.0659, Avg Loss=0.0451]\u001b[A\n",
      "Epoch 1/10:  50%|████▉     | 168/337 [01:43<01:47,  1.58it/s, Loss=0.0659, Avg Loss=0.0451]\u001b[A\n",
      "Epoch 1/10:  50%|████▉     | 168/337 [01:43<01:47,  1.58it/s, Loss=0.0153, Avg Loss=0.0449]\u001b[A\n",
      "Epoch 1/10:  50%|█████     | 169/337 [01:43<01:47,  1.57it/s, Loss=0.0153, Avg Loss=0.0449]\u001b[A\n",
      "Epoch 1/10:  50%|█████     | 169/337 [01:44<01:47,  1.57it/s, Loss=0.0761, Avg Loss=0.0451]\u001b[A\n",
      "Epoch 1/10:  50%|█████     | 170/337 [01:44<01:46,  1.56it/s, Loss=0.0761, Avg Loss=0.0451]\u001b[A\n",
      "Epoch 1/10:  50%|█████     | 170/337 [01:45<01:46,  1.56it/s, Loss=0.0213, Avg Loss=0.0449]\u001b[A\n",
      "Epoch 1/10:  51%|█████     | 171/337 [01:45<01:46,  1.56it/s, Loss=0.0213, Avg Loss=0.0449]\u001b[A\n",
      "Epoch 1/10:  51%|█████     | 171/337 [01:45<01:46,  1.56it/s, Loss=0.0112, Avg Loss=0.0448]\u001b[A\n",
      "Epoch 1/10:  51%|█████     | 172/337 [01:45<01:46,  1.55it/s, Loss=0.0112, Avg Loss=0.0448]\u001b[A\n",
      "Epoch 1/10:  51%|█████     | 172/337 [01:46<01:46,  1.55it/s, Loss=0.0003, Avg Loss=0.0445]\u001b[A\n",
      "Epoch 1/10:  51%|█████▏    | 173/337 [01:46<01:45,  1.55it/s, Loss=0.0003, Avg Loss=0.0445]\u001b[A\n",
      "Epoch 1/10:  51%|█████▏    | 173/337 [01:47<01:45,  1.55it/s, Loss=0.0095, Avg Loss=0.0443]\u001b[A\n",
      "Epoch 1/10:  52%|█████▏    | 174/337 [01:47<01:45,  1.54it/s, Loss=0.0095, Avg Loss=0.0443]\u001b[A\n",
      "Epoch 1/10:  52%|█████▏    | 174/337 [01:47<01:45,  1.54it/s, Loss=0.0243, Avg Loss=0.0442]\u001b[A\n",
      "Epoch 1/10:  52%|█████▏    | 175/337 [01:47<01:45,  1.53it/s, Loss=0.0243, Avg Loss=0.0442]\u001b[A\n",
      "Epoch 1/10:  52%|█████▏    | 175/337 [01:48<01:45,  1.53it/s, Loss=0.0005, Avg Loss=0.0439]\u001b[A\n",
      "Epoch 1/10:  52%|█████▏    | 176/337 [01:48<01:44,  1.54it/s, Loss=0.0005, Avg Loss=0.0439]\u001b[A\n",
      "Epoch 1/10:  52%|█████▏    | 176/337 [01:49<01:44,  1.54it/s, Loss=0.0173, Avg Loss=0.0438]\u001b[A\n",
      "Epoch 1/10:  53%|█████▎    | 177/337 [01:49<01:42,  1.56it/s, Loss=0.0173, Avg Loss=0.0438]\u001b[A\n",
      "Epoch 1/10:  53%|█████▎    | 177/337 [01:49<01:42,  1.56it/s, Loss=0.0119, Avg Loss=0.0436]\u001b[A\n",
      "Epoch 1/10:  53%|█████▎    | 178/337 [01:49<01:42,  1.55it/s, Loss=0.0119, Avg Loss=0.0436]\u001b[A\n",
      "Epoch 1/10:  53%|█████▎    | 178/337 [01:50<01:42,  1.55it/s, Loss=0.0149, Avg Loss=0.0434]\u001b[A\n",
      "Epoch 1/10:  53%|█████▎    | 179/337 [01:50<01:42,  1.55it/s, Loss=0.0149, Avg Loss=0.0434]\u001b[A\n",
      "Epoch 1/10:  53%|█████▎    | 179/337 [01:51<01:42,  1.55it/s, Loss=0.0608, Avg Loss=0.0435]\u001b[A\n",
      "Epoch 1/10:  53%|█████▎    | 180/337 [01:51<01:42,  1.53it/s, Loss=0.0608, Avg Loss=0.0435]\u001b[A\n",
      "Epoch 1/10:  53%|█████▎    | 180/337 [01:51<01:42,  1.53it/s, Loss=0.0123, Avg Loss=0.0434]\u001b[A\n",
      "Epoch 1/10:  54%|█████▎    | 181/337 [01:51<01:41,  1.53it/s, Loss=0.0123, Avg Loss=0.0434]\u001b[A\n",
      "Epoch 1/10:  54%|█████▎    | 181/337 [01:52<01:41,  1.53it/s, Loss=0.2320, Avg Loss=0.0444]\u001b[A\n",
      "Epoch 1/10:  54%|█████▍    | 182/337 [01:52<01:41,  1.53it/s, Loss=0.2320, Avg Loss=0.0444]\u001b[A\n",
      "Epoch 1/10:  54%|█████▍    | 182/337 [01:53<01:41,  1.53it/s, Loss=0.0290, Avg Loss=0.0443]\u001b[A\n",
      "Epoch 1/10:  54%|█████▍    | 183/337 [01:53<01:40,  1.53it/s, Loss=0.0290, Avg Loss=0.0443]\u001b[A\n",
      "Epoch 1/10:  54%|█████▍    | 183/337 [01:53<01:40,  1.53it/s, Loss=0.0144, Avg Loss=0.0442]\u001b[A\n",
      "Epoch 1/10:  55%|█████▍    | 184/337 [01:53<01:40,  1.53it/s, Loss=0.0144, Avg Loss=0.0442]\u001b[A\n",
      "Epoch 1/10:  55%|█████▍    | 184/337 [01:54<01:40,  1.53it/s, Loss=0.0524, Avg Loss=0.0442]\u001b[A\n",
      "Epoch 1/10:  55%|█████▍    | 185/337 [01:54<01:39,  1.52it/s, Loss=0.0524, Avg Loss=0.0442]\u001b[A\n",
      "Epoch 1/10:  55%|█████▍    | 185/337 [01:54<01:39,  1.52it/s, Loss=0.0099, Avg Loss=0.0440]\u001b[A\n",
      "Epoch 1/10:  55%|█████▌    | 186/337 [01:54<01:39,  1.52it/s, Loss=0.0099, Avg Loss=0.0440]\u001b[A\n",
      "Epoch 1/10:  55%|█████▌    | 186/337 [01:55<01:39,  1.52it/s, Loss=0.0002, Avg Loss=0.0438]\u001b[A\n",
      "Epoch 1/10:  55%|█████▌    | 187/337 [01:55<01:38,  1.53it/s, Loss=0.0002, Avg Loss=0.0438]\u001b[A\n",
      "Epoch 1/10:  55%|█████▌    | 187/337 [01:56<01:38,  1.53it/s, Loss=0.0241, Avg Loss=0.0437]\u001b[A\n",
      "Epoch 1/10:  56%|█████▌    | 188/337 [01:56<01:37,  1.53it/s, Loss=0.0241, Avg Loss=0.0437]\u001b[A\n",
      "Epoch 1/10:  56%|█████▌    | 188/337 [01:56<01:37,  1.53it/s, Loss=0.0002, Avg Loss=0.0434]\u001b[A\n",
      "Epoch 1/10:  56%|█████▌    | 189/337 [01:56<01:38,  1.51it/s, Loss=0.0002, Avg Loss=0.0434]\u001b[A\n",
      "Epoch 1/10:  56%|█████▌    | 189/337 [01:57<01:38,  1.51it/s, Loss=0.0053, Avg Loss=0.0432]\u001b[A\n",
      "Epoch 1/10:  56%|█████▋    | 190/337 [01:57<01:37,  1.51it/s, Loss=0.0053, Avg Loss=0.0432]\u001b[A\n",
      "Epoch 1/10:  56%|█████▋    | 190/337 [01:58<01:37,  1.51it/s, Loss=0.0002, Avg Loss=0.0430]\u001b[A\n",
      "Epoch 1/10:  57%|█████▋    | 191/337 [01:58<01:36,  1.51it/s, Loss=0.0002, Avg Loss=0.0430]\u001b[A\n",
      "Epoch 1/10:  57%|█████▋    | 191/337 [01:58<01:36,  1.51it/s, Loss=0.0238, Avg Loss=0.0429]\u001b[A\n",
      "Epoch 1/10:  57%|█████▋    | 192/337 [01:58<01:36,  1.51it/s, Loss=0.0238, Avg Loss=0.0429]\u001b[A\n",
      "Epoch 1/10:  57%|█████▋    | 192/337 [01:59<01:36,  1.51it/s, Loss=0.0070, Avg Loss=0.0427]\u001b[A\n",
      "Epoch 1/10:  57%|█████▋    | 193/337 [01:59<01:35,  1.51it/s, Loss=0.0070, Avg Loss=0.0427]\u001b[A\n",
      "Epoch 1/10:  57%|█████▋    | 193/337 [02:00<01:35,  1.51it/s, Loss=0.0002, Avg Loss=0.0425]\u001b[A\n",
      "Epoch 1/10:  58%|█████▊    | 194/337 [02:00<01:34,  1.51it/s, Loss=0.0002, Avg Loss=0.0425]\u001b[A\n",
      "Epoch 1/10:  58%|█████▊    | 194/337 [02:00<01:34,  1.51it/s, Loss=0.0646, Avg Loss=0.0426]\u001b[A\n",
      "Epoch 1/10:  58%|█████▊    | 195/337 [02:00<01:33,  1.51it/s, Loss=0.0646, Avg Loss=0.0426]\u001b[A\n",
      "Epoch 1/10:  58%|█████▊    | 195/337 [02:01<01:33,  1.51it/s, Loss=0.0002, Avg Loss=0.0424]\u001b[A\n",
      "Epoch 1/10:  58%|█████▊    | 196/337 [02:01<01:33,  1.51it/s, Loss=0.0002, Avg Loss=0.0424]\u001b[A\n",
      "Epoch 1/10:  58%|█████▊    | 196/337 [02:02<01:33,  1.51it/s, Loss=0.0171, Avg Loss=0.0423]\u001b[A\n",
      "Epoch 1/10:  58%|█████▊    | 197/337 [02:02<01:32,  1.51it/s, Loss=0.0171, Avg Loss=0.0423]\u001b[A\n",
      "Epoch 1/10:  58%|█████▊    | 197/337 [02:02<01:32,  1.51it/s, Loss=0.0171, Avg Loss=0.0422]\u001b[A\n",
      "Epoch 1/10:  59%|█████▉    | 198/337 [02:02<01:32,  1.50it/s, Loss=0.0171, Avg Loss=0.0422]\u001b[A\n",
      "Epoch 1/10:  59%|█████▉    | 198/337 [02:03<01:32,  1.50it/s, Loss=0.0003, Avg Loss=0.0419]\u001b[A\n",
      "Epoch 1/10:  59%|█████▉    | 199/337 [02:03<01:31,  1.50it/s, Loss=0.0003, Avg Loss=0.0419]\u001b[A\n",
      "Epoch 1/10:  59%|█████▉    | 199/337 [02:04<01:31,  1.50it/s, Loss=0.0002, Avg Loss=0.0417]\u001b[A\n",
      "Epoch 1/10:  59%|█████▉    | 200/337 [02:04<01:31,  1.50it/s, Loss=0.0002, Avg Loss=0.0417]\u001b[A\n",
      "Epoch 1/10:  59%|█████▉    | 200/337 [02:04<01:31,  1.50it/s, Loss=0.0380, Avg Loss=0.0417]\u001b[A\n",
      "Epoch 1/10:  60%|█████▉    | 201/337 [02:04<01:30,  1.50it/s, Loss=0.0380, Avg Loss=0.0417]\u001b[A\n",
      "Epoch 1/10:  60%|█████▉    | 201/337 [02:05<01:30,  1.50it/s, Loss=0.0081, Avg Loss=0.0416]\u001b[A\n",
      "Epoch 1/10:  60%|█████▉    | 202/337 [02:05<01:29,  1.51it/s, Loss=0.0081, Avg Loss=0.0416]\u001b[A\n",
      "Epoch 1/10:  60%|█████▉    | 202/337 [02:06<01:29,  1.51it/s, Loss=0.0147, Avg Loss=0.0414]\u001b[A\n",
      "Epoch 1/10:  60%|██████    | 203/337 [02:06<01:28,  1.51it/s, Loss=0.0147, Avg Loss=0.0414]\u001b[A\n",
      "Epoch 1/10:  60%|██████    | 203/337 [02:06<01:28,  1.51it/s, Loss=0.0412, Avg Loss=0.0414]\u001b[A\n",
      "Epoch 1/10:  61%|██████    | 204/337 [02:06<01:28,  1.51it/s, Loss=0.0412, Avg Loss=0.0414]\u001b[A\n",
      "Epoch 1/10:  61%|██████    | 204/337 [02:07<01:28,  1.51it/s, Loss=0.1142, Avg Loss=0.0418]\u001b[A\n",
      "Epoch 1/10:  61%|██████    | 205/337 [02:07<01:28,  1.49it/s, Loss=0.1142, Avg Loss=0.0418]\u001b[A\n",
      "Epoch 1/10:  61%|██████    | 205/337 [02:08<01:28,  1.49it/s, Loss=0.0513, Avg Loss=0.0418]\u001b[A\n",
      "Epoch 1/10:  61%|██████    | 206/337 [02:08<01:27,  1.50it/s, Loss=0.0513, Avg Loss=0.0418]\u001b[A\n",
      "Epoch 1/10:  61%|██████    | 206/337 [02:08<01:27,  1.50it/s, Loss=0.0461, Avg Loss=0.0418]\u001b[A\n",
      "Epoch 1/10:  61%|██████▏   | 207/337 [02:08<01:26,  1.50it/s, Loss=0.0461, Avg Loss=0.0418]\u001b[A\n",
      "Epoch 1/10:  61%|██████▏   | 207/337 [02:09<01:26,  1.50it/s, Loss=0.0008, Avg Loss=0.0416]\u001b[A\n",
      "Epoch 1/10:  62%|██████▏   | 208/337 [02:09<01:26,  1.49it/s, Loss=0.0008, Avg Loss=0.0416]\u001b[A\n",
      "Epoch 1/10:  62%|██████▏   | 208/337 [02:10<01:26,  1.49it/s, Loss=0.0391, Avg Loss=0.0416]\u001b[A\n",
      "Epoch 1/10:  62%|██████▏   | 209/337 [02:10<01:26,  1.48it/s, Loss=0.0391, Avg Loss=0.0416]\u001b[A\n",
      "Epoch 1/10:  62%|██████▏   | 209/337 [02:10<01:26,  1.48it/s, Loss=0.0670, Avg Loss=0.0418]\u001b[A\n",
      "Epoch 1/10:  62%|██████▏   | 210/337 [02:10<01:25,  1.49it/s, Loss=0.0670, Avg Loss=0.0418]\u001b[A\n",
      "Epoch 1/10:  62%|██████▏   | 210/337 [02:11<01:25,  1.49it/s, Loss=0.0005, Avg Loss=0.0416]\u001b[A\n",
      "Epoch 1/10:  63%|██████▎   | 211/337 [02:11<01:24,  1.49it/s, Loss=0.0005, Avg Loss=0.0416]\u001b[A\n",
      "Epoch 1/10:  63%|██████▎   | 211/337 [02:12<01:24,  1.49it/s, Loss=0.0126, Avg Loss=0.0414]\u001b[A\n",
      "Epoch 1/10:  63%|██████▎   | 212/337 [02:12<01:24,  1.48it/s, Loss=0.0126, Avg Loss=0.0414]\u001b[A\n",
      "Epoch 1/10:  63%|██████▎   | 212/337 [02:12<01:24,  1.48it/s, Loss=0.0210, Avg Loss=0.0413]\u001b[A\n",
      "Epoch 1/10:  63%|██████▎   | 213/337 [02:12<01:23,  1.48it/s, Loss=0.0210, Avg Loss=0.0413]\u001b[A\n",
      "Epoch 1/10:  63%|██████▎   | 213/337 [02:13<01:23,  1.48it/s, Loss=0.1021, Avg Loss=0.0416]\u001b[A\n",
      "Epoch 1/10:  64%|██████▎   | 214/337 [02:13<01:22,  1.49it/s, Loss=0.1021, Avg Loss=0.0416]\u001b[A\n",
      "Epoch 1/10:  64%|██████▎   | 214/337 [02:14<01:22,  1.49it/s, Loss=0.0254, Avg Loss=0.0415]\u001b[A\n",
      "Epoch 1/10:  64%|██████▍   | 215/337 [02:14<01:21,  1.49it/s, Loss=0.0254, Avg Loss=0.0415]\u001b[A\n",
      "Epoch 1/10:  64%|██████▍   | 215/337 [02:14<01:21,  1.49it/s, Loss=0.0006, Avg Loss=0.0413]\u001b[A\n",
      "Epoch 1/10:  64%|██████▍   | 216/337 [02:14<01:20,  1.50it/s, Loss=0.0006, Avg Loss=0.0413]\u001b[A\n",
      "Epoch 1/10:  64%|██████▍   | 216/337 [02:15<01:20,  1.50it/s, Loss=0.0010, Avg Loss=0.0412]\u001b[A\n",
      "Epoch 1/10:  64%|██████▍   | 217/337 [02:15<01:20,  1.50it/s, Loss=0.0010, Avg Loss=0.0412]\u001b[A\n",
      "Epoch 1/10:  64%|██████▍   | 217/337 [02:16<01:20,  1.50it/s, Loss=0.0003, Avg Loss=0.0410]\u001b[A\n",
      "Epoch 1/10:  65%|██████▍   | 218/337 [02:16<01:19,  1.50it/s, Loss=0.0003, Avg Loss=0.0410]\u001b[A\n",
      "Epoch 1/10:  65%|██████▍   | 218/337 [02:16<01:19,  1.50it/s, Loss=0.0263, Avg Loss=0.0409]\u001b[A\n",
      "Epoch 1/10:  65%|██████▍   | 219/337 [02:16<01:18,  1.50it/s, Loss=0.0263, Avg Loss=0.0409]\u001b[A\n",
      "Epoch 1/10:  65%|██████▍   | 219/337 [02:17<01:18,  1.50it/s, Loss=0.0096, Avg Loss=0.0408]\u001b[A\n",
      "Epoch 1/10:  65%|██████▌   | 220/337 [02:17<01:17,  1.50it/s, Loss=0.0096, Avg Loss=0.0408]\u001b[A\n",
      "Epoch 1/10:  65%|██████▌   | 220/337 [02:18<01:17,  1.50it/s, Loss=0.0156, Avg Loss=0.0406]\u001b[A\n",
      "Epoch 1/10:  66%|██████▌   | 221/337 [02:18<01:16,  1.51it/s, Loss=0.0156, Avg Loss=0.0406]\u001b[A\n",
      "Epoch 1/10:  66%|██████▌   | 221/337 [02:18<01:16,  1.51it/s, Loss=0.0081, Avg Loss=0.0405]\u001b[A\n",
      "Epoch 1/10:  66%|██████▌   | 222/337 [02:18<01:16,  1.51it/s, Loss=0.0081, Avg Loss=0.0405]\u001b[A\n",
      "Epoch 1/10:  66%|██████▌   | 222/337 [02:19<01:16,  1.51it/s, Loss=0.0572, Avg Loss=0.0406]\u001b[A\n",
      "Epoch 1/10:  66%|██████▌   | 223/337 [02:19<01:15,  1.51it/s, Loss=0.0572, Avg Loss=0.0406]\u001b[A\n",
      "Epoch 1/10:  66%|██████▌   | 223/337 [02:20<01:15,  1.51it/s, Loss=0.0002, Avg Loss=0.0404]\u001b[A\n",
      "Epoch 1/10:  66%|██████▋   | 224/337 [02:20<01:14,  1.52it/s, Loss=0.0002, Avg Loss=0.0404]\u001b[A\n",
      "Epoch 1/10:  66%|██████▋   | 224/337 [02:20<01:14,  1.52it/s, Loss=0.0002, Avg Loss=0.0402]\u001b[A\n",
      "Epoch 1/10:  67%|██████▋   | 225/337 [02:20<01:13,  1.52it/s, Loss=0.0002, Avg Loss=0.0402]\u001b[A\n",
      "Epoch 1/10:  67%|██████▋   | 225/337 [02:21<01:13,  1.52it/s, Loss=0.0161, Avg Loss=0.0401]\u001b[A\n",
      "Epoch 1/10:  67%|██████▋   | 226/337 [02:21<01:13,  1.52it/s, Loss=0.0161, Avg Loss=0.0401]\u001b[A\n",
      "Epoch 1/10:  67%|██████▋   | 226/337 [02:22<01:13,  1.52it/s, Loss=0.0014, Avg Loss=0.0399]\u001b[A\n",
      "Epoch 1/10:  67%|██████▋   | 227/337 [02:22<01:12,  1.51it/s, Loss=0.0014, Avg Loss=0.0399]\u001b[A\n",
      "Epoch 1/10:  67%|██████▋   | 227/337 [02:22<01:12,  1.51it/s, Loss=0.0002, Avg Loss=0.0398]\u001b[A\n",
      "Epoch 1/10:  68%|██████▊   | 228/337 [02:22<01:12,  1.51it/s, Loss=0.0002, Avg Loss=0.0398]\u001b[A\n",
      "Epoch 1/10:  68%|██████▊   | 228/337 [02:23<01:12,  1.51it/s, Loss=0.0001, Avg Loss=0.0396]\u001b[A\n",
      "Epoch 1/10:  68%|██████▊   | 229/337 [02:23<01:11,  1.52it/s, Loss=0.0001, Avg Loss=0.0396]\u001b[A\n",
      "Epoch 1/10:  68%|██████▊   | 229/337 [02:24<01:11,  1.52it/s, Loss=0.0014, Avg Loss=0.0394]\u001b[A\n",
      "Epoch 1/10:  68%|██████▊   | 230/337 [02:24<01:10,  1.52it/s, Loss=0.0014, Avg Loss=0.0394]\u001b[A\n",
      "Epoch 1/10:  68%|██████▊   | 230/337 [02:24<01:10,  1.52it/s, Loss=0.0355, Avg Loss=0.0394]\u001b[A\n",
      "Epoch 1/10:  69%|██████▊   | 231/337 [02:24<01:09,  1.52it/s, Loss=0.0355, Avg Loss=0.0394]\u001b[A\n",
      "Epoch 1/10:  69%|██████▊   | 231/337 [02:25<01:09,  1.52it/s, Loss=0.0919, Avg Loss=0.0396]\u001b[A\n",
      "Epoch 1/10:  69%|██████▉   | 232/337 [02:25<01:08,  1.53it/s, Loss=0.0919, Avg Loss=0.0396]\u001b[A\n",
      "Epoch 1/10:  69%|██████▉   | 232/337 [02:26<01:08,  1.53it/s, Loss=0.0245, Avg Loss=0.0396]\u001b[A\n",
      "Epoch 1/10:  69%|██████▉   | 233/337 [02:26<01:07,  1.53it/s, Loss=0.0245, Avg Loss=0.0396]\u001b[A\n",
      "Epoch 1/10:  69%|██████▉   | 233/337 [02:26<01:07,  1.53it/s, Loss=0.0002, Avg Loss=0.0394]\u001b[A\n",
      "Epoch 1/10:  69%|██████▉   | 234/337 [02:26<01:07,  1.53it/s, Loss=0.0002, Avg Loss=0.0394]\u001b[A\n",
      "Epoch 1/10:  69%|██████▉   | 234/337 [02:27<01:07,  1.53it/s, Loss=0.0132, Avg Loss=0.0393]\u001b[A\n",
      "Epoch 1/10:  70%|██████▉   | 235/337 [02:27<01:06,  1.53it/s, Loss=0.0132, Avg Loss=0.0393]\u001b[A\n",
      "Epoch 1/10:  70%|██████▉   | 235/337 [02:28<01:06,  1.53it/s, Loss=0.0001, Avg Loss=0.0391]\u001b[A\n",
      "Epoch 1/10:  70%|███████   | 236/337 [02:28<01:05,  1.53it/s, Loss=0.0001, Avg Loss=0.0391]\u001b[A\n",
      "Epoch 1/10:  70%|███████   | 236/337 [02:28<01:05,  1.53it/s, Loss=0.0154, Avg Loss=0.0390]\u001b[A\n",
      "Epoch 1/10:  70%|███████   | 237/337 [02:28<01:05,  1.53it/s, Loss=0.0154, Avg Loss=0.0390]\u001b[A\n",
      "Epoch 1/10:  70%|███████   | 237/337 [02:29<01:05,  1.53it/s, Loss=0.0136, Avg Loss=0.0389]\u001b[A\n",
      "Epoch 1/10:  71%|███████   | 238/337 [02:29<01:04,  1.53it/s, Loss=0.0136, Avg Loss=0.0389]\u001b[A\n",
      "Epoch 1/10:  71%|███████   | 238/337 [02:30<01:04,  1.53it/s, Loss=0.0373, Avg Loss=0.0389]\u001b[A\n",
      "Epoch 1/10:  71%|███████   | 239/337 [02:30<01:04,  1.53it/s, Loss=0.0373, Avg Loss=0.0389]\u001b[A\n",
      "Epoch 1/10:  71%|███████   | 239/337 [02:30<01:04,  1.53it/s, Loss=0.0229, Avg Loss=0.0388]\u001b[A\n",
      "Epoch 1/10:  71%|███████   | 240/337 [02:30<01:03,  1.53it/s, Loss=0.0229, Avg Loss=0.0388]\u001b[A\n",
      "Epoch 1/10:  71%|███████   | 240/337 [02:31<01:03,  1.53it/s, Loss=0.0545, Avg Loss=0.0389]\u001b[A\n",
      "Epoch 1/10:  72%|███████▏  | 241/337 [02:31<01:02,  1.53it/s, Loss=0.0545, Avg Loss=0.0389]\u001b[A\n",
      "Epoch 1/10:  72%|███████▏  | 241/337 [02:32<01:02,  1.53it/s, Loss=0.0102, Avg Loss=0.0388]\u001b[A\n",
      "Epoch 1/10:  72%|███████▏  | 242/337 [02:32<01:01,  1.53it/s, Loss=0.0102, Avg Loss=0.0388]\u001b[A\n",
      "Epoch 1/10:  72%|███████▏  | 242/337 [02:32<01:01,  1.53it/s, Loss=0.0001, Avg Loss=0.0386]\u001b[A\n",
      "Epoch 1/10:  72%|███████▏  | 243/337 [02:32<01:01,  1.53it/s, Loss=0.0001, Avg Loss=0.0386]\u001b[A\n",
      "Epoch 1/10:  72%|███████▏  | 243/337 [02:33<01:01,  1.53it/s, Loss=0.0195, Avg Loss=0.0386]\u001b[A\n",
      "Epoch 1/10:  72%|███████▏  | 244/337 [02:33<01:00,  1.53it/s, Loss=0.0195, Avg Loss=0.0386]\u001b[A\n",
      "Epoch 1/10:  72%|███████▏  | 244/337 [02:34<01:00,  1.53it/s, Loss=0.1046, Avg Loss=0.0388]\u001b[A\n",
      "Epoch 1/10:  73%|███████▎  | 245/337 [02:34<00:59,  1.54it/s, Loss=0.1046, Avg Loss=0.0388]\u001b[A\n",
      "Epoch 1/10:  73%|███████▎  | 245/337 [02:34<00:59,  1.54it/s, Loss=0.0584, Avg Loss=0.0389]\u001b[A\n",
      "Epoch 1/10:  73%|███████▎  | 246/337 [02:34<00:59,  1.54it/s, Loss=0.0584, Avg Loss=0.0389]\u001b[A\n",
      "Epoch 1/10:  73%|███████▎  | 246/337 [02:35<00:59,  1.54it/s, Loss=0.0367, Avg Loss=0.0389]\u001b[A\n",
      "Epoch 1/10:  73%|███████▎  | 247/337 [02:35<00:58,  1.54it/s, Loss=0.0367, Avg Loss=0.0389]\u001b[A\n",
      "Epoch 1/10:  73%|███████▎  | 247/337 [02:35<00:58,  1.54it/s, Loss=0.0143, Avg Loss=0.0388]\u001b[A\n",
      "Epoch 1/10:  74%|███████▎  | 248/337 [02:35<00:57,  1.54it/s, Loss=0.0143, Avg Loss=0.0388]\u001b[A\n",
      "Epoch 1/10:  74%|███████▎  | 248/337 [02:36<00:57,  1.54it/s, Loss=0.0147, Avg Loss=0.0387]\u001b[A\n",
      "Epoch 1/10:  74%|███████▍  | 249/337 [02:36<00:56,  1.55it/s, Loss=0.0147, Avg Loss=0.0387]\u001b[A\n",
      "Epoch 1/10:  74%|███████▍  | 249/337 [02:37<00:56,  1.55it/s, Loss=0.0002, Avg Loss=0.0385]\u001b[A\n",
      "Epoch 1/10:  74%|███████▍  | 250/337 [02:37<00:56,  1.55it/s, Loss=0.0002, Avg Loss=0.0385]\u001b[A\n",
      "Epoch 1/10:  74%|███████▍  | 250/337 [02:37<00:56,  1.55it/s, Loss=0.0895, Avg Loss=0.0387]\u001b[A\n",
      "Epoch 1/10:  74%|███████▍  | 251/337 [02:37<00:55,  1.55it/s, Loss=0.0895, Avg Loss=0.0387]\u001b[A\n",
      "Epoch 1/10:  74%|███████▍  | 251/337 [02:38<00:55,  1.55it/s, Loss=0.0744, Avg Loss=0.0389]\u001b[A\n",
      "Epoch 1/10:  75%|███████▍  | 252/337 [02:38<00:54,  1.55it/s, Loss=0.0744, Avg Loss=0.0389]\u001b[A\n",
      "Epoch 1/10:  75%|███████▍  | 252/337 [02:39<00:54,  1.55it/s, Loss=0.0496, Avg Loss=0.0389]\u001b[A\n",
      "Epoch 1/10:  75%|███████▌  | 253/337 [02:39<00:54,  1.54it/s, Loss=0.0496, Avg Loss=0.0389]\u001b[A\n",
      "Epoch 1/10:  75%|███████▌  | 253/337 [02:39<00:54,  1.54it/s, Loss=0.0054, Avg Loss=0.0388]\u001b[A\n",
      "Epoch 1/10:  75%|███████▌  | 254/337 [02:39<00:53,  1.54it/s, Loss=0.0054, Avg Loss=0.0388]\u001b[A\n",
      "Epoch 1/10:  75%|███████▌  | 254/337 [02:40<00:53,  1.54it/s, Loss=0.0297, Avg Loss=0.0388]\u001b[A\n",
      "Epoch 1/10:  76%|███████▌  | 255/337 [02:40<00:53,  1.55it/s, Loss=0.0297, Avg Loss=0.0388]\u001b[A\n",
      "Epoch 1/10:  76%|███████▌  | 255/337 [02:41<00:53,  1.55it/s, Loss=0.0011, Avg Loss=0.0386]\u001b[A\n",
      "Epoch 1/10:  76%|███████▌  | 256/337 [02:41<00:52,  1.55it/s, Loss=0.0011, Avg Loss=0.0386]\u001b[A\n",
      "Epoch 1/10:  76%|███████▌  | 256/337 [02:41<00:52,  1.55it/s, Loss=0.0001, Avg Loss=0.0385]\u001b[A\n",
      "Epoch 1/10:  76%|███████▋  | 257/337 [02:41<00:51,  1.55it/s, Loss=0.0001, Avg Loss=0.0385]\u001b[A\n",
      "Epoch 1/10:  76%|███████▋  | 257/337 [02:42<00:51,  1.55it/s, Loss=0.0554, Avg Loss=0.0385]\u001b[A\n",
      "Epoch 1/10:  77%|███████▋  | 258/337 [02:42<00:50,  1.55it/s, Loss=0.0554, Avg Loss=0.0385]\u001b[A\n",
      "Epoch 1/10:  77%|███████▋  | 258/337 [02:43<00:50,  1.55it/s, Loss=0.0018, Avg Loss=0.0384]\u001b[A\n",
      "Epoch 1/10:  77%|███████▋  | 259/337 [02:43<00:50,  1.55it/s, Loss=0.0018, Avg Loss=0.0384]\u001b[A\n",
      "Epoch 1/10:  77%|███████▋  | 259/337 [02:43<00:50,  1.55it/s, Loss=0.0045, Avg Loss=0.0383]\u001b[A\n",
      "Epoch 1/10:  77%|███████▋  | 260/337 [02:43<00:49,  1.56it/s, Loss=0.0045, Avg Loss=0.0383]\u001b[A\n",
      "Epoch 1/10:  77%|███████▋  | 260/337 [02:44<00:49,  1.56it/s, Loss=0.0598, Avg Loss=0.0383]\u001b[A\n",
      "Epoch 1/10:  77%|███████▋  | 261/337 [02:44<00:48,  1.56it/s, Loss=0.0598, Avg Loss=0.0383]\u001b[A\n",
      "Epoch 1/10:  77%|███████▋  | 261/337 [02:44<00:48,  1.56it/s, Loss=0.1606, Avg Loss=0.0388]\u001b[A\n",
      "Epoch 1/10:  78%|███████▊  | 262/337 [02:44<00:48,  1.56it/s, Loss=0.1606, Avg Loss=0.0388]\u001b[A\n",
      "Epoch 1/10:  78%|███████▊  | 262/337 [02:45<00:48,  1.56it/s, Loss=0.0073, Avg Loss=0.0387]\u001b[A\n",
      "Epoch 1/10:  78%|███████▊  | 263/337 [02:45<00:47,  1.56it/s, Loss=0.0073, Avg Loss=0.0387]\u001b[A\n",
      "Epoch 1/10:  78%|███████▊  | 263/337 [02:46<00:47,  1.56it/s, Loss=0.0403, Avg Loss=0.0387]\u001b[A\n",
      "Epoch 1/10:  78%|███████▊  | 264/337 [02:46<00:46,  1.56it/s, Loss=0.0403, Avg Loss=0.0387]\u001b[A\n",
      "Epoch 1/10:  78%|███████▊  | 264/337 [02:46<00:46,  1.56it/s, Loss=0.0194, Avg Loss=0.0386]\u001b[A\n",
      "Epoch 1/10:  79%|███████▊  | 265/337 [02:46<00:46,  1.56it/s, Loss=0.0194, Avg Loss=0.0386]\u001b[A\n",
      "Epoch 1/10:  79%|███████▊  | 265/337 [02:47<00:46,  1.56it/s, Loss=0.0159, Avg Loss=0.0385]\u001b[A\n",
      "Epoch 1/10:  79%|███████▉  | 266/337 [02:47<00:45,  1.56it/s, Loss=0.0159, Avg Loss=0.0385]\u001b[A\n",
      "Epoch 1/10:  79%|███████▉  | 266/337 [02:48<00:45,  1.56it/s, Loss=0.0562, Avg Loss=0.0386]\u001b[A\n",
      "Epoch 1/10:  79%|███████▉  | 267/337 [02:48<00:44,  1.56it/s, Loss=0.0562, Avg Loss=0.0386]\u001b[A\n",
      "Epoch 1/10:  79%|███████▉  | 267/337 [02:48<00:44,  1.56it/s, Loss=0.0556, Avg Loss=0.0387]\u001b[A\n",
      "Epoch 1/10:  80%|███████▉  | 268/337 [02:48<00:44,  1.56it/s, Loss=0.0556, Avg Loss=0.0387]\u001b[A\n",
      "Epoch 1/10:  80%|███████▉  | 268/337 [02:49<00:44,  1.56it/s, Loss=0.0202, Avg Loss=0.0386]\u001b[A\n",
      "Epoch 1/10:  80%|███████▉  | 269/337 [02:49<00:43,  1.55it/s, Loss=0.0202, Avg Loss=0.0386]\u001b[A\n",
      "Epoch 1/10:  80%|███████▉  | 269/337 [02:50<00:43,  1.55it/s, Loss=0.0280, Avg Loss=0.0386]\u001b[A\n",
      "Epoch 1/10:  80%|████████  | 270/337 [02:50<00:43,  1.55it/s, Loss=0.0280, Avg Loss=0.0386]\u001b[A\n",
      "Epoch 1/10:  80%|████████  | 270/337 [02:50<00:43,  1.55it/s, Loss=0.0003, Avg Loss=0.0384]\u001b[A\n",
      "Epoch 1/10:  80%|████████  | 271/337 [02:50<00:42,  1.56it/s, Loss=0.0003, Avg Loss=0.0384]\u001b[A\n",
      "Epoch 1/10:  80%|████████  | 271/337 [02:51<00:42,  1.56it/s, Loss=0.0188, Avg Loss=0.0383]\u001b[A\n",
      "Epoch 1/10:  81%|████████  | 272/337 [02:51<00:41,  1.56it/s, Loss=0.0188, Avg Loss=0.0383]\u001b[A\n",
      "Epoch 1/10:  81%|████████  | 272/337 [02:52<00:41,  1.56it/s, Loss=0.0003, Avg Loss=0.0382]\u001b[A\n",
      "Epoch 1/10:  81%|████████  | 273/337 [02:52<00:40,  1.56it/s, Loss=0.0003, Avg Loss=0.0382]\u001b[A\n",
      "Epoch 1/10:  81%|████████  | 273/337 [02:52<00:40,  1.56it/s, Loss=0.0335, Avg Loss=0.0382]\u001b[A\n",
      "Epoch 1/10:  81%|████████▏ | 274/337 [02:52<00:40,  1.56it/s, Loss=0.0335, Avg Loss=0.0382]\u001b[A\n",
      "Epoch 1/10:  81%|████████▏ | 274/337 [02:53<00:40,  1.56it/s, Loss=0.0155, Avg Loss=0.0381]\u001b[A\n",
      "Epoch 1/10:  82%|████████▏ | 275/337 [02:53<00:40,  1.55it/s, Loss=0.0155, Avg Loss=0.0381]\u001b[A\n",
      "Epoch 1/10:  82%|████████▏ | 275/337 [02:53<00:40,  1.55it/s, Loss=0.0779, Avg Loss=0.0382]\u001b[A\n",
      "Epoch 1/10:  82%|████████▏ | 276/337 [02:53<00:39,  1.56it/s, Loss=0.0779, Avg Loss=0.0382]\u001b[A\n",
      "Epoch 1/10:  82%|████████▏ | 276/337 [02:54<00:39,  1.56it/s, Loss=0.0149, Avg Loss=0.0382]\u001b[A\n",
      "Epoch 1/10:  82%|████████▏ | 277/337 [02:54<00:38,  1.56it/s, Loss=0.0149, Avg Loss=0.0382]\u001b[A\n",
      "Epoch 1/10:  82%|████████▏ | 277/337 [02:55<00:38,  1.56it/s, Loss=0.0355, Avg Loss=0.0382]\u001b[A\n",
      "Epoch 1/10:  82%|████████▏ | 278/337 [02:55<00:37,  1.56it/s, Loss=0.0355, Avg Loss=0.0382]\u001b[A\n",
      "Epoch 1/10:  82%|████████▏ | 278/337 [02:55<00:37,  1.56it/s, Loss=0.0358, Avg Loss=0.0381]\u001b[A\n",
      "Epoch 1/10:  83%|████████▎ | 279/337 [02:55<00:37,  1.56it/s, Loss=0.0358, Avg Loss=0.0381]\u001b[A\n",
      "Epoch 1/10:  83%|████████▎ | 279/337 [02:56<00:37,  1.56it/s, Loss=0.0288, Avg Loss=0.0381]\u001b[A\n",
      "Epoch 1/10:  83%|████████▎ | 280/337 [02:56<00:36,  1.56it/s, Loss=0.0288, Avg Loss=0.0381]\u001b[A\n",
      "Epoch 1/10:  83%|████████▎ | 280/337 [02:57<00:36,  1.56it/s, Loss=0.0005, Avg Loss=0.0380]\u001b[A\n",
      "Epoch 1/10:  83%|████████▎ | 281/337 [02:57<00:35,  1.56it/s, Loss=0.0005, Avg Loss=0.0380]\u001b[A\n",
      "Epoch 1/10:  83%|████████▎ | 281/337 [02:57<00:35,  1.56it/s, Loss=0.0504, Avg Loss=0.0380]\u001b[A\n",
      "Epoch 1/10:  84%|████████▎ | 282/337 [02:57<00:35,  1.55it/s, Loss=0.0504, Avg Loss=0.0380]\u001b[A\n",
      "Epoch 1/10:  84%|████████▎ | 282/337 [02:58<00:35,  1.55it/s, Loss=0.0184, Avg Loss=0.0380]\u001b[A\n",
      "Epoch 1/10:  84%|████████▍ | 283/337 [02:58<00:34,  1.55it/s, Loss=0.0184, Avg Loss=0.0380]\u001b[A\n",
      "Epoch 1/10:  84%|████████▍ | 283/337 [02:59<00:34,  1.55it/s, Loss=0.0129, Avg Loss=0.0379]\u001b[A\n",
      "Epoch 1/10:  84%|████████▍ | 284/337 [02:59<00:34,  1.56it/s, Loss=0.0129, Avg Loss=0.0379]\u001b[A\n",
      "Epoch 1/10:  84%|████████▍ | 284/337 [02:59<00:34,  1.56it/s, Loss=0.0308, Avg Loss=0.0378]\u001b[A\n",
      "Epoch 1/10:  85%|████████▍ | 285/337 [02:59<00:33,  1.56it/s, Loss=0.0308, Avg Loss=0.0378]\u001b[A\n",
      "Epoch 1/10:  85%|████████▍ | 285/337 [03:00<00:33,  1.56it/s, Loss=0.0127, Avg Loss=0.0378]\u001b[A\n",
      "Epoch 1/10:  85%|████████▍ | 286/337 [03:00<00:32,  1.56it/s, Loss=0.0127, Avg Loss=0.0378]\u001b[A\n",
      "Epoch 1/10:  85%|████████▍ | 286/337 [03:01<00:32,  1.56it/s, Loss=0.0075, Avg Loss=0.0376]\u001b[A\n",
      "Epoch 1/10:  85%|████████▌ | 287/337 [03:01<00:31,  1.57it/s, Loss=0.0075, Avg Loss=0.0376]\u001b[A\n",
      "Epoch 1/10:  85%|████████▌ | 287/337 [03:01<00:31,  1.57it/s, Loss=0.0110, Avg Loss=0.0376]\u001b[A\n",
      "Epoch 1/10:  85%|████████▌ | 288/337 [03:01<00:31,  1.56it/s, Loss=0.0110, Avg Loss=0.0376]\u001b[A\n",
      "Epoch 1/10:  85%|████████▌ | 288/337 [03:02<00:31,  1.56it/s, Loss=0.0004, Avg Loss=0.0374]\u001b[A\n",
      "Epoch 1/10:  86%|████████▌ | 289/337 [03:02<00:30,  1.56it/s, Loss=0.0004, Avg Loss=0.0374]\u001b[A\n",
      "Epoch 1/10:  86%|████████▌ | 289/337 [03:02<00:30,  1.56it/s, Loss=0.0254, Avg Loss=0.0374]\u001b[A\n",
      "Epoch 1/10:  86%|████████▌ | 290/337 [03:02<00:30,  1.56it/s, Loss=0.0254, Avg Loss=0.0374]\u001b[A\n",
      "Epoch 1/10:  86%|████████▌ | 290/337 [03:03<00:30,  1.56it/s, Loss=0.0292, Avg Loss=0.0374]\u001b[A\n",
      "Epoch 1/10:  86%|████████▋ | 291/337 [03:03<00:29,  1.56it/s, Loss=0.0292, Avg Loss=0.0374]\u001b[A\n",
      "Epoch 1/10:  86%|████████▋ | 291/337 [03:04<00:29,  1.56it/s, Loss=0.0003, Avg Loss=0.0372]\u001b[A\n",
      "Epoch 1/10:  87%|████████▋ | 292/337 [03:04<00:28,  1.55it/s, Loss=0.0003, Avg Loss=0.0372]\u001b[A\n",
      "Epoch 1/10:  87%|████████▋ | 292/337 [03:04<00:28,  1.55it/s, Loss=0.0003, Avg Loss=0.0371]\u001b[A\n",
      "Epoch 1/10:  87%|████████▋ | 293/337 [03:04<00:28,  1.56it/s, Loss=0.0003, Avg Loss=0.0371]\u001b[A\n",
      "Epoch 1/10:  87%|████████▋ | 293/337 [03:05<00:28,  1.56it/s, Loss=0.0032, Avg Loss=0.0370]\u001b[A\n",
      "Epoch 1/10:  87%|████████▋ | 294/337 [03:05<00:27,  1.56it/s, Loss=0.0032, Avg Loss=0.0370]\u001b[A\n",
      "Epoch 1/10:  87%|████████▋ | 294/337 [03:06<00:27,  1.56it/s, Loss=0.0003, Avg Loss=0.0369]\u001b[A\n",
      "Epoch 1/10:  88%|████████▊ | 295/337 [03:06<00:26,  1.57it/s, Loss=0.0003, Avg Loss=0.0369]\u001b[A\n",
      "Epoch 1/10:  88%|████████▊ | 295/337 [03:06<00:26,  1.57it/s, Loss=0.0117, Avg Loss=0.0368]\u001b[A\n",
      "Epoch 1/10:  88%|████████▊ | 296/337 [03:06<00:26,  1.56it/s, Loss=0.0117, Avg Loss=0.0368]\u001b[A\n",
      "Epoch 1/10:  88%|████████▊ | 296/337 [03:07<00:26,  1.56it/s, Loss=0.0191, Avg Loss=0.0367]\u001b[A\n",
      "Epoch 1/10:  88%|████████▊ | 297/337 [03:07<00:25,  1.57it/s, Loss=0.0191, Avg Loss=0.0367]\u001b[A\n",
      "Epoch 1/10:  88%|████████▊ | 297/337 [03:08<00:25,  1.57it/s, Loss=0.0071, Avg Loss=0.0366]\u001b[A\n",
      "Epoch 1/10:  88%|████████▊ | 298/337 [03:08<00:24,  1.56it/s, Loss=0.0071, Avg Loss=0.0366]\u001b[A\n",
      "Epoch 1/10:  88%|████████▊ | 298/337 [03:08<00:24,  1.56it/s, Loss=0.0784, Avg Loss=0.0368]\u001b[A\n",
      "Epoch 1/10:  89%|████████▊ | 299/337 [03:08<00:24,  1.56it/s, Loss=0.0784, Avg Loss=0.0368]\u001b[A\n",
      "Epoch 1/10:  89%|████████▊ | 299/337 [03:09<00:24,  1.56it/s, Loss=0.0057, Avg Loss=0.0367]\u001b[A\n",
      "Epoch 1/10:  89%|████████▉ | 300/337 [03:09<00:23,  1.56it/s, Loss=0.0057, Avg Loss=0.0367]\u001b[A\n",
      "Epoch 1/10:  89%|████████▉ | 300/337 [03:09<00:23,  1.56it/s, Loss=0.0176, Avg Loss=0.0366]\u001b[A\n",
      "Epoch 1/10:  89%|████████▉ | 301/337 [03:09<00:23,  1.56it/s, Loss=0.0176, Avg Loss=0.0366]\u001b[A\n",
      "Epoch 1/10:  89%|████████▉ | 301/337 [03:10<00:23,  1.56it/s, Loss=0.0148, Avg Loss=0.0365]\u001b[A\n",
      "Epoch 1/10:  90%|████████▉ | 302/337 [03:10<00:22,  1.57it/s, Loss=0.0148, Avg Loss=0.0365]\u001b[A\n",
      "Epoch 1/10:  90%|████████▉ | 302/337 [03:11<00:22,  1.57it/s, Loss=0.0007, Avg Loss=0.0364]\u001b[A\n",
      "Epoch 1/10:  90%|████████▉ | 303/337 [03:11<00:21,  1.57it/s, Loss=0.0007, Avg Loss=0.0364]\u001b[A\n",
      "Epoch 1/10:  90%|████████▉ | 303/337 [03:11<00:21,  1.57it/s, Loss=0.0326, Avg Loss=0.0364]\u001b[A\n",
      "Epoch 1/10:  90%|█████████ | 304/337 [03:11<00:21,  1.57it/s, Loss=0.0326, Avg Loss=0.0364]\u001b[A\n",
      "Epoch 1/10:  90%|█████████ | 304/337 [03:12<00:21,  1.57it/s, Loss=0.0483, Avg Loss=0.0364]\u001b[A\n",
      "Epoch 1/10:  91%|█████████ | 305/337 [03:12<00:20,  1.56it/s, Loss=0.0483, Avg Loss=0.0364]\u001b[A\n",
      "Epoch 1/10:  91%|█████████ | 305/337 [03:13<00:20,  1.56it/s, Loss=0.0248, Avg Loss=0.0364]\u001b[A\n",
      "Epoch 1/10:  91%|█████████ | 306/337 [03:13<00:19,  1.55it/s, Loss=0.0248, Avg Loss=0.0364]\u001b[A\n",
      "Epoch 1/10:  91%|█████████ | 306/337 [03:13<00:19,  1.55it/s, Loss=0.0076, Avg Loss=0.0363]\u001b[A\n",
      "Epoch 1/10:  91%|█████████ | 307/337 [03:13<00:19,  1.54it/s, Loss=0.0076, Avg Loss=0.0363]\u001b[A\n",
      "Epoch 1/10:  91%|█████████ | 307/337 [03:14<00:19,  1.54it/s, Loss=0.0182, Avg Loss=0.0362]\u001b[A\n",
      "Epoch 1/10:  91%|█████████▏| 308/337 [03:14<00:18,  1.54it/s, Loss=0.0182, Avg Loss=0.0362]\u001b[A\n",
      "Epoch 1/10:  91%|█████████▏| 308/337 [03:15<00:18,  1.54it/s, Loss=0.0317, Avg Loss=0.0362]\u001b[A\n",
      "Epoch 1/10:  92%|█████████▏| 309/337 [03:15<00:18,  1.55it/s, Loss=0.0317, Avg Loss=0.0362]\u001b[A\n",
      "Epoch 1/10:  92%|█████████▏| 309/337 [03:15<00:18,  1.55it/s, Loss=0.0316, Avg Loss=0.0362]\u001b[A\n",
      "Epoch 1/10:  92%|█████████▏| 310/337 [03:15<00:17,  1.55it/s, Loss=0.0316, Avg Loss=0.0362]\u001b[A\n",
      "Epoch 1/10:  92%|█████████▏| 310/337 [03:16<00:17,  1.55it/s, Loss=0.0074, Avg Loss=0.0361]\u001b[A\n",
      "Epoch 1/10:  92%|█████████▏| 311/337 [03:16<00:16,  1.56it/s, Loss=0.0074, Avg Loss=0.0361]\u001b[A\n",
      "Epoch 1/10:  92%|█████████▏| 311/337 [03:17<00:16,  1.56it/s, Loss=0.0034, Avg Loss=0.0360]\u001b[A\n",
      "Epoch 1/10:  93%|█████████▎| 312/337 [03:17<00:16,  1.55it/s, Loss=0.0034, Avg Loss=0.0360]\u001b[A\n",
      "Epoch 1/10:  93%|█████████▎| 312/337 [03:17<00:16,  1.55it/s, Loss=0.0299, Avg Loss=0.0360]\u001b[A\n",
      "Epoch 1/10:  93%|█████████▎| 313/337 [03:17<00:15,  1.53it/s, Loss=0.0299, Avg Loss=0.0360]\u001b[A\n",
      "Epoch 1/10:  93%|█████████▎| 313/337 [03:18<00:15,  1.53it/s, Loss=0.0158, Avg Loss=0.0359]\u001b[A\n",
      "Epoch 1/10:  93%|█████████▎| 314/337 [03:18<00:14,  1.53it/s, Loss=0.0158, Avg Loss=0.0359]\u001b[A\n",
      "Epoch 1/10:  93%|█████████▎| 314/337 [03:19<00:14,  1.53it/s, Loss=0.0183, Avg Loss=0.0359]\u001b[A\n",
      "Epoch 1/10:  93%|█████████▎| 315/337 [03:19<00:14,  1.54it/s, Loss=0.0183, Avg Loss=0.0359]\u001b[A\n",
      "Epoch 1/10:  93%|█████████▎| 315/337 [03:19<00:14,  1.54it/s, Loss=0.0002, Avg Loss=0.0358]\u001b[A\n",
      "Epoch 1/10:  94%|█████████▍| 316/337 [03:19<00:13,  1.55it/s, Loss=0.0002, Avg Loss=0.0358]\u001b[A\n",
      "Epoch 1/10:  94%|█████████▍| 316/337 [03:20<00:13,  1.55it/s, Loss=0.0111, Avg Loss=0.0357]\u001b[A\n",
      "Epoch 1/10:  94%|█████████▍| 317/337 [03:20<00:12,  1.55it/s, Loss=0.0111, Avg Loss=0.0357]\u001b[A\n",
      "Epoch 1/10:  94%|█████████▍| 317/337 [03:20<00:12,  1.55it/s, Loss=0.0251, Avg Loss=0.0356]\u001b[A\n",
      "Epoch 1/10:  94%|█████████▍| 318/337 [03:20<00:12,  1.55it/s, Loss=0.0251, Avg Loss=0.0356]\u001b[A\n",
      "Epoch 1/10:  94%|█████████▍| 318/337 [03:21<00:12,  1.55it/s, Loss=0.0362, Avg Loss=0.0356]\u001b[A\n",
      "Epoch 1/10:  95%|█████████▍| 319/337 [03:21<00:11,  1.55it/s, Loss=0.0362, Avg Loss=0.0356]\u001b[A\n",
      "Epoch 1/10:  95%|█████████▍| 319/337 [03:22<00:11,  1.55it/s, Loss=0.0096, Avg Loss=0.0356]\u001b[A\n",
      "Epoch 1/10:  95%|█████████▍| 320/337 [03:22<00:10,  1.55it/s, Loss=0.0096, Avg Loss=0.0356]\u001b[A\n",
      "Epoch 1/10:  95%|█████████▍| 320/337 [03:22<00:10,  1.55it/s, Loss=0.0835, Avg Loss=0.0357]\u001b[A\n",
      "Epoch 1/10:  95%|█████████▌| 321/337 [03:22<00:10,  1.54it/s, Loss=0.0835, Avg Loss=0.0357]\u001b[A\n",
      "Epoch 1/10:  95%|█████████▌| 321/337 [03:23<00:10,  1.54it/s, Loss=0.0347, Avg Loss=0.0357]\u001b[A\n",
      "Epoch 1/10:  96%|█████████▌| 322/337 [03:23<00:09,  1.55it/s, Loss=0.0347, Avg Loss=0.0357]\u001b[A\n",
      "Epoch 1/10:  96%|█████████▌| 322/337 [03:24<00:09,  1.55it/s, Loss=0.0167, Avg Loss=0.0357]\u001b[A\n",
      "Epoch 1/10:  96%|█████████▌| 323/337 [03:24<00:09,  1.54it/s, Loss=0.0167, Avg Loss=0.0357]\u001b[A\n",
      "Epoch 1/10:  96%|█████████▌| 323/337 [03:24<00:09,  1.54it/s, Loss=0.0656, Avg Loss=0.0357]\u001b[A\n",
      "Epoch 1/10:  96%|█████████▌| 324/337 [03:24<00:08,  1.54it/s, Loss=0.0656, Avg Loss=0.0357]\u001b[A\n",
      "Epoch 1/10:  96%|█████████▌| 324/337 [03:25<00:08,  1.54it/s, Loss=0.0175, Avg Loss=0.0357]\u001b[A\n",
      "Epoch 1/10:  96%|█████████▋| 325/337 [03:25<00:07,  1.54it/s, Loss=0.0175, Avg Loss=0.0357]\u001b[A\n",
      "Epoch 1/10:  96%|█████████▋| 325/337 [03:26<00:07,  1.54it/s, Loss=0.0001, Avg Loss=0.0356]\u001b[A\n",
      "Epoch 1/10:  97%|█████████▋| 326/337 [03:26<00:07,  1.54it/s, Loss=0.0001, Avg Loss=0.0356]\u001b[A\n",
      "Epoch 1/10:  97%|█████████▋| 326/337 [03:26<00:07,  1.54it/s, Loss=0.0001, Avg Loss=0.0355]\u001b[A\n",
      "Epoch 1/10:  97%|█████████▋| 327/337 [03:26<00:06,  1.54it/s, Loss=0.0001, Avg Loss=0.0355]\u001b[A\n",
      "Epoch 1/10:  97%|█████████▋| 327/337 [03:27<00:06,  1.54it/s, Loss=0.0001, Avg Loss=0.0354]\u001b[A\n",
      "Epoch 1/10:  97%|█████████▋| 328/337 [03:27<00:05,  1.55it/s, Loss=0.0001, Avg Loss=0.0354]\u001b[A\n",
      "Epoch 1/10:  97%|█████████▋| 328/337 [03:28<00:05,  1.55it/s, Loss=0.0415, Avg Loss=0.0354]\u001b[A\n",
      "Epoch 1/10:  98%|█████████▊| 329/337 [03:28<00:05,  1.55it/s, Loss=0.0415, Avg Loss=0.0354]\u001b[A\n",
      "Epoch 1/10:  98%|█████████▊| 329/337 [03:28<00:05,  1.55it/s, Loss=0.0662, Avg Loss=0.0355]\u001b[A\n",
      "Epoch 1/10:  98%|█████████▊| 330/337 [03:28<00:04,  1.55it/s, Loss=0.0662, Avg Loss=0.0355]\u001b[A\n",
      "Epoch 1/10:  98%|█████████▊| 330/337 [03:29<00:04,  1.55it/s, Loss=0.0107, Avg Loss=0.0354]\u001b[A\n",
      "Epoch 1/10:  98%|█████████▊| 331/337 [03:29<00:03,  1.55it/s, Loss=0.0107, Avg Loss=0.0354]\u001b[A\n",
      "Epoch 1/10:  98%|█████████▊| 331/337 [03:30<00:03,  1.55it/s, Loss=0.1045, Avg Loss=0.0356]\u001b[A\n",
      "Epoch 1/10:  99%|█████████▊| 332/337 [03:30<00:03,  1.54it/s, Loss=0.1045, Avg Loss=0.0356]\u001b[A\n",
      "Epoch 1/10:  99%|█████████▊| 332/337 [03:30<00:03,  1.54it/s, Loss=0.0100, Avg Loss=0.0355]\u001b[A\n",
      "Epoch 1/10:  99%|█████████▉| 333/337 [03:30<00:02,  1.55it/s, Loss=0.0100, Avg Loss=0.0355]\u001b[A\n",
      "Epoch 1/10:  99%|█████████▉| 333/337 [03:31<00:02,  1.55it/s, Loss=0.0183, Avg Loss=0.0355]\u001b[A\n",
      "Epoch 1/10:  99%|█████████▉| 334/337 [03:31<00:01,  1.55it/s, Loss=0.0183, Avg Loss=0.0355]\u001b[A\n",
      "Epoch 1/10:  99%|█████████▉| 334/337 [03:31<00:01,  1.55it/s, Loss=0.0655, Avg Loss=0.0356]\u001b[A\n",
      "Epoch 1/10:  99%|█████████▉| 335/337 [03:31<00:01,  1.55it/s, Loss=0.0655, Avg Loss=0.0356]\u001b[A\n",
      "Epoch 1/10:  99%|█████████▉| 335/337 [03:32<00:01,  1.55it/s, Loss=0.0488, Avg Loss=0.0356]\u001b[A\n",
      "Epoch 1/10: 100%|█████████▉| 336/337 [03:32<00:00,  1.55it/s, Loss=0.0488, Avg Loss=0.0356]\u001b[A\n",
      "Epoch 1/10: 100%|█████████▉| 336/337 [03:32<00:00,  1.55it/s, Loss=0.0000, Avg Loss=0.0355]\u001b[A\n",
      "Epoch 1/10: 100%|██████████| 337/337 [03:32<00:00,  1.58it/s, Loss=0.0000, Avg Loss=0.0355]\n",
      "Validation:   0%|          | 0/72 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation: 100%|██████████| 72/72 [00:19<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      "  Train Loss: 0.0355\n",
      "  Val Loss: 0.0276\n",
      "  Val Accuracy: 0.9444\n",
      "  Val F1-Score: 0.9509\n",
      "--------------------------------------------------\n",
      "New best model saved with F1-Score: 0.9509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:   0%|          | 0/337 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Epoch 2/10: 100%|██████████| 337/337 [03:36<00:00,  1.55it/s, Loss=0.0000, Avg Loss=0.0263]\n",
      "Validation:   0%|          | 0/72 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation: 100%|██████████| 72/72 [00:19<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:\n",
      "  Train Loss: 0.0263\n",
      "  Val Loss: 0.0253\n",
      "  Val Accuracy: 0.9470\n",
      "  Val F1-Score: 0.9494\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:   0%|          | 0/337 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Epoch 3/10: 100%|██████████| 337/337 [03:37<00:00,  1.55it/s, Loss=0.0000, Avg Loss=0.0221]\n",
      "Validation:   0%|          | 0/72 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation: 100%|██████████| 72/72 [00:19<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:\n",
      "  Train Loss: 0.0221\n",
      "  Val Loss: 0.0281\n",
      "  Val Accuracy: 0.9566\n",
      "  Val F1-Score: 0.9574\n",
      "--------------------------------------------------\n",
      "New best model saved with F1-Score: 0.9574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:   0%|          | 0/337 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Epoch 4/10: 100%|██████████| 337/337 [03:37<00:00,  1.55it/s, Loss=9.0881, Avg Loss=0.0418]\n",
      "Validation:   0%|          | 0/72 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation: 100%|██████████| 72/72 [00:18<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:\n",
      "  Train Loss: 0.0418\n",
      "  Val Loss: 0.0356\n",
      "  Val Accuracy: 0.9618\n",
      "  Val F1-Score: 0.9628\n",
      "--------------------------------------------------\n",
      "New best model saved with F1-Score: 0.9628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:   0%|          | 0/337 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Epoch 5/10: 100%|██████████| 337/337 [03:36<00:00,  1.55it/s, Loss=0.0000, Avg Loss=0.0049]\n",
      "Validation:   0%|          | 0/72 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation: 100%|██████████| 72/72 [00:19<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:\n",
      "  Train Loss: 0.0049\n",
      "  Val Loss: 0.0627\n",
      "  Val Accuracy: 0.9644\n",
      "  Val F1-Score: 0.9628\n",
      "--------------------------------------------------\n",
      "New best model saved with F1-Score: 0.9628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:   0%|          | 0/337 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Epoch 6/10: 100%|██████████| 337/337 [03:37<00:00,  1.55it/s, Loss=0.0000, Avg Loss=0.0016]\n",
      "Validation:   0%|          | 0/72 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation: 100%|██████████| 72/72 [00:19<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:\n",
      "  Train Loss: 0.0016\n",
      "  Val Loss: 0.0974\n",
      "  Val Accuracy: 0.9644\n",
      "  Val F1-Score: 0.9668\n",
      "--------------------------------------------------\n",
      "New best model saved with F1-Score: 0.9668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:   0%|          | 0/337 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Epoch 7/10: 100%|██████████| 337/337 [03:36<00:00,  1.55it/s, Loss=0.0000, Avg Loss=0.0007]\n",
      "Validation:   0%|          | 0/72 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation: 100%|██████████| 72/72 [00:19<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0976\n",
      "  Val Accuracy: 0.9653\n",
      "  Val F1-Score: 0.9667\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:   0%|          | 0/337 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Epoch 8/10: 100%|██████████| 337/337 [03:36<00:00,  1.56it/s, Loss=0.0000, Avg Loss=0.0006]\n",
      "Validation:   0%|          | 0/72 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation: 100%|██████████| 72/72 [00:19<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:\n",
      "  Train Loss: 0.0006\n",
      "  Val Loss: 0.0977\n",
      "  Val Accuracy: 0.9644\n",
      "  Val F1-Score: 0.9655\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:   0%|          | 0/337 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Epoch 9/10: 100%|██████████| 337/337 [03:36<00:00,  1.55it/s, Loss=0.0000, Avg Loss=0.0007]\n",
      "Validation:   0%|          | 0/72 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation: 100%|██████████| 72/72 [00:19<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:\n",
      "  Train Loss: 0.0007\n",
      "  Val Loss: 0.0992\n",
      "  Val Accuracy: 0.9653\n",
      "  Val F1-Score: 0.9662\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:   0%|          | 0/337 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Epoch 10/10: 100%|██████████| 337/337 [03:36<00:00,  1.55it/s, Loss=0.0000, Avg Loss=0.0005]\n",
      "Validation:   0%|          | 0/72 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation: 100%|██████████| 72/72 [00:19<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:\n",
      "  Train Loss: 0.0005\n",
      "  Val Loss: 0.0986\n",
      "  Val Accuracy: 0.9653\n",
      "  Val F1-Score: 0.9662\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading best model for evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/73 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Evaluating: 100%|██████████| 73/73 [00:19<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results:\n",
      "Accuracy: 0.9766\n",
      "F1-Score: 0.9765\n",
      "\n",
      "Detailed Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Non-Sarcastic       0.99      0.99      0.99      1101\n",
      "    Sarcastic       0.75      0.73      0.74        52\n",
      "\n",
      "     accuracy                           0.98      1153\n",
      "    macro avg       0.87      0.86      0.86      1153\n",
      " weighted avg       0.98      0.98      0.98      1153\n",
      "\n",
      "Training completed successfully!\n",
      "Final Test Accuracy: 0.9766\n",
      "Final Test F1-Score: 0.9765\n",
      "\n",
      "Computing advanced metrics...\n",
      "Error during main execution: name 'test_loader' is not defined\n",
      "Running demonstration instead...\n",
      "HCI-EASD MODEL CAPABILITIES DEMONSTRATION\n",
      "============================================================\n",
      "Creating demo model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing sample texts...\n",
      "------------------------------------------------------------\n",
      "\n",
      "Sample 1: 'This is absolutely fantastic!'\n",
      "Prediction: Sarcastic\n",
      "Confidence: 0.609\n",
      "Incongruity Score: 0.466\n",
      "Sarcasm Probability: 0.609\n",
      "------------------------------\n",
      "\n",
      "Sample 2: 'What a wonderful day to be stuck in traffic'\n",
      "Prediction: Sarcastic\n",
      "Confidence: 0.592\n",
      "Incongruity Score: 0.471\n",
      "Sarcasm Probability: 0.592\n",
      "------------------------------\n",
      "\n",
      "Sample 3: 'I love waiting in long lines'\n",
      "Prediction: Sarcastic\n",
      "Confidence: 0.624\n",
      "Incongruity Score: 0.462\n",
      "Sarcasm Probability: 0.624\n",
      "------------------------------\n",
      "\n",
      "Sample 4: 'The weather is nice today'\n",
      "Prediction: Sarcastic\n",
      "Confidence: 0.593\n",
      "Incongruity Score: 0.466\n",
      "Sarcasm Probability: 0.593\n",
      "------------------------------\n",
      "\n",
      "Sample 5: 'Thank you for your help'\n",
      "Prediction: Sarcastic\n",
      "Confidence: 0.574\n",
      "Incongruity Score: 0.486\n",
      "Sarcasm Probability: 0.574\n",
      "------------------------------\n",
      "\n",
      "Sample 6: 'Oh great, another meeting'\n",
      "Prediction: Sarcastic\n",
      "Confidence: 0.608\n",
      "Incongruity Score: 0.469\n",
      "Sarcasm Probability: 0.608\n",
      "------------------------------\n",
      "\n",
      "Sample 7: 'Perfect timing for rain during my picnic'\n",
      "Prediction: Sarcastic\n",
      "Confidence: 0.543\n",
      "Incongruity Score: 0.468\n",
      "Sarcasm Probability: 0.543\n",
      "------------------------------\n",
      "\n",
      "Sample 8: 'I enjoyed the movie very much'\n",
      "Prediction: Sarcastic\n",
      "Confidence: 0.569\n",
      "Incongruity Score: 0.491\n",
      "Sarcasm Probability: 0.569\n",
      "------------------------------\n",
      "\n",
      "Sample 9: 'Such amazing customer service... NOT!'\n",
      "Prediction: Sarcastic\n",
      "Confidence: 0.747\n",
      "Incongruity Score: 0.469\n",
      "Sarcasm Probability: 0.747\n",
      "------------------------------\n",
      "\n",
      "Sample 10: 'The food was delicious'\n",
      "Prediction: Sarcastic\n",
      "Confidence: 0.550\n",
      "Incongruity Score: 0.469\n",
      "Sarcasm Probability: 0.550\n",
      "------------------------------\n",
      "\n",
      "Demonstration completed!\n",
      "\n",
      "To use the full model:\n",
      "1. Ensure you have the correct dataset paths\n",
      "2. Install all required dependencies\n",
      "3. Run the script with proper GPU support for best performance\n",
      "4. The model will automatically save the best checkpoint\n",
      "5. Use HCI_EASD_Predictor class for easy inference\n",
      "\n",
      "============================================================\n",
      "HCI-EASD: Hierarchical Cross-Modal Incongruity and\n",
      "Emotion-Aware Sarcasm Detection - Implementation Complete\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    BertTokenizer, BertModel, \n",
    "    AutoTokenizer, AutoModel,\n",
    "    pipeline\n",
    ")\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# =============================================\n",
    "# Data Loading and Preprocessing\n",
    "# =============================================\n",
    "\n",
    "class MultimodalSarcasmDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, transform=None, max_length=128):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.transform = transform\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data.iloc[idx]\n",
    "        \n",
    "        # Text processing\n",
    "        text = str(item.get('text', ''))\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Image processing\n",
    "        try:\n",
    "            if 'image_path' in item and pd.notna(item['image_path']) and os.path.exists(item['image_path']):\n",
    "                image = Image.open(item['image_path']).convert('RGB')\n",
    "                if self.transform:\n",
    "                    image = self.transform(image)\n",
    "            else:\n",
    "                # Create dummy image if not available\n",
    "                image = torch.zeros(3, 224, 224)\n",
    "        except:\n",
    "            image = torch.zeros(3, 224, 224)\n",
    "        \n",
    "        # Label\n",
    "        label = int(item.get('sarcastic', 0))\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
    "            'image': image,\n",
    "            'label': torch.tensor(label, dtype=torch.long),\n",
    "            'text': text\n",
    "        }\n",
    "\n",
    "def load_datasets():\n",
    "    \"\"\"Load and preprocess the datasets\"\"\"\n",
    "    \n",
    "    # File paths (modify these according to your setup)\n",
    "    memotion_labels_path = \"/kaggle/input/memotion-dataset-7k/memotion_dataset_7k/labels.csv\"\n",
    "    memotion_reference_path = \"/kaggle/input/memotion-dataset-7k/memotion_dataset_7k/reference.csv\"\n",
    "    mustard_json_path = \"/kaggle/input/mustard-multimodal-sarcasm-detection-dataset/sarcasm_data.json\"\n",
    "    \n",
    "    all_data = []\n",
    "    \n",
    "    # Load Memotion dataset\n",
    "    try:\n",
    "        if os.path.exists(memotion_labels_path) and os.path.exists(memotion_reference_path):\n",
    "            labels_df = pd.read_csv(memotion_labels_path)\n",
    "            reference_df = pd.read_csv(memotion_reference_path)\n",
    "            \n",
    "            # Merge the dataframes\n",
    "            memotion_df = pd.merge(labels_df, reference_df, on='image_name', how='inner')\n",
    "            \n",
    "            # Process memotion data\n",
    "            for _, row in memotion_df.iterrows():\n",
    "                data_point = {\n",
    "                    'text': row.get('text_corrected', ''),\n",
    "                    'image_path': f\"/kaggle/input/memotion-dataset-7k/memotion_dataset_7k/images/{row['image_name']}\",\n",
    "                    'sarcastic': 1 if row.get('sarcastic', 0) == 1 else 0,\n",
    "                    'dataset': 'memotion'\n",
    "                }\n",
    "                all_data.append(data_point)\n",
    "            \n",
    "            print(f\"Loaded {len(memotion_df)} samples from Memotion dataset\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading Memotion dataset: {e}\")\n",
    "    \n",
    "    # Load MUStARD dataset\n",
    "    try:\n",
    "        if os.path.exists(mustard_json_path):\n",
    "            with open(mustard_json_path, 'r') as f:\n",
    "                mustard_data = json.load(f)\n",
    "            \n",
    "            for key, value in mustard_data.items():\n",
    "                data_point = {\n",
    "                    'text': value.get('utterance', ''),\n",
    "                    'image_path': None,  # MUStARD might not have direct image paths\n",
    "                    'sarcastic': 1 if value.get('sarcasm', False) else 0,\n",
    "                    'dataset': 'mustard'\n",
    "                }\n",
    "                all_data.append(data_point)\n",
    "            \n",
    "            print(f\"Loaded {len(mustard_data)} samples from MUStARD dataset\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading MUStARD dataset: {e}\")\n",
    "    \n",
    "    # Create synthetic data if datasets are not available\n",
    "    if not all_data:\n",
    "        print(\"Creating synthetic data for demonstration...\")\n",
    "        synthetic_texts = [\n",
    "            (\"This is absolutely fantastic!\", 1),\n",
    "            (\"What a wonderful day to be stuck in traffic\", 1),\n",
    "            (\"I love waiting in long lines\", 1),\n",
    "            (\"The weather is nice today\", 0),\n",
    "            (\"Thank you for your help\", 0),\n",
    "            (\"Oh great, another meeting\", 1),\n",
    "            (\"Perfect timing for rain\", 1),\n",
    "            (\"I enjoyed the movie\", 0),\n",
    "            (\"Such amazing customer service\", 1),\n",
    "            (\"The food was delicious\", 0)\n",
    "        ] * 100  # Repeat to create more samples\n",
    "        \n",
    "        for i, (text, label) in enumerate(synthetic_texts):\n",
    "            data_point = {\n",
    "                'text': text,\n",
    "                'image_path': None,\n",
    "                'sarcastic': label,\n",
    "                'dataset': 'synthetic'\n",
    "            }\n",
    "            all_data.append(data_point)\n",
    "    \n",
    "    df = pd.DataFrame(all_data)\n",
    "    print(f\"Total dataset size: {len(df)}\")\n",
    "    print(f\"Sarcastic samples: {df['sarcastic'].sum()}\")\n",
    "    print(f\"Non-sarcastic samples: {len(df) - df['sarcastic'].sum()}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# =============================================\n",
    "# Emotion Detection Components\n",
    "# =============================================\n",
    "\n",
    "class EmotionExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EmotionExtractor, self).__init__()\n",
    "        # Text emotion classifier\n",
    "        self.text_emotion_model = pipeline(\n",
    "            \"text-classification\",\n",
    "            model=\"j-hartmann/emotion-english-distilroberta-base\",\n",
    "            device=0 if torch.cuda.is_available() else -1\n",
    "        )\n",
    "        \n",
    "        # Simple emotion embedding\n",
    "        self.emotion_embedding = nn.Embedding(7, 64)  # 7 basic emotions\n",
    "        \n",
    "    def extract_text_emotion(self, texts):\n",
    "        \"\"\"Extract emotion features from text\"\"\"\n",
    "        emotion_features = []\n",
    "        \n",
    "        for text in texts:\n",
    "            try:\n",
    "                result = self.text_emotion_model(text)[0]\n",
    "                # Map emotion to index\n",
    "                emotion_map = {\n",
    "                    'joy': 0, 'sadness': 1, 'anger': 2, 'fear': 3,\n",
    "                    'surprise': 4, 'disgust': 5, 'neutral': 6\n",
    "                }\n",
    "                emotion_idx = emotion_map.get(result['label'].lower(), 6)\n",
    "                emotion_features.append(emotion_idx)\n",
    "            except:\n",
    "                emotion_features.append(6)  # neutral as default\n",
    "        \n",
    "        return torch.tensor(emotion_features, device=device)\n",
    "    \n",
    "    def forward(self, texts):\n",
    "        emotion_indices = self.extract_text_emotion(texts)\n",
    "        return self.emotion_embedding(emotion_indices)\n",
    "\n",
    "# =============================================\n",
    "# Cross-Modal Incongruity Module\n",
    "# =============================================\n",
    "\n",
    "class CrossModalIncongruityModule(nn.Module):\n",
    "    def __init__(self, text_dim=768, image_dim=2048, hidden_dim=512, num_heads=8):\n",
    "        super(CrossModalIncongruityModule, self).__init__()\n",
    "        \n",
    "        self.text_projection = nn.Linear(text_dim, hidden_dim)\n",
    "        self.image_projection = nn.Linear(image_dim, hidden_dim)\n",
    "        \n",
    "        # Multi-head cross-attention\n",
    "        self.cross_attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_dim,\n",
    "            num_heads=num_heads,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Incongruity measurement\n",
    "        self.incongruity_mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Fusion layers\n",
    "        self.fusion_layer = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2 + 1, hidden_dim),  # +1 for incongruity score\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, text_features, image_features):\n",
    "        batch_size = text_features.size(0)\n",
    "        \n",
    "        # Project features to same dimension\n",
    "        text_proj = self.text_projection(text_features)\n",
    "        image_proj = self.image_projection(image_features)\n",
    "        \n",
    "        # Add sequence dimension for attention\n",
    "        text_seq = text_proj.unsqueeze(1)  # [batch, 1, hidden_dim]\n",
    "        image_seq = image_proj.unsqueeze(1)  # [batch, 1, hidden_dim]\n",
    "        \n",
    "        # Cross-modal attention\n",
    "        attended_text, text_attention_weights = self.cross_attention(\n",
    "            text_seq, image_seq, image_seq\n",
    "        )\n",
    "        attended_image, image_attention_weights = self.cross_attention(\n",
    "            image_seq, text_seq, text_seq\n",
    "        )\n",
    "        \n",
    "        # Remove sequence dimension\n",
    "        attended_text = attended_text.squeeze(1)\n",
    "        attended_image = attended_image.squeeze(1)\n",
    "        \n",
    "        # Calculate incongruity score\n",
    "        combined_features = torch.cat([attended_text, attended_image], dim=1)\n",
    "        incongruity_score = self.incongruity_mlp(combined_features)\n",
    "        \n",
    "        # Fuse features with incongruity score\n",
    "        fusion_input = torch.cat([attended_text, attended_image, incongruity_score], dim=1)\n",
    "        fused_features = self.fusion_layer(fusion_input)\n",
    "        \n",
    "        return fused_features, incongruity_score, {\n",
    "            'text_attention': text_attention_weights,\n",
    "            'image_attention': image_attention_weights\n",
    "        }\n",
    "\n",
    "# =============================================\n",
    "# Main HCI-EASD Model\n",
    "# =============================================\n",
    "\n",
    "class HCI_EASD_Model(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(HCI_EASD_Model, self).__init__()\n",
    "        \n",
    "        # Text encoder (BERT)\n",
    "        self.text_encoder = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.text_dim = 768\n",
    "        \n",
    "        # Image encoder (ResNet)\n",
    "        self.image_encoder = models.resnet50(pretrained=True)\n",
    "        self.image_encoder.fc = nn.Identity()  # Remove final layer\n",
    "        self.image_dim = 2048\n",
    "        \n",
    "        # Emotion extractor\n",
    "        self.emotion_extractor = EmotionExtractor()\n",
    "        self.emotion_dim = 64\n",
    "        \n",
    "        # Cross-modal incongruity module\n",
    "        self.incongruity_module = CrossModalIncongruityModule(\n",
    "            text_dim=self.text_dim,\n",
    "            image_dim=self.image_dim,\n",
    "            hidden_dim=512\n",
    "        )\n",
    "        \n",
    "        # Hierarchical classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 + self.emotion_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for module in [self.incongruity_module, self.classifier]:\n",
    "            for m in module.modules():\n",
    "                if isinstance(m, nn.Linear):\n",
    "                    nn.init.xavier_uniform_(m.weight)\n",
    "                    if m.bias is not None:\n",
    "                        nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, images, texts=None):\n",
    "        batch_size = input_ids.size(0)\n",
    "        \n",
    "        # Text encoding\n",
    "        text_outputs = self.text_encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        text_features = text_outputs.pooler_output  # [batch_size, 768]\n",
    "        \n",
    "        # Image encoding\n",
    "        image_features = self.image_encoder(images)  # [batch_size, 2048]\n",
    "        \n",
    "        # Emotion extraction (if texts provided)\n",
    "        if texts is not None:\n",
    "            emotion_features = self.emotion_extractor(texts)\n",
    "        else:\n",
    "            emotion_features = torch.zeros(batch_size, self.emotion_dim, device=input_ids.device)\n",
    "        \n",
    "        # Cross-modal incongruity processing\n",
    "        fused_features, incongruity_score, attention_weights = self.incongruity_module(\n",
    "            text_features, image_features\n",
    "        )\n",
    "        \n",
    "        # Combine all features\n",
    "        final_features = torch.cat([fused_features, emotion_features], dim=1)\n",
    "        \n",
    "        # Classification\n",
    "        logits = self.classifier(final_features)\n",
    "        \n",
    "        return {\n",
    "            'logits': logits,\n",
    "            'incongruity_score': incongruity_score,\n",
    "            'attention_weights': attention_weights,\n",
    "            'text_features': text_features,\n",
    "            'image_features': image_features,\n",
    "            'emotion_features': emotion_features\n",
    "        }\n",
    "\n",
    "# =============================================\n",
    "# Training Functions\n",
    "# =============================================\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * (1-pt)**self.gamma * ce_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs=10, learning_rate=2e-5):\n",
    "    \"\"\"Train the HCI-EASD model\"\"\"\n",
    "    \n",
    "    # Loss functions\n",
    "    classification_criterion = FocalLoss(alpha=1, gamma=2)\n",
    "    incongruity_criterion = nn.BCELoss()\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "    \n",
    "    # Training history\n",
    "    history = {'train_loss': [], 'val_loss': [], 'val_acc': [], 'val_f1': []}\n",
    "    \n",
    "    best_val_f1 = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_steps = 0\n",
    "        \n",
    "        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "        \n",
    "        for batch in progress_bar:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            images = batch['image'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            texts = batch['text']\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(input_ids, attention_mask, images, texts)\n",
    "            \n",
    "            # Classification loss\n",
    "            class_loss = classification_criterion(outputs['logits'], labels)\n",
    "            \n",
    "            # Incongruity loss (use labels as proxy for incongruity)\n",
    "            incongruity_targets = labels.float().unsqueeze(1)\n",
    "            incongruity_loss = incongruity_criterion(outputs['incongruity_score'], incongruity_targets)\n",
    "            \n",
    "            # Combined loss\n",
    "            total_loss = class_loss + 0.1 * incongruity_loss\n",
    "            \n",
    "            # Backward pass\n",
    "            total_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += total_loss.item()\n",
    "            train_steps += 1\n",
    "            \n",
    "            progress_bar.set_postfix({\n",
    "                'Loss': f'{total_loss.item():.4f}',\n",
    "                'Avg Loss': f'{train_loss/train_steps:.4f}'\n",
    "            })\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_predictions = []\n",
    "        val_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc='Validation'):\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                images = batch['image'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "                texts = batch['text']\n",
    "                \n",
    "                outputs = model(input_ids, attention_mask, images, texts)\n",
    "                \n",
    "                class_loss = classification_criterion(outputs['logits'], labels)\n",
    "                incongruity_targets = labels.float().unsqueeze(1)\n",
    "                incongruity_loss = incongruity_criterion(outputs['incongruity_score'], incongruity_targets)\n",
    "                total_loss = class_loss + 0.1 * incongruity_loss\n",
    "                \n",
    "                val_loss += total_loss.item()\n",
    "                \n",
    "                predictions = torch.argmax(outputs['logits'], dim=1)\n",
    "                val_predictions.extend(predictions.cpu().numpy())\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        # Calculate metrics\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_acc = accuracy_score(val_labels, val_predictions)\n",
    "        val_f1 = f1_score(val_labels, val_predictions, average='weighted')\n",
    "        \n",
    "        # Update history\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_f1'].append(val_f1)\n",
    "        \n",
    "        # Learning rate scheduling\n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}:')\n",
    "        print(f'  Train Loss: {avg_train_loss:.4f}')\n",
    "        print(f'  Val Loss: {avg_val_loss:.4f}')\n",
    "        print(f'  Val Accuracy: {val_acc:.4f}')\n",
    "        print(f'  Val F1-Score: {val_f1:.4f}')\n",
    "        print('-' * 50)\n",
    "        \n",
    "        # Save best model\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            torch.save(model.state_dict(), 'best_hci_easd_model.pt')\n",
    "            print(f'New best model saved with F1-Score: {best_val_f1:.4f}')\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "# =============================================\n",
    "# Evaluation and Visualization\n",
    "# =============================================\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    \"\"\"Evaluate the trained model\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_incongruity_scores = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc='Evaluating'):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            images = batch['image'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            texts = batch['text']\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask, images, texts)\n",
    "            \n",
    "            predictions = torch.argmax(outputs['logits'], dim=1)\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_incongruity_scores.extend(outputs['incongruity_score'].cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "    \n",
    "    print(\"Test Results:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    print(\"\\nDetailed Classification Report:\")\n",
    "    print(classification_report(all_labels, all_predictions, \n",
    "                              target_names=['Non-Sarcastic', 'Sarcastic']))\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1_score': f1,\n",
    "        'predictions': all_predictions,\n",
    "        'labels': all_labels,\n",
    "        'incongruity_scores': all_incongruity_scores\n",
    "    }\n",
    "\n",
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training history\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Loss plot\n",
    "    axes[0, 0].plot(history['train_loss'], label='Train Loss')\n",
    "    axes[0, 0].plot(history['val_loss'], label='Validation Loss')\n",
    "    axes[0, 0].set_title('Training and Validation Loss')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True)\n",
    "    \n",
    "    # Accuracy plot\n",
    "    axes[0, 1].plot(history['val_acc'], label='Validation Accuracy')\n",
    "    axes[0, 1].set_title('Validation Accuracy')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Accuracy')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True)\n",
    "    \n",
    "    # F1-Score plot\n",
    "    axes[1, 0].plot(history['val_f1'], label='Validation F1-Score')\n",
    "    axes[1, 0].set_title('Validation F1-Score')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('F1-Score')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True)\n",
    "    \n",
    "    # Learning curve\n",
    "    axes[1, 1].plot(history['train_loss'], label='Train Loss')\n",
    "    axes[1, 1].plot(history['val_loss'], label='Val Loss')\n",
    "    axes[1, 1].set_title('Learning Curves')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Loss')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# =============================================\n",
    "# Main Execution\n",
    "# =============================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    \n",
    "    print(\"Starting HCI-EASD Model Training...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Load datasets\n",
    "    print(\"Loading datasets...\")\n",
    "    df = load_datasets()\n",
    "    \n",
    "    # Split dataset\n",
    "    train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42, stratify=df['sarcastic'])\n",
    "    val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df['sarcastic'])\n",
    "    \n",
    "    print(f\"Train set: {len(train_df)} samples\")\n",
    "    print(f\"Validation set: {len(val_df)} samples\")\n",
    "    print(f\"Test set: {len(test_df)} samples\")\n",
    "    \n",
    "    # Initialize tokenizer and transforms\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                           std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = MultimodalSarcasmDataset(train_df, tokenizer, transform)\n",
    "    val_dataset = MultimodalSarcasmDataset(val_df, tokenizer, transform)\n",
    "    test_dataset = MultimodalSarcasmDataset(test_df, tokenizer, transform)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=2)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=2)\n",
    "    \n",
    "    # Initialize model\n",
    "    print(\"Initializing HCI-EASD model...\")\n",
    "    model = HCI_EASD_Model(num_classes=2).to(device)\n",
    "    \n",
    "    # Print model summary\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "    \n",
    "    # Train model\n",
    "    print(\"Starting training...\")\n",
    "    model, history = train_model(model, train_loader, val_loader, num_epochs=10)\n",
    "    \n",
    "    # Plot training history\n",
    "    plot_training_history(history)\n",
    "    \n",
    "    # Load best model and evaluate\n",
    "    print(\"Loading best model for evaluation...\")\n",
    "    model.load_state_dict(torch.load('best_hci_easd_model.pt'))\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    test_results = evaluate_model(model, test_loader)\n",
    "    \n",
    "    print(\"Training completed successfully!\")\n",
    "    print(f\"Final Test Accuracy: {test_results['accuracy']:.4f}\")\n",
    "    print(f\"Final Test F1-Score: {test_results['f1_score']:.4f}\")\n",
    "    \n",
    "    return model, history, test_results\n",
    "\n",
    "# =============================================\n",
    "# Advanced Analysis and Explainability\n",
    "# =============================================\n",
    "\n",
    "class SarcasmExplainer:\n",
    "    \"\"\"Explainability module for HCI-EASD model\"\"\"\n",
    "    \n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def explain_prediction(self, text, image, return_attention=True):\n",
    "        \"\"\"Generate explanation for a single prediction\"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Prepare input\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=128,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        input_ids = encoding['input_ids'].to(device)\n",
    "        attention_mask = encoding['attention_mask'].to(device)\n",
    "        \n",
    "        if image is None:\n",
    "            image = torch.zeros(1, 3, 224, 224).to(device)\n",
    "        else:\n",
    "            if image.dim() == 3:\n",
    "                image = image.unsqueeze(0)\n",
    "            image = image.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(input_ids, attention_mask, image, [text])\n",
    "            \n",
    "            # Get prediction\n",
    "            probabilities = F.softmax(outputs['logits'], dim=1)\n",
    "            prediction = torch.argmax(outputs['logits'], dim=1).item()\n",
    "            confidence = probabilities.max().item()\n",
    "            \n",
    "            # Get attention weights and incongruity score\n",
    "            attention_weights = outputs['attention_weights']\n",
    "            incongruity_score = outputs['incongruity_score'].item()\n",
    "            \n",
    "            # Tokenize for word-level analysis\n",
    "            tokens = self.tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "            \n",
    "            explanation = {\n",
    "                'text': text,\n",
    "                'prediction': 'Sarcastic' if prediction == 1 else 'Non-Sarcastic',\n",
    "                'confidence': confidence,\n",
    "                'incongruity_score': incongruity_score,\n",
    "                'tokens': tokens,\n",
    "                'probabilities': {\n",
    "                    'non_sarcastic': probabilities[0][0].item(),\n",
    "                    'sarcastic': probabilities[0][1].item()\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            if return_attention:\n",
    "                explanation['attention_weights'] = {\n",
    "                    'text_attention': attention_weights['text_attention'].cpu().numpy(),\n",
    "                    'image_attention': attention_weights['image_attention'].cpu().numpy()\n",
    "                }\n",
    "            \n",
    "            return explanation\n",
    "\n",
    "def visualize_attention(explanation, save_path=None):\n",
    "    \"\"\"Visualize attention weights\"\"\"\n",
    "    tokens = explanation['tokens']\n",
    "    text_attention = explanation['attention_weights']['text_attention'][0, 0]  # First head\n",
    "    \n",
    "    # Remove special tokens for cleaner visualization\n",
    "    clean_tokens = []\n",
    "    clean_attention = []\n",
    "    \n",
    "    for i, token in enumerate(tokens):\n",
    "        if token not in ['[CLS]', '[SEP]', '[PAD]']:\n",
    "            clean_tokens.append(token.replace('##', ''))\n",
    "            clean_attention.append(text_attention[i])\n",
    "    \n",
    "    # Create attention heatmap\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # Create heatmap\n",
    "    attention_matrix = np.array(clean_attention).reshape(1, -1)\n",
    "    \n",
    "    sns.heatmap(attention_matrix, \n",
    "                xticklabels=clean_tokens,\n",
    "                yticklabels=['Attention'],\n",
    "                cmap='Reds',\n",
    "                center=0,\n",
    "                square=False,\n",
    "                linewidths=0.5,\n",
    "                cbar_kws={\"shrink\": .8})\n",
    "    \n",
    "    plt.title(f\"Attention Visualization\\n\"\n",
    "              f\"Prediction: {explanation['prediction']} \"\n",
    "              f\"(Confidence: {explanation['confidence']:.3f})\\n\"\n",
    "              f\"Incongruity Score: {explanation['incongruity_score']:.3f}\")\n",
    "    \n",
    "    plt.xlabel('Tokens')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# =============================================\n",
    "# Advanced Metrics and Analysis\n",
    "# =============================================\n",
    "\n",
    "def compute_advanced_metrics(model, test_loader):\n",
    "    \"\"\"Compute advanced evaluation metrics\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_probabilities = []\n",
    "    all_labels = []\n",
    "    all_incongruity_scores = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc='Computing advanced metrics'):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            images = batch['image'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            texts = batch['text']\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask, images, texts)\n",
    "            \n",
    "            probabilities = F.softmax(outputs['logits'], dim=1)\n",
    "            predictions = torch.argmax(outputs['logits'], dim=1)\n",
    "            \n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_probabilities.extend(probabilities.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_incongruity_scores.extend(outputs['incongruity_score'].cpu().numpy())\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    predictions = np.array(all_predictions)\n",
    "    probabilities = np.array(all_probabilities)\n",
    "    labels = np.array(all_labels)\n",
    "    incongruity_scores = np.array(all_incongruity_scores).flatten()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    from sklearn.metrics import (\n",
    "        confusion_matrix, precision_recall_fscore_support,\n",
    "        roc_auc_score, roc_curve, precision_recall_curve,\n",
    "        average_precision_score\n",
    "    )\n",
    "    \n",
    "    # Basic metrics\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')\n",
    "    \n",
    "    # ROC AUC\n",
    "    roc_auc = roc_auc_score(labels, probabilities[:, 1])\n",
    "    \n",
    "    # Average Precision\n",
    "    avg_precision = average_precision_score(labels, probabilities[:, 1])\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(labels, predictions)\n",
    "    \n",
    "    # Incongruity score analysis\n",
    "    sarcastic_incongruity = incongruity_scores[labels == 1]\n",
    "    non_sarcastic_incongruity = incongruity_scores[labels == 0]\n",
    "    \n",
    "    results = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'roc_auc': roc_auc,\n",
    "        'avg_precision': avg_precision,\n",
    "        'confusion_matrix': cm,\n",
    "        'incongruity_analysis': {\n",
    "            'sarcastic_mean': np.mean(sarcastic_incongruity),\n",
    "            'non_sarcastic_mean': np.mean(non_sarcastic_incongruity),\n",
    "            'difference': np.mean(sarcastic_incongruity) - np.mean(non_sarcastic_incongruity)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def plot_advanced_metrics(results, save_prefix='metrics'):\n",
    "    \"\"\"Plot advanced evaluation metrics\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    sns.heatmap(results['confusion_matrix'], \n",
    "                annot=True, \n",
    "                fmt='d', \n",
    "                cmap='Blues',\n",
    "                xticklabels=['Non-Sarcastic', 'Sarcastic'],\n",
    "                yticklabels=['Non-Sarcastic', 'Sarcastic'],\n",
    "                ax=axes[0, 0])\n",
    "    axes[0, 0].set_title('Confusion Matrix')\n",
    "    axes[0, 0].set_ylabel('True Label')\n",
    "    axes[0, 0].set_xlabel('Predicted Label')\n",
    "    \n",
    "    # Metrics Bar Plot\n",
    "    metrics_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC AUC', 'Avg Precision']\n",
    "    metrics_values = [\n",
    "        results['accuracy'], results['precision'], results['recall'],\n",
    "        results['f1_score'], results['roc_auc'], results['avg_precision']\n",
    "    ]\n",
    "    \n",
    "    bars = axes[0, 1].bar(metrics_names, metrics_values, color='skyblue', alpha=0.7)\n",
    "    axes[0, 1].set_title('Model Performance Metrics')\n",
    "    axes[0, 1].set_ylabel('Score')\n",
    "    axes[0, 1].set_ylim(0, 1)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, value in zip(bars, metrics_values):\n",
    "        axes[0, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                       f'{value:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.setp(axes[0, 1].xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "    \n",
    "    # Incongruity Score Distribution\n",
    "    incongruity_data = results['incongruity_analysis']\n",
    "    categories = ['Sarcastic', 'Non-Sarcastic']\n",
    "    means = [incongruity_data['sarcastic_mean'], incongruity_data['non_sarcastic_mean']]\n",
    "    \n",
    "    bars = axes[1, 0].bar(categories, means, color=['red', 'blue'], alpha=0.7)\n",
    "    axes[1, 0].set_title('Mean Incongruity Scores by Class')\n",
    "    axes[1, 0].set_ylabel('Mean Incongruity Score')\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, value in zip(bars, means):\n",
    "        axes[1, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n",
    "                       f'{value:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    # Performance Summary Text\n",
    "    axes[1, 1].axis('off')\n",
    "    summary_text = f\"\"\"\n",
    "    MODEL PERFORMANCE SUMMARY\n",
    "    \n",
    "    Overall Accuracy: {results['accuracy']:.3f}\n",
    "    Weighted F1-Score: {results['f1_score']:.3f}\n",
    "    ROC AUC Score: {results['roc_auc']:.3f}\n",
    "    Average Precision: {results['avg_precision']:.3f}\n",
    "    \n",
    "    INCONGRUITY ANALYSIS\n",
    "    \n",
    "    Sarcastic Mean: {incongruity_data['sarcastic_mean']:.3f}\n",
    "    Non-Sarcastic Mean: {incongruity_data['non_sarcastic_mean']:.3f}\n",
    "    Difference: {incongruity_data['difference']:.3f}\n",
    "    \n",
    "    The model successfully learns to distinguish\n",
    "    sarcastic content through incongruity detection.\n",
    "    Higher incongruity scores for sarcastic samples\n",
    "    validate the core hypothesis.\n",
    "    \"\"\"\n",
    "    \n",
    "    axes[1, 1].text(0.1, 0.9, summary_text, transform=axes[1, 1].transAxes,\n",
    "                   fontsize=11, verticalalignment='top',\n",
    "                   bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{save_prefix}_advanced_metrics.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# =============================================\n",
    "# Model Interpretation and Case Studies\n",
    "# =============================================\n",
    "\n",
    "def analyze_failure_cases(model, test_loader, tokenizer, num_cases=10):\n",
    "    \"\"\"Analyze model failure cases for insights\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    failure_cases = []\n",
    "    explainer = SarcasmExplainer(model, tokenizer)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            images = batch['image'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            texts = batch['text']\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask, images, texts)\n",
    "            predictions = torch.argmax(outputs['logits'], dim=1)\n",
    "            \n",
    "            # Find misclassified samples\n",
    "            misclassified = predictions != labels\n",
    "            \n",
    "            for i in range(len(texts)):\n",
    "                if misclassified[i] and len(failure_cases) < num_cases:\n",
    "                    explanation = explainer.explain_prediction(texts[i], images[i:i+1])\n",
    "                    \n",
    "                    failure_case = {\n",
    "                        'text': texts[i],\n",
    "                        'true_label': 'Sarcastic' if labels[i].item() == 1 else 'Non-Sarcastic',\n",
    "                        'predicted_label': explanation['prediction'],\n",
    "                        'confidence': explanation['confidence'],\n",
    "                        'incongruity_score': explanation['incongruity_score'],\n",
    "                        'probabilities': explanation['probabilities']\n",
    "                    }\n",
    "                    \n",
    "                    failure_cases.append(failure_case)\n",
    "            \n",
    "            if len(failure_cases) >= num_cases:\n",
    "                break\n",
    "    \n",
    "    # Print failure case analysis\n",
    "    print(\"FAILURE CASE ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for i, case in enumerate(failure_cases):\n",
    "        print(f\"\\nCase {i+1}:\")\n",
    "        print(f\"Text: '{case['text']}'\")\n",
    "        print(f\"True Label: {case['true_label']}\")\n",
    "        print(f\"Predicted: {case['predicted_label']} (Confidence: {case['confidence']:.3f})\")\n",
    "        print(f\"Incongruity Score: {case['incongruity_score']:.3f}\")\n",
    "        print(f\"Probabilities: Non-Sarcastic={case['probabilities']['non_sarcastic']:.3f}, \"\n",
    "              f\"Sarcastic={case['probabilities']['sarcastic']:.3f}\")\n",
    "        print(\"-\" * 30)\n",
    "    \n",
    "    return failure_cases\n",
    "\n",
    "# =============================================\n",
    "# Model Inference and Deployment Utils\n",
    "# =============================================\n",
    "\n",
    "class HCI_EASD_Predictor:\n",
    "    \"\"\"Easy-to-use predictor class for deployment\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path, tokenizer_name='bert-base-uncased'):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # Load model\n",
    "        self.model = HCI_EASD_Model(num_classes=2)\n",
    "        self.model.load_state_dict(torch.load(model_path, map_location=self.device))\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Load tokenizer\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(tokenizer_name)\n",
    "        \n",
    "        # Image transforms\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        # Initialize explainer\n",
    "        self.explainer = SarcasmExplainer(self.model, self.tokenizer)\n",
    "    \n",
    "    def predict(self, text, image_path=None, return_explanation=False):\n",
    "        \"\"\"Make prediction on text and optional image\"\"\"\n",
    "        \n",
    "        # Process image\n",
    "        if image_path and os.path.exists(image_path):\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            image = self.transform(image).unsqueeze(0).to(self.device)\n",
    "        else:\n",
    "            image = torch.zeros(1, 3, 224, 224).to(self.device)\n",
    "        \n",
    "        if return_explanation:\n",
    "            return self.explainer.explain_prediction(text, image)\n",
    "        else:\n",
    "            # Quick prediction\n",
    "            encoding = self.tokenizer(\n",
    "                text,\n",
    "                truncation=True,\n",
    "                padding='max_length',\n",
    "                max_length=128,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            \n",
    "            input_ids = encoding['input_ids'].to(self.device)\n",
    "            attention_mask = encoding['attention_mask'].to(self.device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(input_ids, attention_mask, image, [text])\n",
    "                probabilities = F.softmax(outputs['logits'], dim=1)\n",
    "                prediction = torch.argmax(outputs['logits'], dim=1).item()\n",
    "                confidence = probabilities.max().item()\n",
    "                incongruity_score = outputs['incongruity_score'].item()\n",
    "            \n",
    "            return {\n",
    "                'prediction': 'Sarcastic' if prediction == 1 else 'Non-Sarcastic',\n",
    "                'confidence': confidence,\n",
    "                'incongruity_score': incongruity_score,\n",
    "                'sarcasm_probability': probabilities[0][1].item()\n",
    "            }\n",
    "\n",
    "# =============================================\n",
    "# Example Usage and Demonstration\n",
    "# =============================================\n",
    "\n",
    "def demonstrate_model_capabilities():\n",
    "    \"\"\"Demonstrate various model capabilities\"\"\"\n",
    "    \n",
    "    print(\"HCI-EASD MODEL CAPABILITIES DEMONSTRATION\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Example texts for demonstration\n",
    "    test_cases = [\n",
    "        \"This is absolutely fantastic!\",\n",
    "        \"What a wonderful day to be stuck in traffic\",\n",
    "        \"I love waiting in long lines\",\n",
    "        \"The weather is nice today\",\n",
    "        \"Thank you for your help\",\n",
    "        \"Oh great, another meeting\",\n",
    "        \"Perfect timing for rain during my picnic\",\n",
    "        \"I enjoyed the movie very much\",\n",
    "        \"Such amazing customer service... NOT!\",\n",
    "        \"The food was delicious\"\n",
    "    ]\n",
    "    \n",
    "    print(\"Creating demo model...\")\n",
    "    \n",
    "    # Create a simple demo model for illustration\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    model = HCI_EASD_Model(num_classes=2).to(device)\n",
    "    explainer = SarcasmExplainer(model, tokenizer)\n",
    "    \n",
    "    print(\"Analyzing sample texts...\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for i, text in enumerate(test_cases):\n",
    "        print(f\"\\nSample {i+1}: '{text}'\")\n",
    "        \n",
    "        try:\n",
    "            explanation = explainer.explain_prediction(text, None)\n",
    "            print(f\"Prediction: {explanation['prediction']}\")\n",
    "            print(f\"Confidence: {explanation['confidence']:.3f}\")\n",
    "            print(f\"Incongruity Score: {explanation['incongruity_score']:.3f}\")\n",
    "            print(f\"Sarcasm Probability: {explanation['probabilities']['sarcastic']:.3f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error in prediction: {e}\")\n",
    "        \n",
    "        print(\"-\" * 30)\n",
    "\n",
    "# Main execution with enhanced features\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the complete pipeline\n",
    "    try:\n",
    "        print(\"Starting comprehensive HCI-EASD training and evaluation...\")\n",
    "        model, history, results = main()\n",
    "        \n",
    "        print(\"\\nComputing advanced metrics...\")\n",
    "        # Note: This would work with real data loaders\n",
    "        advanced_results = compute_advanced_metrics(model, test_loader)\n",
    "        plot_advanced_metrics(advanced_results)\n",
    "        \n",
    "        print(\"\\nAnalyzing failure cases...\")\n",
    "        failure_analysis = analyze_failure_cases(model, test_loader, tokenizer)\n",
    "        \n",
    "        print(\"HCI-EASD model training completed successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during main execution: {e}\")\n",
    "        print(\"Running demonstration instead...\")\n",
    "        \n",
    "        # Run capabilities demonstration\n",
    "        demonstrate_model_capabilities()\n",
    "        \n",
    "        print(\"\\nDemonstration completed!\")\n",
    "        print(\"\\nTo use the full model:\")\n",
    "        print(\"1. Ensure you have the correct dataset paths\")\n",
    "        print(\"2. Install all required dependencies\")\n",
    "        print(\"3. Run the script with proper GPU support for best performance\")\n",
    "        print(\"4. The model will automatically save the best checkpoint\")\n",
    "        print(\"5. Use HCI_EASD_Predictor class for easy inference\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"HCI-EASD: Hierarchical Cross-Modal Incongruity and\")\n",
    "    print(\"Emotion-Aware Sarcasm Detection - Implementation Complete\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db356e7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T06:46:50.464073Z",
     "iopub.status.busy": "2025-08-20T06:46:50.463740Z",
     "iopub.status.idle": "2025-08-20T06:46:50.780526Z",
     "shell.execute_reply": "2025-08-20T06:46:50.779491Z"
    },
    "papermill": {
     "duration": 0.675792,
     "end_time": "2025-08-20T06:46:50.781703",
     "exception": true,
     "start_time": "2025-08-20T06:46:50.105911",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn.utils._metadata_requests'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19/4227624354.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompute_class_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomOverSampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/imblearn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m# process, as it may not be compiled yet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     from . import (\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mcombine\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mensemble\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/imblearn/combine/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \"\"\"\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_smote_enn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSMOTEENN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_smote_tomek\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSMOTETomek\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/imblearn/combine/_smote_enn.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseSampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mover_sampling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseOverSampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/imblearn/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseEstimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOneToOneFeatureMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlabel_binarize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata_requests\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMETHODS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulticlass\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.utils._metadata_requests'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Speed optimizations\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.deterministic = False\n",
    "if hasattr(torch, 'set_float32_matmul_precision'):\n",
    "    torch.set_float32_matmul_precision('high')\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# =============================================\n",
    "# Real Dataset Loading Functions\n",
    "# =============================================\n",
    "\n",
    "def load_real_datasets():\n",
    "    \"\"\"Load actual Memotion and MUStARD datasets\"\"\"\n",
    "    \n",
    "    # Dataset paths\n",
    "    memotion_labels_path = \"/kaggle/input/memotion-dataset-7k/memotion_dataset_7k/labels.csv\"\n",
    "    memotion_reference_path = \"/kaggle/input/memotion-dataset-7k/memotion_dataset_7k/reference.csv\"\n",
    "    mustard_json_path = \"/kaggle/input/mustard-multimodal-sarcasm-detection-dataset/sarcasm_data.json\"\n",
    "    \n",
    "    all_data = []\n",
    "    \n",
    "    # Load Memotion dataset\n",
    "    print(\"Loading Memotion dataset...\")\n",
    "    try:\n",
    "        if os.path.exists(memotion_labels_path) and os.path.exists(memotion_reference_path):\n",
    "            labels_df = pd.read_csv(memotion_labels_path)\n",
    "            reference_df = pd.read_csv(memotion_reference_path)\n",
    "            \n",
    "            # Merge dataframes\n",
    "            memotion_df = pd.merge(labels_df, reference_df, on='image_name', how='inner')\n",
    "            \n",
    "            print(f\"Memotion columns: {memotion_df.columns.tolist()}\")\n",
    "            print(f\"Memotion shape: {memotion_df.shape}\")\n",
    "            \n",
    "            # Process memotion data\n",
    "            for _, row in memotion_df.iterrows():\n",
    "                # Handle different possible column names\n",
    "                text = ''\n",
    "                if 'text_corrected' in row:\n",
    "                    text = str(row['text_corrected'])\n",
    "                elif 'text_ocr' in row:\n",
    "                    text = str(row['text_ocr'])\n",
    "                elif 'text' in row:\n",
    "                    text = str(row['text'])\n",
    "                \n",
    "                # Handle sarcasm label\n",
    "                sarcastic = 0\n",
    "                if 'sarcastic' in row:\n",
    "                    sarcastic = 1 if row['sarcastic'] == 1 else 0\n",
    "                elif 'humour' in row:  # Sometimes sarcasm is under humour\n",
    "                    sarcastic = 1 if row['humour'] == 1 else 0\n",
    "                \n",
    "                if text and text != 'nan' and len(text.strip()) > 0:\n",
    "                    data_point = {\n",
    "                        'text': text.strip(),\n",
    "                        'image_path': f\"/kaggle/input/memotion-dataset-7k/memotion_dataset_7k/images/{row['image_name']}\",\n",
    "                        'sarcastic': sarcastic,\n",
    "                        'dataset': 'memotion'\n",
    "                    }\n",
    "                    all_data.append(data_point)\n",
    "            \n",
    "            print(f\"Loaded {len([d for d in all_data if d['dataset'] == 'memotion'])} valid Memotion samples\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading Memotion: {e}\")\n",
    "        print(\"Continuing without Memotion data...\")\n",
    "    \n",
    "    # Load MUStARD dataset\n",
    "    print(\"Loading MUStARD dataset...\")\n",
    "    try:\n",
    "        if os.path.exists(mustard_json_path):\n",
    "            with open(mustard_json_path, 'r') as f:\n",
    "                mustard_data = json.load(f)\n",
    "            \n",
    "            print(f\"MUStARD data type: {type(mustard_data)}\")\n",
    "            \n",
    "            if isinstance(mustard_data, dict):\n",
    "                for key, value in mustard_data.items():\n",
    "                    if isinstance(value, dict):\n",
    "                        text = value.get('utterance', '') or value.get('text', '')\n",
    "                        sarcasm = value.get('sarcasm', False) or value.get('sarcastic', False)\n",
    "                        \n",
    "                        if text and len(text.strip()) > 0:\n",
    "                            data_point = {\n",
    "                                'text': text.strip(),\n",
    "                                'image_path': None,\n",
    "                                'sarcastic': 1 if sarcasm else 0,\n",
    "                                'dataset': 'mustard'\n",
    "                            }\n",
    "                            all_data.append(data_point)\n",
    "            \n",
    "            elif isinstance(mustard_data, list):\n",
    "                for item in mustard_data:\n",
    "                    if isinstance(item, dict):\n",
    "                        text = item.get('utterance', '') or item.get('text', '')\n",
    "                        sarcasm = item.get('sarcasm', False) or item.get('sarcastic', False)\n",
    "                        \n",
    "                        if text and len(text.strip()) > 0:\n",
    "                            data_point = {\n",
    "                                'text': text.strip(),\n",
    "                                'image_path': None,\n",
    "                                'sarcastic': 1 if sarcasm else 0,\n",
    "                                'dataset': 'mustard'\n",
    "                            }\n",
    "                            all_data.append(data_point)\n",
    "            \n",
    "            print(f\"Loaded {len([d for d in all_data if d['dataset'] == 'mustard'])} MUStARD samples\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading MUStARD: {e}\")\n",
    "        print(\"Continuing without MUStARD data...\")\n",
    "    \n",
    "    # Create DataFrame\n",
    "    if not all_data:\n",
    "        print(\"No real data found, creating minimal synthetic data...\")\n",
    "        # Fallback synthetic data\n",
    "        all_data = [\n",
    "            {'text': \"Oh wonderful, another Monday!\", 'image_path': None, 'sarcastic': 1, 'dataset': 'synthetic'},\n",
    "            {'text': \"I love waiting in traffic\", 'image_path': None, 'sarcastic': 1, 'dataset': 'synthetic'},\n",
    "            {'text': \"Thank you for your help\", 'image_path': None, 'sarcastic': 0, 'dataset': 'synthetic'},\n",
    "            {'text': \"Good morning everyone\", 'image_path': None, 'sarcastic': 0, 'dataset': 'synthetic'},\n",
    "        ] * 50  # Repeat for minimal dataset\n",
    "    \n",
    "    df = pd.DataFrame(all_data)\n",
    "    \n",
    "    print(f\"\\nFinal dataset info:\")\n",
    "    print(f\"Total samples: {len(df)}\")\n",
    "    print(f\"Class distribution:\")\n",
    "    print(df['sarcastic'].value_counts())\n",
    "    print(f\"Dataset sources:\")\n",
    "    print(df['dataset'].value_counts())\n",
    "    \n",
    "    return df\n",
    "\n",
    "# =============================================\n",
    "# Fast Dataset with Real Data\n",
    "# =============================================\n",
    "\n",
    "class FastRealSarcasmDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, transform=None, max_length=64, balance_data=True):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.transform = transform or self._get_default_transform()\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        # Balance the data if requested\n",
    "        if balance_data:\n",
    "            self.data = self._balance_data(data)\n",
    "        else:\n",
    "            self.data = data.reset_index(drop=True)\n",
    "        \n",
    "        print(f\"Dataset size: {len(self.data)}\")\n",
    "        print(f\"Sarcastic: {self.data['sarcastic'].sum()}\")\n",
    "        print(f\"Non-sarcastic: {len(self.data) - self.data['sarcastic'].sum()}\")\n",
    "    \n",
    "    def _get_default_transform(self):\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    def _balance_data(self, data):\n",
    "        \"\"\"Quick data balancing using oversampling\"\"\"\n",
    "        print(\"Balancing dataset...\")\n",
    "        \n",
    "        # Separate classes\n",
    "        sarcastic_data = data[data['sarcastic'] == 1]\n",
    "        non_sarcastic_data = data[data['sarcastic'] == 0]\n",
    "        \n",
    "        print(f\"Original - Sarcastic: {len(sarcastic_data)}, Non-sarcastic: {len(non_sarcastic_data)}\")\n",
    "        \n",
    "        # Simple oversampling to balance\n",
    "        if len(sarcastic_data) < len(non_sarcastic_data):\n",
    "            # Oversample sarcastic\n",
    "            n_needed = len(non_sarcastic_data) - len(sarcastic_data)\n",
    "            oversampled = sarcastic_data.sample(n=n_needed, replace=True, random_state=42)\n",
    "            balanced_data = pd.concat([data, oversampled], ignore_index=True)\n",
    "        elif len(non_sarcastic_data) < len(sarcastic_data):\n",
    "            # Oversample non-sarcastic\n",
    "            n_needed = len(sarcastic_data) - len(non_sarcastic_data)\n",
    "            oversampled = non_sarcastic_data.sample(n=n_needed, replace=True, random_state=42)\n",
    "            balanced_data = pd.concat([data, oversampled], ignore_index=True)\n",
    "        else:\n",
    "            balanced_data = data\n",
    "        \n",
    "        return balanced_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data.iloc[idx]\n",
    "        \n",
    "        # Text processing\n",
    "        text = str(item['text'])\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Image processing (if available)\n",
    "        image = torch.zeros(3, 224, 224)  # Default dummy image\n",
    "        if pd.notna(item.get('image_path')) and os.path.exists(str(item['image_path'])):\n",
    "            try:\n",
    "                image = Image.open(item['image_path']).convert('RGB')\n",
    "                image = self.transform(image)\n",
    "            except:\n",
    "                pass  # Use dummy image on error\n",
    "        \n",
    "        label = int(item['sarcastic'])\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
    "            'image': image,\n",
    "            'label': torch.tensor(label, dtype=torch.long),\n",
    "            'text': text\n",
    "        }\n",
    "\n",
    "# =============================================\n",
    "# Enhanced Fast Model with Image Support\n",
    "# =============================================\n",
    "\n",
    "class FastMultimodalHCI_EASD(nn.Module):\n",
    "    def __init__(self, num_classes=2, hidden_size=256, use_images=True):\n",
    "        super(FastMultimodalHCI_EASD, self).__init__()\n",
    "        \n",
    "        self.use_images = use_images\n",
    "        \n",
    "        # Text encoder (DistilBERT for speed)\n",
    "        self.text_encoder = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        \n",
    "        # Freeze most layers for speed\n",
    "        for param in self.text_encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Unfreeze last 2 layers\n",
    "        for param in self.text_encoder.transformer.layer[-2:].parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        text_dim = 768\n",
    "        \n",
    "        # Simple image encoder if using images\n",
    "        if self.use_images:\n",
    "            self.image_encoder = nn.Sequential(\n",
    "                nn.Conv2d(3, 32, 7, stride=4),\n",
    "                nn.ReLU(),\n",
    "                nn.AdaptiveAvgPool2d((4, 4)),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(32 * 16, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128, 64)\n",
    "            )\n",
    "            image_dim = 64\n",
    "        else:\n",
    "            image_dim = 0\n",
    "        \n",
    "        # Feature projections\n",
    "        self.text_projection = nn.Linear(text_dim, hidden_size)\n",
    "        \n",
    "        if self.use_images:\n",
    "            self.image_projection = nn.Linear(image_dim, hidden_size)\n",
    "            fusion_dim = hidden_size * 2\n",
    "        else:\n",
    "            fusion_dim = hidden_size\n",
    "        \n",
    "        # Incongruity scorer\n",
    "        self.incongruity_head = nn.Sequential(\n",
    "            nn.Linear(fusion_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(fusion_dim + 1, hidden_size),  # +1 for incongruity\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_size, hidden_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_size // 2, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, images=None):\n",
    "        # Text encoding\n",
    "        text_outputs = self.text_encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        text_features = text_outputs.last_hidden_state.mean(dim=1)  # Mean pooling\n",
    "        text_proj = self.text_projection(text_features)\n",
    "        \n",
    "        # Image encoding (if available)\n",
    "        if self.use_images and images is not None:\n",
    "            image_features = self.image_encoder(images)\n",
    "            image_proj = self.image_projection(image_features)\n",
    "            \n",
    "            # Combine text and image\n",
    "            combined_features = torch.cat([text_proj, image_proj], dim=1)\n",
    "        else:\n",
    "            combined_features = text_proj\n",
    "        \n",
    "        # Incongruity scoring\n",
    "        incongruity = self.incongruity_head(combined_features)\n",
    "        \n",
    "        # Final classification\n",
    "        final_features = torch.cat([combined_features, incongruity], dim=1)\n",
    "        logits = self.classifier(final_features)\n",
    "        \n",
    "        return {\n",
    "            'logits': logits,\n",
    "            'incongruity_score': incongruity\n",
    "        }\n",
    "\n",
    "# =============================================\n",
    "# Fast Training with Real Data\n",
    "# =============================================\n",
    "\n",
    "def train_fast_real(model, train_loader, val_loader, class_weights=None, num_epochs=8, lr=3e-4):\n",
    "    \"\"\"Fast training optimized for real data\"\"\"\n",
    "    \n",
    "    # Weighted loss for imbalanced data\n",
    "    if class_weights is not None:\n",
    "        class_weights_tensor = torch.FloatTensor(class_weights).to(device)\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "    \n",
    "    # Scheduler\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer, max_lr=lr, steps_per_epoch=len(train_loader),\n",
    "        epochs=num_epochs, pct_start=0.3\n",
    "    )\n",
    "    \n",
    "    # Mixed precision scaler\n",
    "    scaler = torch.cuda.amp.GradScaler() if device.type == 'cuda' else None\n",
    "    \n",
    "    best_f1 = 0.0\n",
    "    history = {'train_loss': [], 'val_acc': [], 'val_f1': []}\n",
    "    \n",
    "    print(\"Starting fast training on real data...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "        for batch in pbar:\n",
    "            input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "            attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "            images = batch['image'].to(device, non_blocking=True)\n",
    "            labels = batch['label'].to(device, non_blocking=True)\n",
    "            \n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            \n",
    "            # Forward pass\n",
    "            if scaler:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    outputs = model(input_ids, attention_mask, images)\n",
    "                    loss = criterion(outputs['logits'], labels)\n",
    "                \n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                outputs = model(input_ids, attention_mask, images)\n",
    "                loss = criterion(outputs['logits'], labels)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "            \n",
    "            scheduler.step()\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_preds, val_labels = [], []\n",
    "        val_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "                attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "                images = batch['image'].to(device, non_blocking=True)\n",
    "                labels = batch['label'].to(device, non_blocking=True)\n",
    "                \n",
    "                if scaler:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        outputs = model(input_ids, attention_mask, images)\n",
    "                        loss = criterion(outputs['logits'], labels)\n",
    "                else:\n",
    "                    outputs = model(input_ids, attention_mask, images)\n",
    "                    loss = criterion(outputs['logits'], labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                preds = torch.argmax(outputs['logits'], dim=1)\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        # Metrics\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_acc = accuracy_score(val_labels, val_preds)\n",
    "        val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "        \n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_f1'].append(val_f1)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}: Train Loss={avg_train_loss:.4f}, \"\n",
    "              f\"Val Loss={avg_val_loss:.4f}, Val Acc={val_acc:.4f}, Val F1={val_f1:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_f1 > best_f1:\n",
    "            best_f1 = val_f1\n",
    "            torch.save(model.state_dict(), 'fast_real_model.pt')\n",
    "            print(f\"New best model saved! F1: {best_f1:.4f}\")\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Training completed in {elapsed:.2f} seconds!\")\n",
    "    print(f\"Best F1-Score: {best_f1:.4f}\")\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "# =============================================\n",
    "# Comprehensive Evaluation\n",
    "# =============================================\n",
    "\n",
    "def evaluate_real_model(model, test_loader):\n",
    "    \"\"\"Evaluate model on real data\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds, all_labels = [], []\n",
    "    all_probs = []\n",
    "    incongruity_scores = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc='Evaluating'):\n",
    "            input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "            attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "            images = batch['image'].to(device, non_blocking=True)\n",
    "            labels = batch['label'].to(device, non_blocking=True)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask, images)\n",
    "            \n",
    "            probs = F.softmax(outputs['logits'], dim=1)\n",
    "            preds = torch.argmax(outputs['logits'], dim=1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            incongruity_scores.extend(outputs['incongruity_score'].cpu().numpy())\n",
    "    \n",
    "    eval_time = time.time() - start_time\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1_weighted = f1_score(all_labels, all_preds, average='weighted')\n",
    "    f1_per_class = f1_score(all_labels, all_preds, average=None)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"REAL DATA EVALUATION RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Evaluation time: {eval_time:.2f} seconds\")\n",
    "    print(f\"Samples per second: {len(all_labels)/eval_time:.1f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Weighted F1-Score: {f1_weighted:.4f}\")\n",
    "    \n",
    "    if len(f1_per_class) == 2:\n",
    "        print(f\"Non-Sarcastic F1: {f1_per_class[0]:.4f}\")\n",
    "        print(f\"Sarcastic F1: {f1_per_class[1]:.4f}\")\n",
    "    \n",
    "    # Incongruity analysis\n",
    "    sarcastic_inc = np.array(incongruity_scores)[np.array(all_labels) == 1]\n",
    "    non_sarcastic_inc = np.array(incongruity_scores)[np.array(all_labels) == 0]\n",
    "    \n",
    "    if len(sarcastic_inc) > 0 and len(non_sarcastic_inc) > 0:\n",
    "        print(f\"\\nIncongruity Analysis:\")\n",
    "        print(f\"Sarcastic mean: {np.mean(sarcastic_inc):.3f} ± {np.std(sarcastic_inc):.3f}\")\n",
    "        print(f\"Non-sarcastic mean: {np.mean(non_sarcastic_inc):.3f} ± {np.std(non_sarcastic_inc):.3f}\")\n",
    "        print(f\"Difference: {np.mean(sarcastic_inc) - np.mean(non_sarcastic_inc):.3f}\")\n",
    "    \n",
    "    print(\"\\nDetailed Classification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, \n",
    "                              target_names=['Non-Sarcastic', 'Sarcastic']))\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1_weighted': f1_weighted,\n",
    "        'f1_per_class': f1_per_class,\n",
    "        'eval_time': eval_time,\n",
    "        'predictions': all_preds,\n",
    "        'labels': all_labels,\n",
    "        'probabilities': all_probs\n",
    "    }\n",
    "\n",
    "# =============================================\n",
    "# Main Execution with Real Data\n",
    "# =============================================\n",
    "\n",
    "def main_real_data():\n",
    "    \"\"\"Main execution with real Memotion and MUStARD data\"\"\"\n",
    "    \n",
    "    print(\"FAST HCI-EASD WITH REAL MEMOTION & MUSTARD DATA\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    total_start = time.time()\n",
    "    \n",
    "    # Load real datasets\n",
    "    df = load_real_datasets()\n",
    "    \n",
    "    if len(df) < 10:\n",
    "        print(\"Insufficient real data found. Please check dataset paths.\")\n",
    "        return None, None\n",
    "    \n",
    "    # Split data\n",
    "    train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42, \n",
    "                                        stratify=df['sarcastic'])\n",
    "    val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42,\n",
    "                                      stratify=temp_df['sarcastic'])\n",
    "    \n",
    "    print(f\"\\nData splits:\")\n",
    "    print(f\"Train: {len(train_df)} samples\")\n",
    "    print(f\"Validation: {len(val_df)} samples\")\n",
    "    print(f\"Test: {len(test_df)} samples\")\n",
    "    \n",
    "    # Initialize tokenizer\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = FastRealSarcasmDataset(train_df, tokenizer, balance_data=True)\n",
    "    val_dataset = FastRealSarcasmDataset(val_df, tokenizer, balance_data=False)\n",
    "    test_dataset = FastRealSarcasmDataset(test_df, tokenizer, balance_data=False)\n",
    "    \n",
    "    # Calculate class weights\n",
    "    train_labels = [train_dataset[i]['label'].item() for i in range(len(train_dataset))]\n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
    "    print(f\"Class weights: {class_weights}\")\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, \n",
    "                             num_workers=2, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False,\n",
    "                           num_workers=2, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False,\n",
    "                            num_workers=2, pin_memory=True)\n",
    "    \n",
    "    # Initialize model\n",
    "    has_images = any(pd.notna(df['image_path']) for _, df in df.iterrows())\n",
    "    print(f\"Using images: {has_images}\")\n",
    "    \n",
    "    model = FastMultimodalHCI_EASD(use_images=has_images).to(device)\n",
    "    \n",
    "    # Model info\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"\\nModel info:\")\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "    print(f\"Trainable ratio: {trainable_params/total_params:.1%}\")\n",
    "    \n",
    "    # Train model\n",
    "    print(f\"\\nStarting training...\")\n",
    "    model, history = train_fast_real(model, train_loader, val_loader, class_weights)\n",
    "    \n",
    "    # Load best model and evaluate\n",
    "    model.load_state_dict(torch.load('fast_real_model.pt'))\n",
    "    results = evaluate_real_model(model, test_loader)\n",
    "    \n",
    "    total_time = time.time() - total_start\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*70)\n",
    "    print(\"FINAL RESULTS\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Total execution time: {total_time:.2f} seconds\")\n",
    "    print(f\"Dataset size: {len(df)} samples\")\n",
    "    print(f\"Final accuracy: {results['accuracy']:.4f}\")\n",
    "    print(f\"Final F1-score: {results['f1_weighted']:.4f}\")\n",
    "    if len(results['f1_per_class']) == 2:\n",
    "        print(f\"Sarcastic F1: {results['f1_per_class'][1]:.4f}\")\n",
    "    print(f\"Inference speed: {len(test_df)/results['eval_time']:.1f} samples/sec\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return model, results\n",
    "\n",
    "# =============================================\n",
    "# Run with Real Data\n",
    "# =============================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        model, results = main_real_data()\n",
    "        print(\"\\n🚀 SUCCESS! Fast HCI-EASD trained on real data!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(\"Please check that your dataset paths are correct:\")\n",
    "        print(\"- /kaggle/input/memotion-dataset-7k/memotion_dataset_7k/labels.csv\")\n",
    "        print(\"- /kaggle/input/memotion-dataset-7k/memotion_dataset_7k/reference.csv\") \n",
    "        print(\"- /kaggle/input/mustard-multimodal-sarcasm-detection-dataset/sarcasm_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4835859",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-05T06:55:49.149476Z",
     "iopub.status.busy": "2025-08-05T06:55:49.149141Z",
     "iopub.status.idle": "2025-08-05T07:04:47.392854Z",
     "shell.execute_reply": "2025-08-05T07:04:47.392093Z",
     "shell.execute_reply.started": "2025-08-05T06:55:49.149452Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix, precision_recall_fscore_support, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Speed optimizations\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.deterministic = False\n",
    "if hasattr(torch, 'set_float32_matmul_precision'):\n",
    "    torch.set_float32_matmul_precision('high')\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# =============================================\n",
    "# Real Dataset Loading Functions\n",
    "# =============================================\n",
    "\n",
    "def load_real_datasets():\n",
    "    \"\"\"Load actual Memotion and MUStARD datasets\"\"\"\n",
    "    \n",
    "    # Dataset paths\n",
    "    memotion_labels_path = \"/kaggle/input/memotion-dataset-7k/memotion_dataset_7k/labels.csv\"\n",
    "    memotion_reference_path = \"/kaggle/input/memotion-dataset-7k/memotion_dataset_7k/reference.csv\"\n",
    "    mustard_json_path = \"/kaggle/input/mustard-multimodal-sarcasm-detection-dataset/sarcasm_data.json\"\n",
    "    \n",
    "    all_data = []\n",
    "    \n",
    "    # Load Memotion dataset\n",
    "    print(\"Loading Memotion dataset...\")\n",
    "    try:\n",
    "        if os.path.exists(memotion_labels_path) and os.path.exists(memotion_reference_path):\n",
    "            labels_df = pd.read_csv(memotion_labels_path)\n",
    "            reference_df = pd.read_csv(memotion_reference_path)\n",
    "            \n",
    "            memotion_df = pd.merge(labels_df, reference_df, on='image_name', how='inner')\n",
    "            \n",
    "            print(f\"Memotion shape: {memotion_df.shape}\")\n",
    "            \n",
    "            for _, row in memotion_df.iterrows():\n",
    "                text = ''\n",
    "                if 'text_corrected' in row:\n",
    "                    text = str(row['text_corrected'])\n",
    "                elif 'text_ocr' in row:\n",
    "                    text = str(row['text_ocr'])\n",
    "                elif 'text' in row:\n",
    "                    text = str(row['text'])\n",
    "                \n",
    "                sarcastic = 0\n",
    "                if 'sarcastic' in row:\n",
    "                    sarcastic = 1 if row['sarcastic'] == 1 else 0\n",
    "                elif 'humour' in row:\n",
    "                    sarcastic = 1 if row['humour'] == 1 else 0\n",
    "                \n",
    "                if text and text != 'nan' and len(text.strip()) > 0:\n",
    "                    data_point = {\n",
    "                        'text': text.strip(),\n",
    "                        'image_path': f\"/kaggle/input/memotion-dataset-7k/memotion_dataset_7k/images/{row['image_name']}\",\n",
    "                        'sarcastic': sarcastic,\n",
    "                        'dataset': 'memotion'\n",
    "                    }\n",
    "                    all_data.append(data_point)\n",
    "            \n",
    "            print(f\"Loaded {len([d for d in all_data if d['dataset'] == 'memotion'])} valid Memotion samples\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading Memotion: {e}\")\n",
    "        print(\"Continuing without Memotion data...\")\n",
    "    \n",
    "    # Load MUStARD dataset\n",
    "    print(\"Loading MUStARD dataset...\")\n",
    "    try:\n",
    "        if os.path.exists(mustard_json_path):\n",
    "            with open(mustard_json_path, 'r') as f:\n",
    "                mustard_data = json.load(f)\n",
    "            \n",
    "            if isinstance(mustard_data, dict):\n",
    "                for key, value in mustard_data.items():\n",
    "                    if isinstance(value, dict):\n",
    "                        text = value.get('utterance', '') or value.get('text', '')\n",
    "                        sarcasm = value.get('sarcasm', False) or value.get('sarcastic', False)\n",
    "                        \n",
    "                        if text and len(text.strip()) > 0:\n",
    "                            data_point = {\n",
    "                                'text': text.strip(),\n",
    "                                'image_path': None,\n",
    "                                'sarcastic': 1 if sarcasm else 0,\n",
    "                                'dataset': 'mustard'\n",
    "                            }\n",
    "                            all_data.append(data_point)\n",
    "            \n",
    "            elif isinstance(mustard_data, list):\n",
    "                for item in mustard_data:\n",
    "                    if isinstance(item, dict):\n",
    "                        text = item.get('utterance', '') or item.get('text', '')\n",
    "                        sarcasm = item.get('sarcasm', False) or item.get('sarcastic', False)\n",
    "                        \n",
    "                        if text and len(text.strip()) > 0:\n",
    "                            data_point = {\n",
    "                                'text': text.strip(),\n",
    "                                'image_path': None,\n",
    "                                'sarcastic': 1 if sarcasm else 0,\n",
    "                                'dataset': 'mustard'\n",
    "                            }\n",
    "                            all_data.append(data_point)\n",
    "            \n",
    "            print(f\"Loaded {len([d for d in all_data if d['dataset'] == 'mustard'])} MUStARD samples\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading MUStARD: {e}\")\n",
    "        print(\"Continuing without MUStARD data...\")\n",
    "    \n",
    "    if not all_data:\n",
    "        print(\"No real data found, creating minimal synthetic data...\")\n",
    "        all_data = [\n",
    "            {'text': \"Oh wonderful, another Monday!\", 'image_path': None, 'sarcastic': 1, 'dataset': 'synthetic'},\n",
    "            {'text': \"I love waiting in traffic\", 'image_path': None, 'sarcastic': 1, 'dataset': 'synthetic'},\n",
    "            {'text': \"Thank you for your help\", 'image_path': None, 'sarcastic': 0, 'dataset': 'synthetic'},\n",
    "            {'text': \"Good morning everyone\", 'image_path': None, 'sarcastic': 0, 'dataset': 'synthetic'},\n",
    "        ] * 50\n",
    "    \n",
    "    df = pd.DataFrame(all_data)\n",
    "    \n",
    "    print(f\"\\nFinal dataset info:\")\n",
    "    print(f\"Total samples: {len(df)}\")\n",
    "    print(f\"Class distribution:\")\n",
    "    print(df['sarcastic'].value_counts())\n",
    "    print(f\"Dataset sources:\")\n",
    "    print(df['dataset'].value_counts())\n",
    "    \n",
    "    return df\n",
    "\n",
    "# =============================================\n",
    "# Fast Dataset with Real Data\n",
    "# =============================================\n",
    "\n",
    "class FastRealSarcasmDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, transform=None, max_length=64, balance_data=True):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.transform = transform or self._get_default_transform()\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        if balance_data:\n",
    "            self.data = self._balance_data(data)\n",
    "        else:\n",
    "            self.data = data.reset_index(drop=True)\n",
    "        \n",
    "        print(f\"Dataset size: {len(self.data)}\")\n",
    "        print(f\"Sarcastic: {self.data['sarcastic'].sum()}\")\n",
    "        print(f\"Non-sarcastic: {len(self.data) - self.data['sarcastic'].sum()}\")\n",
    "    \n",
    "    def _get_default_transform(self):\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    def _balance_data(self, data):\n",
    "        print(\"Balancing dataset...\")\n",
    "        \n",
    "        sarcastic_data = data[data['sarcastic'] == 1]\n",
    "        non_sarcastic_data = data[data['sarcastic'] == 0]\n",
    "        \n",
    "        print(f\"Original - Sarcastic: {len(sarcastic_data)}, Non-sarcastic: {len(non_sarcastic_data)}\")\n",
    "        \n",
    "        if len(sarcastic_data) < len(non_sarcastic_data):\n",
    "            n_needed = len(non_sarcastic_data) - len(sarcastic_data)\n",
    "            oversampled = sarcastic_data.sample(n=n_needed, replace=True, random_state=42)\n",
    "            balanced_data = pd.concat([data, oversampled], ignore_index=True)\n",
    "        elif len(non_sarcastic_data) < len(sarcastic_data):\n",
    "            n_needed = len(sarcastic_data) - len(non_sarcastic_data)\n",
    "            oversampled = non_sarcastic_data.sample(n=n_needed, replace=True, random_state=42)\n",
    "            balanced_data = pd.concat([data, oversampled], ignore_index=True)\n",
    "        else:\n",
    "            balanced_data = data\n",
    "        \n",
    "        return balanced_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data.iloc[idx]\n",
    "        \n",
    "        text = str(item['text'])\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        image = torch.zeros(3, 224, 224)\n",
    "        if pd.notna(item.get('image_path')) and os.path.exists(str(item['image_path'])):\n",
    "            try:\n",
    "                image = Image.open(item['image_path']).convert('RGB')\n",
    "                image = self.transform(image)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        label = int(item['sarcastic'])\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
    "            'image': image,\n",
    "            'label': torch.tensor(label, dtype=torch.long),\n",
    "            'text': text\n",
    "        }\n",
    "\n",
    "# =============================================\n",
    "# Enhanced Fast Model with Image Support\n",
    "# =============================================\n",
    "\n",
    "class FastMultimodalHCI_EASD(nn.Module):\n",
    "    def __init__(self, num_classes=2, hidden_size=256, use_images=True):\n",
    "        super(FastMultimodalHCI_EASD, self).__init__()\n",
    "        \n",
    "        self.use_images = use_images\n",
    "        \n",
    "        self.text_encoder = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        \n",
    "        for param in self.text_encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        for param in self.text_encoder.transformer.layer[-2:].parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        text_dim = 768\n",
    "        \n",
    "        if self.use_images:\n",
    "            self.image_encoder = nn.Sequential(\n",
    "                nn.Conv2d(3, 32, 7, stride=4),\n",
    "                nn.ReLU(),\n",
    "                nn.AdaptiveAvgPool2d((4, 4)),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(32 * 16, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128, 64)\n",
    "            )\n",
    "            image_dim = 64\n",
    "        else:\n",
    "            image_dim = 0\n",
    "        \n",
    "        self.text_projection = nn.Linear(text_dim, hidden_size)\n",
    "        \n",
    "        if self.use_images:\n",
    "            self.image_projection = nn.Linear(image_dim, hidden_size)\n",
    "            fusion_dim = hidden_size * 2\n",
    "        else:\n",
    "            fusion_dim = hidden_size\n",
    "        \n",
    "        self.incongruity_head = nn.Sequential(\n",
    "            nn.Linear(fusion_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(fusion_dim + 1, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_size, hidden_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_size // 2, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, images=None):\n",
    "        text_outputs = self.text_encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        text_features = text_outputs.last_hidden_state.mean(dim=1)\n",
    "        text_proj = self.text_projection(text_features)\n",
    "        \n",
    "        if self.use_images and images is not None:\n",
    "            image_features = self.image_encoder(images)\n",
    "            image_proj = self.image_projection(image_features)\n",
    "            \n",
    "            combined_features = torch.cat([text_proj, image_proj], dim=1)\n",
    "        else:\n",
    "            combined_features = text_proj\n",
    "        \n",
    "        incongruity = self.incongruity_head(combined_features)\n",
    "        \n",
    "        final_features = torch.cat([combined_features, incongruity], dim=1)\n",
    "        logits = self.classifier(final_features)\n",
    "        \n",
    "        return {\n",
    "            'logits': logits,\n",
    "            'incongruity_score': incongruity\n",
    "        }\n",
    "\n",
    "# =============================================\n",
    "# Fast Training with Real Data\n",
    "# =============================================\n",
    "\n",
    "def train_fast_real(model, train_loader, val_loader, class_weights=None, num_epochs=8, lr=3e-4):\n",
    "    \"\"\"Fast training optimized for real data\"\"\"\n",
    "    \n",
    "    if class_weights is not None:\n",
    "        class_weights_tensor = torch.FloatTensor(class_weights).to(device)\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer, max_lr=lr, steps_per_epoch=len(train_loader),\n",
    "        epochs=num_epochs, pct_start=0.3\n",
    "    )\n",
    "    \n",
    "    scaler = torch.cuda.amp.GradScaler() if device.type == 'cuda' else None\n",
    "    \n",
    "    best_f1 = 0.0\n",
    "    history = {'train_loss': [], 'val_acc': [], 'val_f1': []}\n",
    "    \n",
    "    print(\"Starting fast training on real data...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "        for batch in pbar:\n",
    "            input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "            attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "            images = batch['image'].to(device, non_blocking=True)\n",
    "            labels = batch['label'].to(device, non_blocking=True)\n",
    "            \n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            \n",
    "            if scaler:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    outputs = model(input_ids, attention_mask, images)\n",
    "                    loss = criterion(outputs['logits'], labels)\n",
    "                \n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                outputs = model(input_ids, attention_mask, images)\n",
    "                loss = criterion(outputs['logits'], labels)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "            \n",
    "            scheduler.step()\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "        \n",
    "        model.eval()\n",
    "        val_preds, val_labels = [], []\n",
    "        val_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "                attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "                images = batch['image'].to(device, non_blocking=True)\n",
    "                labels = batch['label'].to(device, non_blocking=True)\n",
    "                \n",
    "                if scaler:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        outputs = model(input_ids, attention_mask, images)\n",
    "                        loss = criterion(outputs['logits'], labels)\n",
    "                else:\n",
    "                    outputs = model(input_ids, attention_mask, images)\n",
    "                    loss = criterion(outputs['logits'], labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                preds = torch.argmax(outputs['logits'], dim=1)\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_acc = accuracy_score(val_labels, val_preds)\n",
    "        val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "        \n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_f1'].append(val_f1)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}: Train Loss={avg_train_loss:.4f}, \"\n",
    "              f\"Val Loss={avg_val_loss:.4f}, Val Acc={val_acc:.4f}, Val F1={val_f1:.4f}\")\n",
    "        \n",
    "        if val_f1 > best_f1:\n",
    "            best_f1 = val_f1\n",
    "            torch.save(model.state_dict(), 'fast_real_model.pt')\n",
    "            print(f\"New best model saved! F1: {best_f1:.4f}\")\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Training completed in {elapsed:.2f} seconds!\")\n",
    "    print(f\"Best F1-Score: {best_f1:.4f}\")\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "# =============================================\n",
    "# Evaluation Functions\n",
    "# =============================================\n",
    "# =============================================\n",
    "# Evaluation Functions (Corrected)\n",
    "# =============================================\n",
    "\n",
    "def evaluate_real_model(model, test_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds, all_labels = [], []\n",
    "    all_probs = []\n",
    "    incongruity_scores = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc='Evaluating'):\n",
    "            input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "            attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "            images = batch['image'].to(device, non_blocking=True)\n",
    "            labels = batch['label'].to(device, non_blocking=True)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask, images)\n",
    "            \n",
    "            probs = F.softmax(outputs['logits'], dim=1)\n",
    "            preds = torch.argmax(outputs['logits'], dim=1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            \n",
    "            # --- FIX IS HERE ---\n",
    "            # Extend incongruity_scores with the scores from the batch\n",
    "            incongruity_scores.extend(outputs['incongruity_score'].cpu().numpy())\n",
    "    \n",
    "    eval_time = time.time() - start_time\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1_weighted = f1_score(all_labels, all_preds, average='weighted')\n",
    "    f1_per_class = f1_score(all_labels, all_preds, average=None)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"REAL DATA EVALUATION RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Evaluation time: {eval_time:.2f} seconds\")\n",
    "    print(f\"Samples per second: {len(all_labels)/eval_time:.1f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Weighted F1-Score: {f1_weighted:.4f}\")\n",
    "    \n",
    "    if len(f1_per_class) == 2:\n",
    "        print(f\"Non-Sarcastic F1: {f1_per_class[0]:.4f}\")\n",
    "        print(f\"Sarcastic F1: {f1_per_class[1]:.4f}\")\n",
    "    \n",
    "    sarcastic_inc = np.array(incongruity_scores)[np.array(all_labels) == 1]\n",
    "    non_sarcastic_inc = np.array(incongruity_scores)[np.array(all_labels) == 0]\n",
    "    \n",
    "    if len(sarcastic_inc) > 0 and len(non_sarcastic_inc) > 0:\n",
    "        print(f\"\\nIncongruity Analysis:\")\n",
    "        print(f\"Sarcastic mean: {np.mean(sarcastic_inc):.3f} ± {np.std(sarcastic_inc):.3f}\")\n",
    "        print(f\"Non-sarcastic mean: {np.mean(non_sarcastic_inc):.3f} ± {np.std(non_sarcastic_inc):.3f}\")\n",
    "        print(f\"Difference: {np.mean(sarcastic_inc) - np.mean(non_sarcastic_inc):.3f}\")\n",
    "    \n",
    "    print(\"\\nDetailed Classification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, \n",
    "                              target_names=['Non-Sarcastic', 'Sarcastic']))\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1_weighted': f1_weighted,\n",
    "        'f1_per_class': f1_per_class,\n",
    "        'eval_time': eval_time,\n",
    "        'predictions': all_preds,\n",
    "        'labels': all_labels,\n",
    "        'probabilities': all_probs,\n",
    "        'incongruity_scores': incongruity_scores # <-- This line is crucial for the KeyError fix\n",
    "    }\n",
    "\n",
    "# =============================================\n",
    "# Advanced Results Analysis Functions (New)\n",
    "# =============================================\n",
    "\n",
    "def plot_confusion_matrix(labels, preds, class_names=['Non-Sarcastic', 'Sarcastic']):\n",
    "    cm = confusion_matrix(labels, preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_roc_curve(labels, probs, class_names=['Non-Sarcastic', 'Sarcastic']):\n",
    "    probs = np.array(probs)\n",
    "    fpr, tpr, _ = roc_curve(labels, probs[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'Receiver Operating Characteristic (ROC) Curve for {class_names[1]}')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "def analyze_incongruity_scores(labels, incongruity_scores, preds, class_names=['Non-Sarcastic', 'Sarcastic']):\n",
    "    labels = np.array(labels)\n",
    "    incongruity_scores = np.array(incongruity_scores).flatten()\n",
    "    preds = np.array(preds)\n",
    "    \n",
    "    sarcastic_scores = incongruity_scores[labels == 1]\n",
    "    non_sarcastic_scores = incongruity_scores[labels == 0]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x=[class_names[1]] * len(sarcastic_scores) + [class_names[0]] * len(non_sarcastic_scores),\n",
    "                y=np.concatenate([sarcastic_scores, non_sarcastic_scores]),\n",
    "                palette='Set2')\n",
    "    plt.title('Incongruity Scores by True Class')\n",
    "    plt.ylabel('Incongruity Score')\n",
    "    plt.xlabel('True Class')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nIncongruity Score Statistics:\")\n",
    "    print(f\"Mean score for {class_names[1]}: {np.mean(sarcastic_scores):.4f} +/- {np.std(sarcastic_scores):.4f}\")\n",
    "    print(f\"Mean score for {class_names[0]}: {np.mean(non_sarcastic_scores):.4f} +/- {np.std(non_sarcastic_scores):.4f}\")\n",
    "    \n",
    "    correct_preds_scores = incongruity_scores[labels == preds]\n",
    "    incorrect_preds_scores = incongruity_scores[labels != preds]\n",
    "    \n",
    "    if len(correct_preds_scores) > 0 and len(incorrect_preds_scores) > 0:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.histplot(correct_preds_scores, color='green', label='Correct Predictions', kde=True)\n",
    "        sns.histplot(incorrect_preds_scores, color='red', label='Incorrect Predictions', kde=True)\n",
    "        plt.title('Incongruity Score Distribution: Correct vs. Incorrect Predictions')\n",
    "        plt.xlabel('Incongruity Score')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "def show_misclassified_examples(test_df, labels, preds, num_examples=5):\n",
    "    misclassified_indices = [i for i, (true, pred) in enumerate(zip(labels, preds)) if true != pred]\n",
    "    \n",
    "    print(f\"\\n--- Showing {num_examples} Misclassified Examples ---\")\n",
    "    for i in range(min(num_examples, len(misclassified_indices))):\n",
    "        idx = misclassified_indices[i]\n",
    "        sample = test_df.iloc[idx]\n",
    "        print(f\"\\nExample {i+1}:\")\n",
    "        print(f\"Text: {sample['text']}\")\n",
    "        print(f\"True Label: {'Sarcastic' if sample['sarcastic'] == 1 else 'Non-Sarcastic'}\")\n",
    "        print(f\"Predicted Label: {'Sarcastic' if preds[idx] == 1 else 'Non-Sarcastic'}\")\n",
    "        if pd.notna(sample.get('image_path')):\n",
    "            print(f\"Image Path: {sample['image_path']}\")\n",
    "    \n",
    "    if len(misclassified_indices) == 0:\n",
    "        print(\"No misclassified examples to show. The model achieved 100% accuracy!\")\n",
    "\n",
    "def advanced_results_analysis(results, test_df):\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ADVANCED RESULTS ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    all_labels = results['labels']\n",
    "    all_preds = results['predictions']\n",
    "    all_probs = results['probabilities']\n",
    "    incongruity_scores = results['incongruity_scores']\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=None)\n",
    "    print(\"\\n--- Detailed Metrics per Class ---\")\n",
    "    print(f\"{'Class':<15}{'Precision':<15}{'Recall':<15}{'F1-Score':<15}\")\n",
    "    print(\"---------------------------------------------------------\")\n",
    "    print(f\"{'Non-Sarcastic':<15}{precision[0]:<15.4f}{recall[0]:<15.4f}{f1[0]:<15.4f}\")\n",
    "    print(f\"{'Sarcastic':<15}{precision[1]:<15.4f}{recall[1]:<15.4f}{f1[1]:<15.4f}\")\n",
    "    \n",
    "    print(\"\\n--- Generating Visualizations ---\")\n",
    "    plot_confusion_matrix(all_labels, all_preds)\n",
    "    plot_roc_curve(all_labels, all_probs)\n",
    "    analyze_incongruity_scores(all_labels, incongruity_scores, all_preds)\n",
    "    show_misclassified_examples(test_df, all_labels, all_preds)\n",
    "\n",
    "# =============================================\n",
    "# Main Execution\n",
    "# =============================================\n",
    "\n",
    "def main_real_data():\n",
    "    \"\"\"Main execution with real Memotion and MUStARD data\"\"\"\n",
    "    \n",
    "    print(\"FAST HCI-EASD WITH REAL MEMOTION & MUSTARD DATA\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    total_start = time.time()\n",
    "    \n",
    "    df = load_real_datasets()\n",
    "    \n",
    "    if len(df) < 10:\n",
    "        print(\"Insufficient real data found. Please check dataset paths.\")\n",
    "        return\n",
    "    \n",
    "    train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42, stratify=df['sarcastic'])\n",
    "    val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df['sarcastic'])\n",
    "    \n",
    "    print(f\"\\nData splits:\")\n",
    "    print(f\"Train: {len(train_df)} samples\")\n",
    "    print(f\"Validation: {len(val_df)} samples\")\n",
    "    print(f\"Test: {len(test_df)} samples\")\n",
    "    \n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    \n",
    "    train_dataset = FastRealSarcasmDataset(train_df, tokenizer, balance_data=True)\n",
    "    val_dataset = FastRealSarcasmDataset(val_df, tokenizer, balance_data=False)\n",
    "    test_dataset = FastRealSarcasmDataset(test_df, tokenizer, balance_data=False)\n",
    "    \n",
    "    train_labels = [train_dataset[i]['label'].item() for i in range(len(train_dataset))]\n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
    "    print(f\"Class weights: {class_weights}\")\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    \n",
    "    has_images = any(pd.notna(df['image_path']) for _, df in df.iterrows())\n",
    "    print(f\"Using images: {has_images}\")\n",
    "    \n",
    "    model = FastMultimodalHCI_EASD(use_images=has_images).to(device)\n",
    "    \n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"\\nModel info:\")\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "    print(f\"Trainable ratio: {trainable_params/total_params:.1%}\")\n",
    "    \n",
    "    print(f\"\\nStarting training...\")\n",
    "    model, history = train_fast_real(model, train_loader, val_loader, class_weights)\n",
    "    \n",
    "    model.load_state_dict(torch.load('fast_real_model.pt'))\n",
    "    results = evaluate_real_model(model, test_loader)\n",
    "    \n",
    "    # Run the advanced analysis\n",
    "    advanced_results_analysis(results, test_df)\n",
    "    \n",
    "    total_time = time.time() - total_start\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*70)\n",
    "    print(\"FINAL SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Total execution time: {total_time:.2f} seconds\")\n",
    "    print(f\"Dataset size: {len(df)} samples\")\n",
    "    print(f\"Final accuracy: {results['accuracy']:.4f}\")\n",
    "    print(f\"Final F1-score: {results['f1_weighted']:.4f}\")\n",
    "    if len(results['f1_per_class']) == 2:\n",
    "        print(f\"Sarcastic F1: {results['f1_per_class'][1]:.4f}\")\n",
    "    print(f\"Inference speed: {len(test_df)/results['eval_time']:.1f} samples/sec\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        main_real_data()\n",
    "        print(\"\\n🚀 SUCCESS! All analysis complete.\")\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(\"\\nIt seems one or more of your dataset files could not be found.\")\n",
    "        print(\"Please ensure the following paths are correct and accessible:\")\n",
    "        print(\"- /kaggle/input/memotion-dataset-7k/memotion_dataset_7k/labels.csv\")\n",
    "        print(\"- /kaggle/input/memotion-dataset-7k/memotion_dataset_7k/reference.csv\") \n",
    "        print(\"- /kaggle/input/mustard-multimodal-sarcasm-detection-dataset/sarcasm_data.json\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a12e64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-05T07:04:47.394375Z",
     "iopub.status.busy": "2025-08-05T07:04:47.394151Z",
     "iopub.status.idle": "2025-08-05T07:04:47.826454Z",
     "shell.execute_reply": "2025-08-05T07:04:47.825640Z",
     "shell.execute_reply.started": "2025-08-05T07:04:47.394357Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_confidence_distribution(labels, probs, class_names=['Non-Sarcastic', 'Sarcastic']):\n",
    "    \"\"\"\n",
    "    Plots the distribution of prediction probabilities for each class.\n",
    "    \n",
    "    Args:\n",
    "        labels (list): True labels.\n",
    "        probs (list of lists): Predicted probabilities for each class.\n",
    "        class_names (list): Names for the classes.\n",
    "    \"\"\"\n",
    "    probs = np.array(probs)\n",
    "    \n",
    "    sarcastic_probs = probs[np.array(labels) == 1]\n",
    "    non_sarcastic_probs = probs[np.array(labels) == 0]\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(sarcastic_probs[:, 1], bins=20, kde=True, color='red', label='Sarcastic')\n",
    "    plt.title(f'Sarcastic Predictions ({class_names[1]})')\n",
    "    plt.xlabel('Predicted Probability of Sarcasm')\n",
    "    plt.ylabel('Count')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.histplot(non_sarcastic_probs[:, 1], bins=20, kde=True, color='blue', label='Non-Sarcastic')\n",
    "    plt.title(f'Non-Sarcastic Predictions ({class_names[0]})')\n",
    "    plt.xlabel('Predicted Probability of Sarcasm')\n",
    "    plt.ylabel('Count')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# How to call it:\n",
    "plot_confidence_distribution(results['labels'], results['probabilities'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6cc169",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-05T07:05:21.113955Z",
     "iopub.status.busy": "2025-08-05T07:05:21.113584Z",
     "iopub.status.idle": "2025-08-05T07:05:21.343648Z",
     "shell.execute_reply": "2025-08-05T07:05:21.342735Z",
     "shell.execute_reply.started": "2025-08-05T07:05:21.113929Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_calibration_curve(labels, probs, n_bins=10):\n",
    "    \"\"\"\n",
    "    Plots a calibration curve (reliability diagram).\n",
    "    \n",
    "    Args:\n",
    "        labels (list): True labels.\n",
    "        probs (list of lists): Predicted probabilities for the positive class.\n",
    "        n_bins (int): Number of bins for the plot.\n",
    "    \"\"\"\n",
    "    probs = np.array(probs)\n",
    "    positive_probs = probs[:, 1]\n",
    "    \n",
    "    bins = np.linspace(0.0, 1.0, n_bins + 1)\n",
    "    bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "    \n",
    "    correctness = []\n",
    "    confidence = []\n",
    "    \n",
    "    for i in range(n_bins):\n",
    "        in_bin = (positive_probs > bins[i]) & (positive_probs <= bins[i+1])\n",
    "        if np.sum(in_bin) > 0:\n",
    "            avg_prob = np.mean(positive_probs[in_bin])\n",
    "            avg_correct = np.mean(labels[in_bin] == 1)\n",
    "            correctness.append(avg_correct)\n",
    "            confidence.append(avg_prob)\n",
    "            \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n",
    "    plt.plot(confidence, correctness, \"s-\", label=\"Model\")\n",
    "    plt.xlabel(\"Mean Predicted Probability\")\n",
    "    plt.ylabel(\"Fraction of Positives\")\n",
    "    plt.title(\"Calibration Plot\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# How to call it:\n",
    "plot_calibration_curve(np.array(results['labels']), np.array(results['probabilities']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfb31e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-05T07:08:29.726113Z",
     "iopub.status.busy": "2025-08-05T07:08:29.725742Z",
     "iopub.status.idle": "2025-08-05T07:14:49.746685Z",
     "shell.execute_reply": "2025-08-05T07:14:49.745688Z",
     "shell.execute_reply.started": "2025-08-05T07:08:29.726087Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix, precision_recall_fscore_support, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Speed optimizations\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.deterministic = False\n",
    "if hasattr(torch, 'set_float32_matmul_precision'):\n",
    "    torch.set_float32_matmul_precision('high')\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# =============================================\n",
    "# Real Dataset Loading Functions\n",
    "# =============================================\n",
    "\n",
    "def load_real_datasets():\n",
    "    \"\"\"Load actual Memotion and MUStARD datasets\"\"\"\n",
    "    \n",
    "    memotion_labels_path = \"/kaggle/input/memotion-dataset-7k/memotion_dataset_7k/labels.csv\"\n",
    "    memotion_reference_path = \"/kaggle/input/memotion-dataset-7k/memotion_dataset_7k/reference.csv\"\n",
    "    mustard_json_path = \"/kaggle/input/mustard-multimodal-sarcasm-detection-dataset/sarcasm_data.json\"\n",
    "    \n",
    "    all_data = []\n",
    "    \n",
    "    print(\"Loading Memotion dataset...\")\n",
    "    try:\n",
    "        if os.path.exists(memotion_labels_path) and os.path.exists(memotion_reference_path):\n",
    "            labels_df = pd.read_csv(memotion_labels_path)\n",
    "            reference_df = pd.read_csv(memotion_reference_path)\n",
    "            \n",
    "            memotion_df = pd.merge(labels_df, reference_df, on='image_name', how='inner')\n",
    "            \n",
    "            print(f\"Memotion shape: {memotion_df.shape}\")\n",
    "            \n",
    "            for _, row in memotion_df.iterrows():\n",
    "                text = ''\n",
    "                if 'text_corrected' in row:\n",
    "                    text = str(row['text_corrected'])\n",
    "                elif 'text_ocr' in row:\n",
    "                    text = str(row['text_ocr'])\n",
    "                elif 'text' in row:\n",
    "                    text = str(row['text'])\n",
    "                \n",
    "                sarcastic = 0\n",
    "                if 'sarcastic' in row:\n",
    "                    sarcastic = 1 if row['sarcastic'] == 1 else 0\n",
    "                elif 'humour' in row:\n",
    "                    sarcastic = 1 if row['humour'] == 1 else 0\n",
    "                \n",
    "                if text and text != 'nan' and len(text.strip()) > 0:\n",
    "                    data_point = {\n",
    "                        'text': text.strip(),\n",
    "                        'image_path': f\"/kaggle/input/memotion-dataset-7k/memotion_dataset_7k/images/{row['image_name']}\",\n",
    "                        'sarcastic': sarcastic,\n",
    "                        'dataset': 'memotion'\n",
    "                    }\n",
    "                    all_data.append(data_point)\n",
    "            \n",
    "            print(f\"Loaded {len([d for d in all_data if d['dataset'] == 'memotion'])} valid Memotion samples\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading Memotion: {e}\")\n",
    "        print(\"Continuing without Memotion data...\")\n",
    "    \n",
    "    print(\"Loading MUStARD dataset...\")\n",
    "    try:\n",
    "        if os.path.exists(mustard_json_path):\n",
    "            with open(mustard_json_path, 'r') as f:\n",
    "                mustard_data = json.load(f)\n",
    "            \n",
    "            if isinstance(mustard_data, dict):\n",
    "                for key, value in mustard_data.items():\n",
    "                    if isinstance(value, dict):\n",
    "                        text = value.get('utterance', '') or value.get('text', '')\n",
    "                        sarcasm = value.get('sarcasm', False) or value.get('sarcastic', False)\n",
    "                        \n",
    "                        if text and len(text.strip()) > 0:\n",
    "                            data_point = {\n",
    "                                'text': text.strip(),\n",
    "                                'image_path': None,\n",
    "                                'sarcastic': 1 if sarcasm else 0,\n",
    "                                'dataset': 'mustard'\n",
    "                            }\n",
    "                            all_data.append(data_point)\n",
    "            \n",
    "            elif isinstance(mustard_data, list):\n",
    "                for item in mustard_data:\n",
    "                    if isinstance(item, dict):\n",
    "                        text = item.get('utterance', '') or item.get('text', '')\n",
    "                        sarcasm = item.get('sarcasm', False) or item.get('sarcastic', False)\n",
    "                        \n",
    "                        if text and len(text.strip()) > 0:\n",
    "                            data_point = {\n",
    "                                'text': text.strip(),\n",
    "                                'image_path': None,\n",
    "                                'sarcastic': 1 if sarcasm else 0,\n",
    "                                'dataset': 'mustard'\n",
    "                            }\n",
    "                            all_data.append(data_point)\n",
    "            \n",
    "            print(f\"Loaded {len([d for d in all_data if d['dataset'] == 'mustard'])} MUStARD samples\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading MUStARD: {e}\")\n",
    "        print(\"Continuing without MUStARD data...\")\n",
    "    \n",
    "    if not all_data:\n",
    "        print(\"No real data found, creating minimal synthetic data...\")\n",
    "        all_data = [\n",
    "            {'text': \"Oh wonderful, another Monday!\", 'image_path': None, 'sarcastic': 1, 'dataset': 'synthetic'},\n",
    "            {'text': \"I love waiting in traffic\", 'image_path': None, 'sarcastic': 1, 'dataset': 'synthetic'},\n",
    "            {'text': \"Thank you for your help\", 'image_path': None, 'sarcastic': 0, 'dataset': 'synthetic'},\n",
    "            {'text': \"Good morning everyone\", 'image_path': None, 'sarcastic': 0, 'dataset': 'synthetic'},\n",
    "        ] * 50\n",
    "    \n",
    "    df = pd.DataFrame(all_data)\n",
    "    \n",
    "    print(f\"\\nFinal dataset info:\")\n",
    "    print(f\"Total samples: {len(df)}\")\n",
    "    print(f\"Class distribution:\")\n",
    "    print(df['sarcastic'].value_counts())\n",
    "    print(f\"Dataset sources:\")\n",
    "    print(df['dataset'].value_counts())\n",
    "    \n",
    "    return df\n",
    "\n",
    "# =============================================\n",
    "# Fast Dataset with Real Data\n",
    "# =============================================\n",
    "\n",
    "class FastRealSarcasmDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, transform=None, max_length=64, balance_data=True):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.transform = transform or self._get_default_transform()\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        if balance_data:\n",
    "            self.data = self._balance_data(data)\n",
    "        else:\n",
    "            self.data = data.reset_index(drop=True)\n",
    "        \n",
    "        print(f\"Dataset size: {len(self.data)}\")\n",
    "        print(f\"Sarcastic: {self.data['sarcastic'].sum()}\")\n",
    "        print(f\"Non-sarcastic: {len(self.data) - self.data['sarcastic'].sum()}\")\n",
    "    \n",
    "    def _get_default_transform(self):\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    def _balance_data(self, data):\n",
    "        print(\"Balancing dataset...\")\n",
    "        \n",
    "        sarcastic_data = data[data['sarcastic'] == 1]\n",
    "        non_sarcastic_data = data[data['sarcastic'] == 0]\n",
    "        \n",
    "        print(f\"Original - Sarcastic: {len(sarcastic_data)}, Non-sarcastic: {len(non_sarcastic_data)}\")\n",
    "        \n",
    "        if len(sarcastic_data) < len(non_sarcastic_data):\n",
    "            n_needed = len(non_sarcastic_data) - len(sarcastic_data)\n",
    "            oversampled = sarcastic_data.sample(n=n_needed, replace=True, random_state=42)\n",
    "            balanced_data = pd.concat([data, oversampled], ignore_index=True)\n",
    "        elif len(non_sarcastic_data) < len(sarcastic_data):\n",
    "            n_needed = len(sarcastic_data) - len(non_sarcastic_data)\n",
    "            oversampled = non_sarcastic_data.sample(n=n_needed, replace=True, random_state=42)\n",
    "            balanced_data = pd.concat([data, oversampled], ignore_index=True)\n",
    "        else:\n",
    "            balanced_data = data\n",
    "        \n",
    "        return balanced_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data.iloc[idx]\n",
    "        \n",
    "        text = str(item['text'])\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        image = torch.zeros(3, 224, 224)\n",
    "        if pd.notna(item.get('image_path')) and os.path.exists(str(item['image_path'])):\n",
    "            try:\n",
    "                image = Image.open(item['image_path']).convert('RGB')\n",
    "                image = self.transform(image)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        label = int(item['sarcastic'])\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
    "            'image': image,\n",
    "            'label': torch.tensor(label, dtype=torch.long),\n",
    "            'text': text\n",
    "        }\n",
    "\n",
    "# =============================================\n",
    "# Enhanced Fast Model with Image Support\n",
    "# =============================================\n",
    "\n",
    "class FastMultimodalHCI_EASD(nn.Module):\n",
    "    def __init__(self, num_classes=2, hidden_size=256, use_images=True):\n",
    "        super(FastMultimodalHCI_EASD, self).__init__()\n",
    "        \n",
    "        self.use_images = use_images\n",
    "        \n",
    "        self.text_encoder = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        \n",
    "        for param in self.text_encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        for param in self.text_encoder.transformer.layer[-2:].parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        text_dim = 768\n",
    "        \n",
    "        if self.use_images:\n",
    "            self.image_encoder = nn.Sequential(\n",
    "                nn.Conv2d(3, 32, 7, stride=4),\n",
    "                nn.ReLU(),\n",
    "                nn.AdaptiveAvgPool2d((4, 4)),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(32 * 16, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128, 64)\n",
    "            )\n",
    "            image_dim = 64\n",
    "        else:\n",
    "            image_dim = 0\n",
    "        \n",
    "        self.text_projection = nn.Linear(text_dim, hidden_size)\n",
    "        \n",
    "        if self.use_images:\n",
    "            self.image_projection = nn.Linear(image_dim, hidden_size)\n",
    "            fusion_dim = hidden_size * 2\n",
    "        else:\n",
    "            fusion_dim = hidden_size\n",
    "        \n",
    "        self.incongruity_head = nn.Sequential(\n",
    "            nn.Linear(fusion_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(fusion_dim + 1, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_size, hidden_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_size // 2, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, images=None):\n",
    "        text_outputs = self.text_encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        text_features = text_outputs.last_hidden_state.mean(dim=1)\n",
    "        text_proj = self.text_projection(text_features)\n",
    "        \n",
    "        if self.use_images and images is not None:\n",
    "            image_features = self.image_encoder(images)\n",
    "            image_proj = self.image_projection(image_features)\n",
    "            \n",
    "            combined_features = torch.cat([text_proj, image_proj], dim=1)\n",
    "        else:\n",
    "            combined_features = text_proj\n",
    "        \n",
    "        incongruity = self.incongruity_head(combined_features)\n",
    "        \n",
    "        final_features = torch.cat([combined_features, incongruity], dim=1)\n",
    "        logits = self.classifier(final_features)\n",
    "        \n",
    "        return {\n",
    "            'logits': logits,\n",
    "            'incongruity_score': incongruity\n",
    "        }\n",
    "\n",
    "# =============================================\n",
    "# Fast Training with Real Data\n",
    "# =============================================\n",
    "\n",
    "def train_fast_real(model, train_loader, val_loader, class_weights=None, num_epochs=8, lr=3e-4):\n",
    "    if class_weights is not None:\n",
    "        class_weights_tensor = torch.FloatTensor(class_weights).to(device)\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer, max_lr=lr, steps_per_epoch=len(train_loader),\n",
    "        epochs=num_epochs, pct_start=0.3\n",
    "    )\n",
    "    \n",
    "    scaler = torch.cuda.amp.GradScaler() if device.type == 'cuda' else None\n",
    "    \n",
    "    best_f1 = 0.0\n",
    "    history = {'train_loss': [], 'val_acc': [], 'val_f1': []}\n",
    "    \n",
    "    print(\"Starting fast training on real data...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "        for batch in pbar:\n",
    "            input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "            attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "            images = batch['image'].to(device, non_blocking=True)\n",
    "            labels = batch['label'].to(device, non_blocking=True)\n",
    "            \n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            \n",
    "            if scaler:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    outputs = model(input_ids, attention_mask, images)\n",
    "                    loss = criterion(outputs['logits'], labels)\n",
    "                \n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                outputs = model(input_ids, attention_mask, images)\n",
    "                loss = criterion(outputs['logits'], labels)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "            \n",
    "            scheduler.step()\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "        \n",
    "        model.eval()\n",
    "        val_preds, val_labels = [], []\n",
    "        val_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "                attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "                images = batch['image'].to(device, non_blocking=True)\n",
    "                labels = batch['label'].to(device, non_blocking=True)\n",
    "                \n",
    "                if scaler:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        outputs = model(input_ids, attention_mask, images)\n",
    "                        loss = criterion(outputs['logits'], labels)\n",
    "                else:\n",
    "                    outputs = model(input_ids, attention_mask, images)\n",
    "                    loss = criterion(outputs['logits'], labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                preds = torch.argmax(outputs['logits'], dim=1)\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_acc = accuracy_score(val_labels, val_preds)\n",
    "        val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "        \n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_f1'].append(val_f1)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}: Train Loss={avg_train_loss:.4f}, \"\n",
    "              f\"Val Loss={avg_val_loss:.4f}, Val Acc={val_acc:.4f}, Val F1={val_f1:.4f}\")\n",
    "        \n",
    "        if val_f1 > best_f1:\n",
    "            best_f1 = val_f1\n",
    "            torch.save(model.state_dict(), 'fast_real_model.pt')\n",
    "            print(f\"New best model saved! F1: {best_f1:.4f}\")\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Training completed in {elapsed:.2f} seconds!\")\n",
    "    print(f\"Best F1-Score: {best_f1:.4f}\")\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "# =============================================\n",
    "# Evaluation and Analysis Functions (Corrected and Advanced)\n",
    "# =============================================\n",
    "\n",
    "def evaluate_real_model(model, test_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds, all_labels = [], []\n",
    "    all_probs = []\n",
    "    incongruity_scores = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc='Evaluating'):\n",
    "            input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "            attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "            images = batch['image'].to(device, non_blocking=True)\n",
    "            labels = batch['label'].to(device, non_blocking=True)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask, images)\n",
    "            \n",
    "            probs = F.softmax(outputs['logits'], dim=1)\n",
    "            preds = torch.argmax(outputs['logits'], dim=1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            incongruity_scores.extend(outputs['incongruity_score'].cpu().numpy())\n",
    "    \n",
    "    eval_time = time.time() - start_time\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1_weighted = f1_score(all_labels, all_preds, average='weighted')\n",
    "    f1_per_class = f1_score(all_labels, all_preds, average=None)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"REAL DATA EVALUATION RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Evaluation time: {eval_time:.2f} seconds\")\n",
    "    print(f\"Samples per second: {len(all_labels)/eval_time:.1f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Weighted F1-Score: {f1_weighted:.4f}\")\n",
    "    \n",
    "    if len(f1_per_class) == 2:\n",
    "        print(f\"Non-Sarcastic F1: {f1_per_class[0]:.4f}\")\n",
    "        print(f\"Sarcastic F1: {f1_per_class[1]:.4f}\")\n",
    "    \n",
    "    sarcastic_inc = np.array(incongruity_scores)[np.array(all_labels) == 1]\n",
    "    non_sarcastic_inc = np.array(incongruity_scores)[np.array(all_labels) == 0]\n",
    "    \n",
    "    if len(sarcastic_inc) > 0 and len(non_sarcastic_inc) > 0:\n",
    "        print(f\"\\nIncongruity Analysis:\")\n",
    "        print(f\"Sarcastic mean: {np.mean(sarcastic_inc):.3f} ± {np.std(sarcastic_inc):.3f}\")\n",
    "        print(f\"Non-sarcastic mean: {np.mean(non_sarcastic_inc):.3f} ± {np.std(non_sarcastic_inc):.3f}\")\n",
    "        print(f\"Difference: {np.mean(sarcastic_inc) - np.mean(non_sarcastic_inc):.3f}\")\n",
    "    \n",
    "    print(\"\\nDetailed Classification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, \n",
    "                              target_names=['Non-Sarcastic', 'Sarcastic']))\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1_weighted': f1_weighted,\n",
    "        'f1_per_class': f1_per_class,\n",
    "        'eval_time': eval_time,\n",
    "        'predictions': all_preds,\n",
    "        'labels': all_labels,\n",
    "        'probabilities': all_probs,\n",
    "        'incongruity_scores': incongruity_scores\n",
    "    }\n",
    "\n",
    "def plot_confusion_matrix(labels, preds, class_names=['Non-Sarcastic', 'Sarcastic']):\n",
    "    cm = confusion_matrix(labels, preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_roc_curve(labels, probs, class_names=['Non-Sarcastic', 'Sarcastic']):\n",
    "    probs = np.array(probs)\n",
    "    fpr, tpr, _ = roc_curve(labels, probs[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'Receiver Operating Characteristic (ROC) Curve for {class_names[1]}')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "def analyze_incongruity_scores(labels, incongruity_scores, preds, class_names=['Non-Sarcastic', 'Sarcastic']):\n",
    "    labels = np.array(labels)\n",
    "    incongruity_scores = np.array(incongruity_scores).flatten()\n",
    "    preds = np.array(preds)\n",
    "    \n",
    "    sarcastic_scores = incongruity_scores[labels == 1]\n",
    "    non_sarcastic_scores = incongruity_scores[labels == 0]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x=[class_names[1]] * len(sarcastic_scores) + [class_names[0]] * len(non_sarcastic_scores),\n",
    "                y=np.concatenate([sarcastic_scores, non_sarcastic_scores]),\n",
    "                palette='Set2')\n",
    "    plt.title('Incongruity Scores by True Class')\n",
    "    plt.ylabel('Incongruity Score')\n",
    "    plt.xlabel('True Class')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nIncongruity Score Statistics:\")\n",
    "    print(f\"Mean score for {class_names[1]}: {np.mean(sarcastic_scores):.4f} +/- {np.std(sarcastic_scores):.4f}\")\n",
    "    print(f\"Mean score for {class_names[0]}: {np.mean(non_sarcastic_scores):.4f} +/- {np.std(non_sarcastic_scores):.4f}\")\n",
    "    \n",
    "    correct_preds_scores = incongruity_scores[labels == preds]\n",
    "    incorrect_preds_scores = incongruity_scores[labels != preds]\n",
    "    \n",
    "    if len(correct_preds_scores) > 0 and len(incorrect_preds_scores) > 0:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.histplot(correct_preds_scores, color='green', label='Correct Predictions', kde=True)\n",
    "        sns.histplot(incorrect_preds_scores, color='red', label='Incorrect Predictions', kde=True)\n",
    "        plt.title('Incongruity Score Distribution: Correct vs. Incorrect Predictions')\n",
    "        plt.xlabel('Incongruity Score')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "def plot_confidence_distribution(labels, probs, class_names=['Non-Sarcastic', 'Sarcastic']):\n",
    "    probs = np.array(probs)\n",
    "    \n",
    "    sarcastic_probs = probs[np.array(labels) == 1]\n",
    "    non_sarcastic_probs = probs[np.array(labels) == 0]\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(sarcastic_probs[:, 1], bins=20, kde=True, color='red', label='Sarcastic')\n",
    "    plt.title(f'Sarcastic Predictions ({class_names[1]})')\n",
    "    plt.xlabel('Predicted Probability of Sarcasm')\n",
    "    plt.ylabel('Count')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.histplot(non_sarcastic_probs[:, 1], bins=20, kde=True, color='blue', label='Non-Sarcastic')\n",
    "    plt.title(f'Non-Sarcastic Predictions ({class_names[0]})')\n",
    "    plt.xlabel('Predicted Probability of Sarcasm')\n",
    "    plt.ylabel('Count')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_calibration_curve(labels, probs, n_bins=10):\n",
    "    probs = np.array(probs)\n",
    "    positive_probs = probs[:, 1]\n",
    "    \n",
    "    bins = np.linspace(0.0, 1.0, n_bins + 1)\n",
    "    bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "    \n",
    "    correctness = []\n",
    "    confidence = []\n",
    "    \n",
    "    for i in range(n_bins):\n",
    "        in_bin = (positive_probs > bins[i]) & (positive_probs <= bins[i+1])\n",
    "        if np.sum(in_bin) > 0:\n",
    "            avg_prob = np.mean(positive_probs[in_bin])\n",
    "            avg_correct = np.mean(labels[in_bin] == 1)\n",
    "            correctness.append(avg_correct)\n",
    "            confidence.append(avg_prob)\n",
    "            \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n",
    "    plt.plot(confidence, correctness, \"s-\", label=\"Model\")\n",
    "    plt.xlabel(\"Mean Predicted Probability\")\n",
    "    plt.ylabel(\"Fraction of Positives\")\n",
    "    plt.title(\"Calibration Plot\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def analyze_incongruity_by_error(labels, preds, incongruity_scores):\n",
    "    labels = np.array(labels)\n",
    "    preds = np.array(preds)\n",
    "    incongruity_scores = np.array(incongruity_scores).flatten()\n",
    "    \n",
    "    correct_sarcastic_inc = incongruity_scores[(labels == 1) & (preds == 1)]\n",
    "    incorrect_sarcastic_inc = incongruity_scores[(labels == 1) & (preds == 0)]\n",
    "    \n",
    "    correct_non_sarcastic_inc = incongruity_scores[(labels == 0) & (preds == 0)]\n",
    "    incorrect_non_sarcastic_inc = incongruity_scores[(labels == 0) & (preds == 1)]\n",
    "    \n",
    "    print(\"\\n--- Incongruity Score Analysis by Prediction Error ---\")\n",
    "    print(f\"Correctly predicted Sarcastic (TP): {np.mean(correct_sarcastic_inc):.4f} +/- {np.std(correct_sarcastic_inc):.4f}\")\n",
    "    print(f\"Incorrectly predicted Sarcastic (FN): {np.mean(incorrect_sarcastic_inc):.4f} +/- {np.std(incorrect_sarcastic_inc):.4f}\")\n",
    "    print(f\"Correctly predicted Non-Sarcastic (TN): {np.mean(correct_non_sarcastic_inc):.4f} +/- {np.std(correct_non_sarcastic_inc):.4f}\")\n",
    "    print(f\"Incorrectly predicted Non-Sarcastic (FP): {np.mean(incorrect_non_sarcastic_inc):.4f} +/- {np.std(incorrect_non_sarcastic_inc):.4f}\")\n",
    "\n",
    "def show_misclassified_examples(test_df, labels, preds, num_examples=5, class_names=['Non-Sarcastic', 'Sarcastic']):\n",
    "    misclassified_indices = [i for i, (true, pred) in enumerate(zip(labels, preds)) if true != pred]\n",
    "    \n",
    "    print(f\"\\n--- Showing {num_examples} Misclassified Examples ---\")\n",
    "    for i in range(min(num_examples, len(misclassified_indices))):\n",
    "        idx = misclassified_indices[i]\n",
    "        sample = test_df.iloc[idx]\n",
    "        print(f\"\\nExample {i+1}:\")\n",
    "        print(f\"Text: {sample['text']}\")\n",
    "        print(f\"True Label: {'Sarcastic' if sample['sarcastic'] == 1 else 'Non-Sarcastic'}\")\n",
    "        print(f\"Predicted Label: {'Sarcastic' if preds[idx] == 1 else 'Non-Sarcastic'}\")\n",
    "        if pd.notna(sample.get('image_path')):\n",
    "            print(f\"Image Path: {sample['image_path']}\")\n",
    "    \n",
    "    if len(misclassified_indices) == 0:\n",
    "        print(\"No misclassified examples to show. The model achieved 100% accuracy!\")\n",
    "\n",
    "def categorize_errors(test_df, labels, preds, num_examples=5, class_names=['Non-Sarcastic', 'Sarcastic']):\n",
    "    labels = np.array(labels)\n",
    "    preds = np.array(preds)\n",
    "    \n",
    "    false_positives_idx = np.where((labels == 0) & (preds == 1))[0]\n",
    "    false_negatives_idx = np.where((labels == 1) & (preds == 0))[0]\n",
    "    \n",
    "    print(\"\\n--- False Positive Examples (Predicted Sarcastic, True Non-Sarcastic) ---\")\n",
    "    for i in range(min(num_examples, len(false_positives_idx))):\n",
    "        idx = false_positives_idx[i]\n",
    "        sample = test_df.iloc[idx]\n",
    "        print(f\"\\nExample {i+1}:\")\n",
    "        print(f\"Text: {sample['text']}\")\n",
    "        print(f\"Predicted Label: {class_names[1]}, True Label: {class_names[0]}\")\n",
    "    \n",
    "    print(\"\\n--- False Negative Examples (Predicted Non-Sarcastic, True Sarcastic) ---\")\n",
    "    for i in range(min(num_examples, len(false_negatives_idx))):\n",
    "        idx = false_negatives_idx[i]\n",
    "        sample = test_df.iloc[idx]\n",
    "        print(f\"\\nExample {i+1}:\")\n",
    "        print(f\"Text: {sample['text']}\")\n",
    "        print(f\"Predicted Label: {class_names[0]}, True Label: {class_names[1]}\")\n",
    "\n",
    "def advanced_results_analysis(results, test_df):\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ADVANCED RESULTS ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    all_labels = results['labels']\n",
    "    all_preds = results['predictions']\n",
    "    all_probs = results['probabilities']\n",
    "    incongruity_scores = results['incongruity_scores']\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=None)\n",
    "    print(\"\\n--- Detailed Metrics per Class ---\")\n",
    "    print(f\"{'Class':<15}{'Precision':<15}{'Recall':<15}{'F1-Score':<15}\")\n",
    "    print(\"---------------------------------------------------------\")\n",
    "    print(f\"{'Non-Sarcastic':<15}{precision[0]:<15.4f}{recall[0]:<15.4f}{f1[0]:<15.4f}\")\n",
    "    print(f\"{'Sarcastic':<15}{precision[1]:<15.4f}{recall[1]:<15.4f}{f1[1]:<15.4f}\")\n",
    "    \n",
    "    print(\"\\n--- Generating Visualizations ---\")\n",
    "    plot_confusion_matrix(all_labels, all_preds)\n",
    "    plot_roc_curve(all_labels, all_probs)\n",
    "    analyze_incongruity_scores(all_labels, incongruity_scores, all_preds)\n",
    "    \n",
    "    # Run the new advanced analysis plots\n",
    "    plot_confidence_distribution(all_labels, all_probs)\n",
    "    plot_calibration_curve(all_labels, all_probs)\n",
    "    analyze_incongruity_by_error(all_labels, all_preds, incongruity_scores)\n",
    "    categorize_errors(test_df.reset_index(drop=True), all_labels, all_preds)\n",
    "\n",
    "# =============================================\n",
    "# Main Execution\n",
    "# =============================================\n",
    "\n",
    "def main_real_data():\n",
    "    print(\"FAST HCI-EASD WITH REAL MEMOTION & MUSTARD DATA\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    total_start = time.time()\n",
    "    \n",
    "    df = load_real_datasets()\n",
    "    \n",
    "    if len(df) < 10:\n",
    "        print(\"Insufficient real data found. Please check dataset paths.\")\n",
    "        return\n",
    "    \n",
    "    train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42, stratify=df['sarcastic'])\n",
    "    val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df['sarcastic'])\n",
    "    \n",
    "    print(f\"\\nData splits:\")\n",
    "    print(f\"Train: {len(train_df)} samples\")\n",
    "    print(f\"Validation: {len(val_df)} samples\")\n",
    "    print(f\"Test: {len(test_df)} samples\")\n",
    "    \n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    \n",
    "    train_dataset = FastRealSarcasmDataset(train_df, tokenizer, balance_data=True)\n",
    "    val_dataset = FastRealSarcasmDataset(val_df, tokenizer, balance_data=False)\n",
    "    test_dataset = FastRealSarcasmDataset(test_df, tokenizer, balance_data=False)\n",
    "    \n",
    "    train_labels = [train_dataset[i]['label'].item() for i in range(len(train_dataset))]\n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
    "    print(f\"Class weights: {class_weights}\")\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    \n",
    "    has_images = any(pd.notna(df['image_path']) for _, df in df.iterrows())\n",
    "    print(f\"Using images: {has_images}\")\n",
    "    \n",
    "    model = FastMultimodalHCI_EASD(use_images=has_images).to(device)\n",
    "    \n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"\\nModel info:\")\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "    print(f\"Trainable ratio: {trainable_params/total_params:.1%}\")\n",
    "    \n",
    "    print(f\"\\nStarting training...\")\n",
    "    model, history = train_fast_real(model, train_loader, val_loader, class_weights)\n",
    "    \n",
    "    model.load_state_dict(torch.load('fast_real_model.pt'))\n",
    "    results = evaluate_real_model(model, test_loader)\n",
    "    \n",
    "    advanced_results_analysis(results, test_df)\n",
    "    \n",
    "    total_time = time.time() - total_start\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*70)\n",
    "    print(\"FINAL SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Total execution time: {total_time:.2f} seconds\")\n",
    "    print(f\"Dataset size: {len(df)} samples\")\n",
    "    print(f\"Final accuracy: {results['accuracy']:.4f}\")\n",
    "    print(f\"Final F1-score: {results['f1_weighted']:.4f}\")\n",
    "    if len(results['f1_per_class']) == 2:\n",
    "        print(f\"Sarcastic F1: {results['f1_per_class'][1]:.4f}\")\n",
    "    print(f\"Inference speed: {len(test_df)/results['eval_time']:.1f} samples/sec\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        main_real_data()\n",
    "        print(\"\\n🚀 SUCCESS! All analysis complete.\")\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(\"\\nIt seems one or more of your dataset files could not be found.\")\n",
    "        print(\"Please ensure the following paths are correct and accessible:\")\n",
    "        print(\"- /kaggle/input/memotion-dataset-7k/memotion_dataset_7k/labels.csv\")\n",
    "        print(\"- /kaggle/input/memotion-dataset-7k/memotion_dataset_7k/reference.csv\") \n",
    "        print(\"- /kaggle/input/mustard-multimodal-sarcasm-detection-dataset/sarcasm_data.json\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00060a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-05T07:19:59.306310Z",
     "iopub.status.busy": "2025-08-05T07:19:59.306020Z",
     "iopub.status.idle": "2025-08-05T07:19:59.323165Z",
     "shell.execute_reply": "2025-08-05T07:19:59.322266Z",
     "shell.execute_reply.started": "2025-08-05T07:19:59.306288Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def analyze_by_confidence_bins(labels, probs, n_bins=10):\n",
    "    \"\"\"\n",
    "    Analyzes model performance across different confidence intervals.\n",
    "    \n",
    "    Args:\n",
    "        labels (list): True labels.\n",
    "        probs (list of lists): Predicted probabilities for the positive class.\n",
    "        n_bins (int): Number of bins for the analysis.\n",
    "    \"\"\"\n",
    "    labels = np.array(labels)\n",
    "    probs = np.array(probs)[:, 1]\n",
    "    \n",
    "    bins = np.linspace(0.0, 1.0, n_bins + 1)\n",
    "    bin_labels = [f\"({bins[i]:.2f}-{bins[i+1]:.2f}]\" for i in range(n_bins)]\n",
    "    \n",
    "    print(\"\\n--- Model Performance by Confidence Interval ---\")\n",
    "    print(f\"{'Confidence Interval':<25}{'Total Samples':<15}{'Accuracy':<15}{'Error Rate':<15}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for i in range(n_bins):\n",
    "        lower_bound, upper_bound = bins[i], bins[i+1]\n",
    "        \n",
    "        # Consider predictions in the current bin\n",
    "        if i == n_bins - 1:\n",
    "            indices = np.where((probs > lower_bound) & (probs <= upper_bound))\n",
    "        else:\n",
    "            indices = np.where((probs >= lower_bound) & (probs < upper_bound))\n",
    "        \n",
    "        bin_labels_subset = labels[indices]\n",
    "        bin_probs_subset = probs[indices]\n",
    "        \n",
    "        if len(bin_labels_subset) > 0:\n",
    "            bin_preds = (bin_probs_subset > 0.5).astype(int)\n",
    "            accuracy = accuracy_score(bin_labels_subset, bin_preds)\n",
    "            error_rate = 1 - accuracy\n",
    "            \n",
    "            print(f\"{bin_labels[i]:<25}{len(bin_labels_subset):<15}{accuracy:<15.4f}{error_rate:<15.4f}\")\n",
    "        else:\n",
    "            print(f\"{bin_labels[i]:<25}{0:<15}{'-':<15}{'-':<15}\")\n",
    "\n",
    "# How to call it:\n",
    "analyze_by_confidence_bins(results['labels'], results['probabilities'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886f5faa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T16:09:46.983480Z",
     "iopub.status.busy": "2025-08-06T16:09:46.983164Z",
     "iopub.status.idle": "2025-08-06T16:17:51.802662Z",
     "shell.execute_reply": "2025-08-06T16:17:51.801704Z",
     "shell.execute_reply.started": "2025-08-06T16:09:46.983458Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix, precision_recall_fscore_support, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Speed optimizations\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.deterministic = False\n",
    "if hasattr(torch, 'set_float32_matmul_precision'):\n",
    "    torch.set_float32_matmul_precision('high')\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# =============================================\n",
    "# Real Dataset Loading Functions\n",
    "# =============================================\n",
    "\n",
    "def load_real_datasets():\n",
    "    \"\"\"Load actual Memotion and MUStARD datasets\"\"\"\n",
    "    \n",
    "    memotion_labels_path = \"/kaggle/input/memotion-dataset-7k/memotion_dataset_7k/labels.csv\"\n",
    "    memotion_reference_path = \"/kaggle/input/memotion-dataset-7k/memotion_dataset_7k/reference.csv\"\n",
    "    mustard_json_path = \"/kaggle/input/mustard-multimodal-sarcasm-detection-dataset/sarcasm_data.json\"\n",
    "    \n",
    "    all_data = []\n",
    "    \n",
    "    print(\"Loading Memotion dataset...\")\n",
    "    try:\n",
    "        if os.path.exists(memotion_labels_path) and os.path.exists(memotion_reference_path):\n",
    "            labels_df = pd.read_csv(memotion_labels_path)\n",
    "            reference_df = pd.read_csv(memotion_reference_path)\n",
    "            \n",
    "            memotion_df = pd.merge(labels_df, reference_df, on='image_name', how='inner')\n",
    "            \n",
    "            print(f\"Memotion shape: {memotion_df.shape}\")\n",
    "            \n",
    "            for _, row in memotion_df.iterrows():\n",
    "                text = ''\n",
    "                if 'text_corrected' in row:\n",
    "                    text = str(row['text_corrected'])\n",
    "                elif 'text_ocr' in row:\n",
    "                    text = str(row['text_ocr'])\n",
    "                elif 'text' in row:\n",
    "                    text = str(row['text'])\n",
    "                \n",
    "                sarcastic = 0\n",
    "                if 'sarcastic' in row:\n",
    "                    sarcastic = 1 if row['sarcastic'] == 1 else 0\n",
    "                elif 'humour' in row:\n",
    "                    sarcastic = 1 if row['humour'] == 1 else 0\n",
    "                \n",
    "                if text and text != 'nan' and len(text.strip()) > 0:\n",
    "                    data_point = {\n",
    "                        'text': text.strip(),\n",
    "                        'image_path': f\"/kaggle/input/memotion-dataset-7k/memotion_dataset_7k/images/{row['image_name']}\",\n",
    "                        'sarcastic': sarcastic,\n",
    "                        'dataset': 'memotion'\n",
    "                    }\n",
    "                    all_data.append(data_point)\n",
    "            \n",
    "            print(f\"Loaded {len([d for d in all_data if d['dataset'] == 'memotion'])} valid Memotion samples\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading Memotion: {e}\")\n",
    "        print(\"Continuing without Memotion data...\")\n",
    "    \n",
    "    print(\"Loading MUStARD dataset...\")\n",
    "    try:\n",
    "        if os.path.exists(mustard_json_path):\n",
    "            with open(mustard_json_path, 'r') as f:\n",
    "                mustard_data = json.load(f)\n",
    "            \n",
    "            if isinstance(mustard_data, dict):\n",
    "                for key, value in mustard_data.items():\n",
    "                    if isinstance(value, dict):\n",
    "                        text = value.get('utterance', '') or value.get('text', '')\n",
    "                        sarcasm = value.get('sarcasm', False) or value.get('sarcastic', False)\n",
    "                        \n",
    "                        if text and len(text.strip()) > 0:\n",
    "                            data_point = {\n",
    "                                'text': text.strip(),\n",
    "                                'image_path': None,\n",
    "                                'sarcastic': 1 if sarcasm else 0,\n",
    "                                'dataset': 'mustard'\n",
    "                            }\n",
    "                            all_data.append(data_point)\n",
    "            \n",
    "            elif isinstance(mustard_data, list):\n",
    "                for item in mustard_data:\n",
    "                    if isinstance(item, dict):\n",
    "                        text = item.get('utterance', '') or item.get('text', '')\n",
    "                        sarcasm = item.get('sarcasm', False) or item.get('sarcastic', False)\n",
    "                        \n",
    "                        if text and len(text.strip()) > 0:\n",
    "                            data_point = {\n",
    "                                'text': text.strip(),\n",
    "                                'image_path': None,\n",
    "                                'sarcastic': 1 if sarcasm else 0,\n",
    "                                'dataset': 'mustard'\n",
    "                            }\n",
    "                            all_data.append(data_point)\n",
    "            \n",
    "            print(f\"Loaded {len([d for d in all_data if d['dataset'] == 'mustard'])} MUStARD samples\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading MUStARD: {e}\")\n",
    "        print(\"Continuing without MUStARD data...\")\n",
    "    \n",
    "    if not all_data:\n",
    "        print(\"No real data found, creating minimal synthetic data...\")\n",
    "        all_data = [\n",
    "            {'text': \"Oh wonderful, another Monday!\", 'image_path': None, 'sarcastic': 1, 'dataset': 'synthetic'},\n",
    "            {'text': \"I love waiting in traffic\", 'image_path': None, 'sarcastic': 1, 'dataset': 'synthetic'},\n",
    "            {'text': \"Thank you for your help\", 'image_path': None, 'sarcastic': 0, 'dataset': 'synthetic'},\n",
    "            {'text': \"Good morning everyone\", 'image_path': None, 'sarcastic': 0, 'dataset': 'synthetic'},\n",
    "        ] * 50\n",
    "    \n",
    "    df = pd.DataFrame(all_data)\n",
    "    \n",
    "    print(f\"\\nFinal dataset info:\")\n",
    "    print(f\"Total samples: {len(df)}\")\n",
    "    print(f\"Class distribution:\")\n",
    "    print(df['sarcastic'].value_counts())\n",
    "    print(f\"Dataset sources:\")\n",
    "    print(df['dataset'].value_counts())\n",
    "    \n",
    "    return df\n",
    "\n",
    "# =============================================\n",
    "# Fast Dataset with Real Data\n",
    "# =============================================\n",
    "\n",
    "class FastRealSarcasmDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, transform=None, max_length=64, balance_data=True):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.transform = transform or self._get_default_transform()\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        if balance_data:\n",
    "            self.data = self._balance_data(data)\n",
    "        else:\n",
    "            self.data = data.reset_index(drop=True)\n",
    "        \n",
    "        print(f\"Dataset size: {len(self.data)}\")\n",
    "        print(f\"Sarcastic: {self.data['sarcastic'].sum()}\")\n",
    "        print(f\"Non-sarcastic: {len(self.data) - self.data['sarcastic'].sum()}\")\n",
    "    \n",
    "    def _get_default_transform(self):\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    def _balance_data(self, data):\n",
    "        print(\"Balancing dataset...\")\n",
    "        \n",
    "        sarcastic_data = data[data['sarcastic'] == 1]\n",
    "        non_sarcastic_data = data[data['sarcastic'] == 0]\n",
    "        \n",
    "        print(f\"Original - Sarcastic: {len(sarcastic_data)}, Non-sarcastic: {len(non_sarcastic_data)}\")\n",
    "        \n",
    "        if len(sarcastic_data) < len(non_sarcastic_data):\n",
    "            n_needed = len(non_sarcastic_data) - len(sarcastic_data)\n",
    "            oversampled = sarcastic_data.sample(n=n_needed, replace=True, random_state=42)\n",
    "            balanced_data = pd.concat([data, oversampled], ignore_index=True)\n",
    "        elif len(non_sarcastic_data) < len(sarcastic_data):\n",
    "            n_needed = len(sarcastic_data) - len(non_sarcastic_data)\n",
    "            oversampled = non_sarcastic_data.sample(n=n_needed, replace=True, random_state=42)\n",
    "            balanced_data = pd.concat([data, oversampled], ignore_index=True)\n",
    "        else:\n",
    "            balanced_data = data\n",
    "        \n",
    "        return balanced_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data.iloc[idx]\n",
    "        \n",
    "        text = str(item['text'])\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        image = torch.zeros(3, 224, 224)\n",
    "        if pd.notna(item.get('image_path')) and os.path.exists(str(item['image_path'])):\n",
    "            try:\n",
    "                image = Image.open(item['image_path']).convert('RGB')\n",
    "                image = self.transform(image)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        label = int(item['sarcastic'])\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
    "            'image': image,\n",
    "            'label': torch.tensor(label, dtype=torch.long),\n",
    "            'text': text\n",
    "        }\n",
    "\n",
    "# =============================================\n",
    "# Enhanced Fast Model with Image Support\n",
    "# =============================================\n",
    "\n",
    "class FastMultimodalHCI_EASD(nn.Module):\n",
    "    def __init__(self, num_classes=2, hidden_size=256, use_images=True):\n",
    "        super(FastMultimodalHCI_EASD, self).__init__()\n",
    "        \n",
    "        self.use_images = use_images\n",
    "        \n",
    "        self.text_encoder = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        \n",
    "        for param in self.text_encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        for param in self.text_encoder.transformer.layer[-2:].parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        text_dim = 768\n",
    "        \n",
    "        if self.use_images:\n",
    "            self.image_encoder = nn.Sequential(\n",
    "                nn.Conv2d(3, 32, 7, stride=4),\n",
    "                nn.ReLU(),\n",
    "                nn.AdaptiveAvgPool2d((4, 4)),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(32 * 16, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128, 64)\n",
    "            )\n",
    "            image_dim = 64\n",
    "        else:\n",
    "            image_dim = 0\n",
    "        \n",
    "        self.text_projection = nn.Linear(text_dim, hidden_size)\n",
    "        \n",
    "        if self.use_images:\n",
    "            self.image_projection = nn.Linear(image_dim, hidden_size)\n",
    "            fusion_dim = hidden_size * 2\n",
    "        else:\n",
    "            fusion_dim = hidden_size\n",
    "        \n",
    "        self.incongruity_head = nn.Sequential(\n",
    "            nn.Linear(fusion_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(fusion_dim + 1, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_size, hidden_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_size // 2, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, images=None):\n",
    "        text_outputs = self.text_encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        text_features = text_outputs.last_hidden_state.mean(dim=1)\n",
    "        text_proj = self.text_projection(text_features)\n",
    "        \n",
    "        if self.use_images and images is not None:\n",
    "            image_features = self.image_encoder(images)\n",
    "            image_proj = self.image_projection(image_features)\n",
    "            \n",
    "            combined_features = torch.cat([text_proj, image_proj], dim=1)\n",
    "        else:\n",
    "            combined_features = text_proj\n",
    "        \n",
    "        incongruity = self.incongruity_head(combined_features)\n",
    "        \n",
    "        final_features = torch.cat([combined_features, incongruity], dim=1)\n",
    "        logits = self.classifier(final_features)\n",
    "        \n",
    "        return {\n",
    "            'logits': logits,\n",
    "            'incongruity_score': incongruity\n",
    "        }\n",
    "\n",
    "# =============================================\n",
    "# Fast Training with Real Data\n",
    "# =============================================\n",
    "\n",
    "def train_fast_real(model, train_loader, val_loader, class_weights=None, num_epochs=8, lr=3e-4):\n",
    "    if class_weights is not None:\n",
    "        class_weights_tensor = torch.FloatTensor(class_weights).to(device)\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer, max_lr=lr, steps_per_epoch=len(train_loader),\n",
    "        epochs=num_epochs, pct_start=0.3\n",
    "    )\n",
    "    \n",
    "    scaler = torch.cuda.amp.GradScaler() if device.type == 'cuda' else None\n",
    "    \n",
    "    best_f1 = 0.0\n",
    "    history = {'train_loss': [], 'val_acc': [], 'val_f1': []}\n",
    "    \n",
    "    print(\"Starting fast training on real data...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "        for batch in pbar:\n",
    "            input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "            attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "            images = batch['image'].to(device, non_blocking=True)\n",
    "            labels = batch['label'].to(device, non_blocking=True)\n",
    "            \n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            \n",
    "            if scaler:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    outputs = model(input_ids, attention_mask, images)\n",
    "                    loss = criterion(outputs['logits'], labels)\n",
    "                \n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                outputs = model(input_ids, attention_mask, images)\n",
    "                loss = criterion(outputs['logits'], labels)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "            \n",
    "            scheduler.step()\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "        \n",
    "        model.eval()\n",
    "        val_preds, val_labels = [], []\n",
    "        val_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "                attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "                images = batch['image'].to(device, non_blocking=True)\n",
    "                labels = batch['label'].to(device, non_blocking=True)\n",
    "                \n",
    "                if scaler:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        outputs = model(input_ids, attention_mask, images)\n",
    "                        loss = criterion(outputs['logits'], labels)\n",
    "                else:\n",
    "                    outputs = model(input_ids, attention_mask, images)\n",
    "                    loss = criterion(outputs['logits'], labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                preds = torch.argmax(outputs['logits'], dim=1)\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_acc = accuracy_score(val_labels, val_preds)\n",
    "        val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "        \n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_f1'].append(val_f1)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}: Train Loss={avg_train_loss:.4f}, \"\n",
    "              f\"Val Loss={avg_val_loss:.4f}, Val Acc={val_acc:.4f}, Val F1={val_f1:.4f}\")\n",
    "        \n",
    "        if val_f1 > best_f1:\n",
    "            best_f1 = val_f1\n",
    "            torch.save(model.state_dict(), 'fast_real_model.pt')\n",
    "            print(f\"New best model saved! F1: {best_f1:.4f}\")\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Training completed in {elapsed:.2f} seconds!\")\n",
    "    print(f\"Best F1-Score: {best_f1:.4f}\")\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "# =============================================\n",
    "# Evaluation and Analysis Functions (Corrected and Advanced)\n",
    "# =============================================\n",
    "\n",
    "def evaluate_real_model(model, test_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds, all_labels = [], []\n",
    "    all_probs = []\n",
    "    incongruity_scores = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc='Evaluating'):\n",
    "            input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "            attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "            images = batch['image'].to(device, non_blocking=True)\n",
    "            labels = batch['label'].to(device, non_blocking=True)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask, images)\n",
    "            \n",
    "            probs = F.softmax(outputs['logits'], dim=1)\n",
    "            preds = torch.argmax(outputs['logits'], dim=1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            incongruity_scores.extend(outputs['incongruity_score'].cpu().numpy())\n",
    "    \n",
    "    eval_time = time.time() - start_time\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1_weighted = f1_score(all_labels, all_preds, average='weighted')\n",
    "    f1_per_class = f1_score(all_labels, all_preds, average=None)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"REAL DATA EVALUATION RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Evaluation time: {eval_time:.2f} seconds\")\n",
    "    print(f\"Samples per second: {len(all_labels)/eval_time:.1f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Weighted F1-Score: {f1_weighted:.4f}\")\n",
    "    \n",
    "    if len(f1_per_class) == 2:\n",
    "        print(f\"Non-Sarcastic F1: {f1_per_class[0]:.4f}\")\n",
    "        print(f\"Sarcastic F1: {f1_per_class[1]:.4f}\")\n",
    "    \n",
    "    sarcastic_inc = np.array(incongruity_scores)[np.array(all_labels) == 1]\n",
    "    non_sarcastic_inc = np.array(incongruity_scores)[np.array(all_labels) == 0]\n",
    "    \n",
    "    if len(sarcastic_inc) > 0 and len(non_sarcastic_inc) > 0:\n",
    "        print(f\"\\nIncongruity Analysis:\")\n",
    "        print(f\"Sarcastic mean: {np.mean(sarcastic_inc):.3f} ± {np.std(sarcastic_inc):.3f}\")\n",
    "        print(f\"Non-sarcastic mean: {np.mean(non_sarcastic_inc):.3f} ± {np.std(non_sarcastic_inc):.3f}\")\n",
    "        print(f\"Difference: {np.mean(sarcastic_inc) - np.mean(non_sarcastic_inc):.3f}\")\n",
    "    \n",
    "    print(\"\\nDetailed Classification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, \n",
    "                              target_names=['Non-Sarcastic', 'Sarcastic']))\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1_weighted': f1_weighted,\n",
    "        'f1_per_class': f1_per_class,\n",
    "        'eval_time': eval_time,\n",
    "        'predictions': all_preds,\n",
    "        'labels': all_labels,\n",
    "        'probabilities': all_probs,\n",
    "        'incongruity_scores': incongruity_scores\n",
    "    }\n",
    "\n",
    "def plot_confusion_matrix(labels, preds, class_names=['Non-Sarcastic', 'Sarcastic']):\n",
    "    cm = confusion_matrix(labels, preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_roc_curve(labels, probs, class_names=['Non-Sarcastic', 'Sarcastic']):\n",
    "    probs = np.array(probs)\n",
    "    fpr, tpr, _ = roc_curve(labels, probs[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'Receiver Operating Characteristic (ROC) Curve for {class_names[1]}')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "def analyze_incongruity_scores(labels, incongruity_scores, preds, class_names=['Non-Sarcastic', 'Sarcastic']):\n",
    "    labels = np.array(labels)\n",
    "    incongruity_scores = np.array(incongruity_scores).flatten()\n",
    "    preds = np.array(preds)\n",
    "    \n",
    "    sarcastic_scores = incongruity_scores[labels == 1]\n",
    "    non_sarcastic_scores = incongruity_scores[labels == 0]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x=[class_names[1]] * len(sarcastic_scores) + [class_names[0]] * len(non_sarcastic_scores),\n",
    "                y=np.concatenate([sarcastic_scores, non_sarcastic_scores]),\n",
    "                palette='Set2')\n",
    "    plt.title('Incongruity Scores by True Class')\n",
    "    plt.ylabel('Incongruity Score')\n",
    "    plt.xlabel('True Class')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nIncongruity Score Statistics:\")\n",
    "    print(f\"Mean score for {class_names[1]}: {np.mean(sarcastic_scores):.4f} +/- {np.std(sarcastic_scores):.4f}\")\n",
    "    print(f\"Mean score for {class_names[0]}: {np.mean(non_sarcastic_scores):.4f} +/- {np.std(non_sarcastic_scores):.4f}\")\n",
    "    \n",
    "    correct_preds_scores = incongruity_scores[labels == preds]\n",
    "    incorrect_preds_scores = incongruity_scores[labels != preds]\n",
    "    \n",
    "    if len(correct_preds_scores) > 0 and len(incorrect_preds_scores) > 0:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.histplot(correct_preds_scores, color='green', label='Correct Predictions', kde=True)\n",
    "        sns.histplot(incorrect_preds_scores, color='red', label='Incorrect Predictions', kde=True)\n",
    "        plt.title('Incongruity Score Distribution: Correct vs. Incorrect Predictions')\n",
    "        plt.xlabel('Incongruity Score')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "def plot_confidence_distribution(labels, probs, class_names=['Non-Sarcastic', 'Sarcastic']):\n",
    "    probs = np.array(probs)\n",
    "    sarcastic_probs = probs[np.array(labels) == 1]\n",
    "    non_sarcastic_probs = probs[np.array(labels) == 0]\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(sarcastic_probs[:, 1], bins=20, kde=True, color='red', label='Sarcastic')\n",
    "    plt.title(f'Sarcastic Predictions ({class_names[1]})')\n",
    "    plt.xlabel('Predicted Probability of Sarcasm')\n",
    "    plt.ylabel('Count')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.histplot(non_sarcastic_probs[:, 1], bins=20, kde=True, color='blue', label='Non-Sarcastic')\n",
    "    plt.title(f'Non-Sarcastic Predictions ({class_names[0]})')\n",
    "    plt.xlabel('Predicted Probability of Sarcasm')\n",
    "    plt.ylabel('Count')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_calibration_curve(labels, probs, n_bins=10):\n",
    "    probs = np.array(probs)\n",
    "    positive_probs = probs[:, 1]\n",
    "    \n",
    "    bins = np.linspace(0.0, 1.0, n_bins + 1)\n",
    "    bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "    \n",
    "    correctness = []\n",
    "    confidence = []\n",
    "    \n",
    "    for i in range(n_bins):\n",
    "        in_bin = (positive_probs > bins[i]) & (positive_probs <= bins[i+1])\n",
    "        if np.sum(in_bin) > 0:\n",
    "            avg_prob = np.mean(positive_probs[in_bin])\n",
    "            avg_correct = np.mean(labels[in_bin] == 1)\n",
    "            correctness.append(avg_correct)\n",
    "            confidence.append(avg_prob)\n",
    "            \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n",
    "    plt.plot(confidence, correctness, \"s-\", label=\"Model\")\n",
    "    plt.xlabel(\"Mean Predicted Probability\")\n",
    "    plt.ylabel(\"Fraction of Positives\")\n",
    "    plt.title(\"Calibration Plot\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def analyze_incongruity_by_error(labels, preds, incongruity_scores):\n",
    "    labels = np.array(labels)\n",
    "    preds = np.array(preds)\n",
    "    incongruity_scores = np.array(incongruity_scores).flatten()\n",
    "    \n",
    "    correct_sarcastic_inc = incongruity_scores[(labels == 1) & (preds == 1)]\n",
    "    incorrect_sarcastic_inc = incongruity_scores[(labels == 1) & (preds == 0)]\n",
    "    \n",
    "    correct_non_sarcastic_inc = incongruity_scores[(labels == 0) & (preds == 0)]\n",
    "    incorrect_non_sarcastic_inc = incongruity_scores[(labels == 0) & (preds == 1)]\n",
    "    \n",
    "    print(\"\\n--- Incongruity Score Analysis by Prediction Error ---\")\n",
    "    print(f\"Correctly predicted Sarcastic (TP): {np.mean(correct_sarcastic_inc):.4f} +/- {np.std(correct_sarcastic_inc):.4f}\")\n",
    "    print(f\"Incorrectly predicted Sarcastic (FN): {np.mean(incorrect_sarcastic_inc):.4f} +/- {np.std(incorrect_sarcastic_inc):.4f}\")\n",
    "    print(f\"Correctly predicted Non-Sarcastic (TN): {np.mean(correct_non_sarcastic_inc):.4f} +/- {np.std(correct_non_sarcastic_inc):.4f}\")\n",
    "    print(f\"Incorrectly predicted Non-Sarcastic (FP): {np.mean(incorrect_non_sarcastic_inc):.4f} +/- {np.std(incorrect_non_sarcastic_inc):.4f}\")\n",
    "\n",
    "def show_misclassified_examples(test_df, labels, preds, num_examples=5, class_names=['Non-Sarcastic', 'Sarcastic']):\n",
    "    misclassified_indices = [i for i, (true, pred) in enumerate(zip(labels, preds)) if true != pred]\n",
    "    \n",
    "    print(f\"\\n--- Showing {num_examples} Misclassified Examples ---\")\n",
    "    for i in range(min(num_examples, len(misclassified_indices))):\n",
    "        idx = misclassified_indices[i]\n",
    "        sample = test_df.iloc[idx]\n",
    "        print(f\"\\nExample {i+1}:\")\n",
    "        print(f\"Text: {sample['text']}\")\n",
    "        print(f\"True Label: {'Sarcastic' if sample['sarcastic'] == 1 else 'Non-Sarcastic'}\")\n",
    "        print(f\"Predicted Label: {'Sarcastic' if preds[idx] == 1 else 'Non-Sarcastic'}\")\n",
    "        if pd.notna(sample.get('image_path')):\n",
    "            print(f\"Image Path: {sample['image_path']}\")\n",
    "    \n",
    "    if len(misclassified_indices) == 0:\n",
    "        print(\"No misclassified examples to show. The model achieved 100% accuracy!\")\n",
    "\n",
    "def categorize_errors(test_df, labels, preds, num_examples=5, class_names=['Non-Sarcastic', 'Sarcastic']):\n",
    "    labels = np.array(labels)\n",
    "    preds = np.array(preds)\n",
    "    \n",
    "    false_positives_idx = np.where((labels == 0) & (preds == 1))[0]\n",
    "    false_negatives_idx = np.where((labels == 1) & (preds == 0))[0]\n",
    "    \n",
    "    print(\"\\n--- False Positive Examples (Predicted Sarcastic, True Non-Sarcastic) ---\")\n",
    "    for i in range(min(num_examples, len(false_positives_idx))):\n",
    "        idx = false_positives_idx[i]\n",
    "        sample = test_df.iloc[idx]\n",
    "        print(f\"\\nExample {i+1}:\")\n",
    "        print(f\"Text: {sample['text']}\")\n",
    "        print(f\"Predicted Label: {class_names[1]}, True Label: {class_names[0]}\")\n",
    "    \n",
    "    print(\"\\n--- False Negative Examples (Predicted Non-Sarcastic, True Sarcastic) ---\")\n",
    "    for i in range(min(num_examples, len(false_negatives_idx))):\n",
    "        idx = false_negatives_idx[i]\n",
    "        sample = test_df.iloc[idx]\n",
    "        print(f\"\\nExample {i+1}:\")\n",
    "        print(f\"Text: {sample['text']}\")\n",
    "        print(f\"Predicted Label: {class_names[0]}, True Label: {class_names[1]}\")\n",
    "\n",
    "def plot_incongruity_vs_probability(labels, probs, incongruity_scores, class_names=['Non-Sarcastic', 'Sarcastic']):\n",
    "    probs = np.array(probs)\n",
    "    incongruity_scores = np.array(incongruity_scores).flatten()\n",
    "    \n",
    "    positive_probs = probs[:, 1]\n",
    "    \n",
    "    sarcastic_probs = positive_probs[np.array(labels) == 1]\n",
    "    sarcastic_incongruity = incongruity_scores[np.array(labels) == 1]\n",
    "    \n",
    "    non_sarcastic_probs = positive_probs[np.array(labels) == 0]\n",
    "    non_sarcastic_incongruity = incongruity_scores[np.array(labels) == 0]\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    plt.scatter(non_sarcastic_incongruity, non_sarcastic_probs, alpha=0.6, s=50, \n",
    "                label=f'True {class_names[0]}', color='blue', edgecolors='k')\n",
    "    plt.scatter(sarcastic_incongruity, sarcastic_probs, alpha=0.6, s=50, \n",
    "                label=f'True {class_names[1]}', color='red', edgecolors='k')\n",
    "    \n",
    "    plt.title('Incongruity Score vs. Sarcasm Prediction Probability')\n",
    "    plt.xlabel('Incongruity Score')\n",
    "    plt.ylabel('Predicted Probability of Sarcasm')\n",
    "    plt.legend()\n",
    "    plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    plt.show()\n",
    "\n",
    "def visualize_error_distribution_incongruity(labels, preds, incongruity_scores, class_names=['Non-Sarcastic', 'Sarcastic']):\n",
    "    labels = np.array(labels)\n",
    "    preds = np.array(preds)\n",
    "    incongruity_scores = np.array(incongruity_scores).flatten()\n",
    "    \n",
    "    tp = incongruity_scores[(labels == 1) & (preds == 1)]\n",
    "    fn = incongruity_scores[(labels == 1) & (preds == 0)]\n",
    "    tn = incongruity_scores[(labels == 0) & (preds == 0)]\n",
    "    fp = incongruity_scores[(labels == 0) & (preds == 1)]\n",
    "    \n",
    "    data = [tp, fn, tn, fp]\n",
    "    labels_list = ['True Positives', 'False Negatives', 'True Negatives', 'False Positives']\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.violinplot(data=data, palette=['green', 'red', 'lightgreen', 'orange'])\n",
    "    plt.xticks(ticks=np.arange(4), labels=labels_list)\n",
    "    plt.title('Distribution of Incongruity Scores by Prediction Outcome')\n",
    "    plt.ylabel('Incongruity Score')\n",
    "    plt.show()\n",
    "\n",
    "def analyze_by_confidence_bins(labels, probs, n_bins=10):\n",
    "    labels = np.array(labels)\n",
    "    probs = np.array(probs)[:, 1]\n",
    "    \n",
    "    bins = np.linspace(0.0, 1.0, n_bins + 1)\n",
    "    bin_labels = [f\"({bins[i]:.2f}-{bins[i+1]:.2f}]\" for i in range(n_bins)]\n",
    "    \n",
    "    print(\"\\n--- Model Performance by Confidence Interval ---\")\n",
    "    print(f\"{'Confidence Interval':<25}{'Total Samples':<15}{'Accuracy':<15}{'Error Rate':<15}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for i in range(n_bins):\n",
    "        lower_bound, upper_bound = bins[i], bins[i+1]\n",
    "        \n",
    "        if i == n_bins - 1:\n",
    "            indices = np.where((probs > lower_bound) & (probs <= upper_bound))\n",
    "        else:\n",
    "            indices = np.where((probs >= lower_bound) & (probs < upper_bound))\n",
    "        \n",
    "        bin_labels_subset = labels[indices]\n",
    "        bin_probs_subset = probs[indices]\n",
    "        \n",
    "        if len(bin_labels_subset) > 0:\n",
    "            bin_preds = (bin_probs_subset > 0.5).astype(int)\n",
    "            accuracy = accuracy_score(bin_labels_subset, bin_preds)\n",
    "            error_rate = 1 - accuracy\n",
    "            \n",
    "            print(f\"{bin_labels[i]:<25}{len(bin_labels_subset):<15}{accuracy:<15.4f}{error_rate:<15.4f}\")\n",
    "        else:\n",
    "            print(f\"{bin_labels[i]:<25}{0:<15}{'-':<15}{'-':<15}\")\n",
    "    \n",
    "def advanced_results_analysis(results, test_df):\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ADVANCED RESULTS ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    all_labels = results['labels']\n",
    "    all_preds = results['predictions']\n",
    "    all_probs = results['probabilities']\n",
    "    incongruity_scores = results['incongruity_scores']\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=None)\n",
    "    print(\"\\n--- Detailed Metrics per Class ---\")\n",
    "    print(f\"{'Class':<15}{'Precision':<15}{'Recall':<15}{'F1-Score':<15}\")\n",
    "    print(\"---------------------------------------------------------\")\n",
    "    print(f\"{'Non-Sarcastic':<15}{precision[0]:<15.4f}{recall[0]:<15.4f}{f1[0]:<15.4f}\")\n",
    "    print(f\"{'Sarcastic':<15}{precision[1]:<15.4f}{recall[1]:<15.4f}{f1[1]:<15.4f}\")\n",
    "    \n",
    "    print(\"\\n--- Generating Visualizations ---\")\n",
    "    plot_confusion_matrix(all_labels, all_preds)\n",
    "    plot_roc_curve(all_labels, all_probs)\n",
    "    analyze_incongruity_scores(all_labels, incongruity_scores, all_preds)\n",
    "    \n",
    "    print(\"\\n--- Generating More Advanced Visualizations ---\")\n",
    "    plot_confidence_distribution(all_labels, all_probs)\n",
    "    plot_calibration_curve(all_labels, all_probs)\n",
    "    plot_incongruity_vs_probability(all_labels, all_probs, incongruity_scores)\n",
    "    visualize_error_distribution_incongruity(all_labels, all_preds, incongruity_scores)\n",
    "    \n",
    "    print(\"\\n--- Deeper Quantitative Analysis ---\")\n",
    "    analyze_incongruity_by_error(all_labels, all_preds, incongruity_scores)\n",
    "    analyze_by_confidence_bins(all_labels, all_probs)\n",
    "    \n",
    "    show_misclassified_examples(test_df.reset_index(drop=True), all_labels, all_preds)\n",
    "    categorize_errors(test_df.reset_index(drop=True), all_labels, all_preds)\n",
    "\n",
    "# =============================================\n",
    "# Main Execution\n",
    "# =============================================\n",
    "\n",
    "def main_real_data():\n",
    "    print(\"FAST HCI-EASD WITH REAL MEMOTION & MUSTARD DATA\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    total_start = time.time()\n",
    "    \n",
    "    df = load_real_datasets()\n",
    "    \n",
    "    if len(df) < 10:\n",
    "        print(\"Insufficient real data found. Please check dataset paths.\")\n",
    "        return\n",
    "    \n",
    "    train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42, stratify=df['sarcastic'])\n",
    "    val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df['sarcastic'])\n",
    "    \n",
    "    print(f\"\\nData splits:\")\n",
    "    print(f\"Train: {len(train_df)} samples\")\n",
    "    print(f\"Validation: {len(val_df)} samples\")\n",
    "    print(f\"Test: {len(test_df)} samples\")\n",
    "    \n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    \n",
    "    train_dataset = FastRealSarcasmDataset(train_df, tokenizer, balance_data=True)\n",
    "    val_dataset = FastRealSarcasmDataset(val_df, tokenizer, balance_data=False)\n",
    "    test_dataset = FastRealSarcasmDataset(test_df, tokenizer, balance_data=False)\n",
    "    \n",
    "    train_labels = [train_dataset[i]['label'].item() for i in range(len(train_dataset))]\n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
    "    print(f\"Class weights: {class_weights}\")\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    \n",
    "    has_images = any(pd.notna(df['image_path']) for _, df in df.iterrows())\n",
    "    print(f\"Using images: {has_images}\")\n",
    "    \n",
    "    model = FastMultimodalHCI_EASD(use_images=has_images).to(device)\n",
    "    \n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"\\nModel info:\")\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "    print(f\"Trainable ratio: {trainable_params/total_params:.1%}\")\n",
    "    \n",
    "    print(f\"\\nStarting training...\")\n",
    "    model, history = train_fast_real(model, train_loader, val_loader, class_weights)\n",
    "    \n",
    "    model.load_state_dict(torch.load('fast_real_model.pt'))\n",
    "    results = evaluate_real_model(model, test_loader)\n",
    "    \n",
    "    advanced_results_analysis(results, test_df)\n",
    "    \n",
    "    total_time = time.time() - total_start\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*70)\n",
    "    print(\"FINAL SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Total execution time: {total_time:.2f} seconds\")\n",
    "    print(f\"Dataset size: {len(df)} samples\")\n",
    "    print(f\"Final accuracy: {results['accuracy']:.4f}\")\n",
    "    print(f\"Final F1-score: {results['f1_weighted']:.4f}\")\n",
    "    if len(results['f1_per_class']) == 2:\n",
    "        print(f\"Sarcastic F1: {results['f1_per_class'][1]:.4f}\")\n",
    "    print(f\"Inference speed: {len(test_df)/results['eval_time']:.1f} samples/sec\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        main_real_data()\n",
    "        print(\"\\n🚀 SUCCESS! All analysis complete.\")\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(\"\\nIt seems one or more of your dataset files could not be found.\")\n",
    "        print(\"Please ensure the following paths are correct and accessible:\")\n",
    "        print(\"- /kaggle/input/memotion-dataset-7k/memotion_dataset_7k/labels.csv\")\n",
    "        print(\"- /kaggle/input/memotion-dataset-7k/memotion_dataset_7k/reference.csv\") \n",
    "        print(\"- /kaggle/input/mustard-multimodal-sarcasm-detection-dataset/sarcasm_data.json\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c165b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T16:20:53.379208Z",
     "iopub.status.busy": "2025-08-06T16:20:53.378844Z",
     "iopub.status.idle": "2025-08-06T16:21:16.376800Z",
     "shell.execute_reply": "2025-08-06T16:21:16.376035Z",
     "shell.execute_reply.started": "2025-08-06T16:20:53.379185Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    " # =============================================\n",
    "# Specialized Analysis Tools and Advanced Plots for HCI-EASD\n",
    "# =============================================\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.metrics import brier_score_loss\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "from wordcloud import WordCloud\n",
    "from matplotlib.patches import Rectangle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =============================================\n",
    "# Advanced Performance Analysis\n",
    "# =============================================\n",
    "\n",
    "class AdvancedPerformanceAnalyzer:\n",
    "    \"\"\"Advanced performance analysis tools\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f']\n",
    "    \n",
    "    def plot_calibration_analysis(self, y_true, y_prob, save_prefix='calibration'):\n",
    "        \"\"\"Plot model calibration analysis\"\"\"\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        \n",
    "        # 1. Calibration plot\n",
    "        fraction_of_positives, mean_predicted_value = calibration_curve(\n",
    "            y_true, y_prob[:, 1], n_bins=10\n",
    "        )\n",
    "        \n",
    "        axes[0,0].plot(mean_predicted_value, fraction_of_positives, \"s-\", \n",
    "                      color=self.colors[0], label=\"Model\", linewidth=2, markersize=8)\n",
    "        axes[0,0].plot([0, 1], [0, 1], \"k--\", alpha=0.7, label=\"Perfect calibration\")\n",
    "        \n",
    "        # Calculate calibration error\n",
    "        calibration_error = np.mean(np.abs(fraction_of_positives - mean_predicted_value))\n",
    "        \n",
    "        axes[0,0].set_xlabel('Mean Predicted Probability')\n",
    "        axes[0,0].set_ylabel('Fraction of Positives')\n",
    "        axes[0,0].set_title(f'Calibration Plot\\nCalibration Error: {calibration_error:.4f}')\n",
    "        axes[0,0].legend()\n",
    "        axes[0,0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 2. Reliability diagram with histogram\n",
    "        bin_boundaries = np.linspace(0, 1, 11)\n",
    "        bin_lowers = bin_boundaries[:-1]\n",
    "        bin_uppers = bin_boundaries[1:]\n",
    "        \n",
    "        # Calculate calibration for each bin\n",
    "        bin_accuracies = []\n",
    "        bin_confidences = []\n",
    "        bin_counts = []\n",
    "        \n",
    "        for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
    "            in_bin = (y_prob[:, 1] > bin_lower) & (y_prob[:, 1] <= bin_upper)\n",
    "            prop_in_bin = in_bin.mean()\n",
    "            \n",
    "            if prop_in_bin > 0:\n",
    "                accuracy_in_bin = y_true[in_bin].mean()\n",
    "                avg_confidence_in_bin = y_prob[in_bin, 1].mean()\n",
    "                bin_accuracies.append(accuracy_in_bin)\n",
    "                bin_confidences.append(avg_confidence_in_bin)\n",
    "                bin_counts.append(in_bin.sum())\n",
    "            else:\n",
    "                bin_accuracies.append(0)\n",
    "                bin_confidences.append((bin_lower + bin_upper) / 2)\n",
    "                bin_counts.append(0)\n",
    "        \n",
    "        # Plot reliability diagram\n",
    "        axes[0,1].bar(bin_confidences, bin_accuracies, width=0.08, alpha=0.7, \n",
    "                     color=self.colors[1], edgecolor='black', label='Accuracy')\n",
    "        axes[0,1].plot([0, 1], [0, 1], 'k--', alpha=0.7, label='Perfect calibration')\n",
    "        \n",
    "        # Add count annotations\n",
    "        for i, (conf, acc, count) in enumerate(zip(bin_confidences, bin_accuracies, bin_counts)):\n",
    "            if count > 0:\n",
    "                axes[0,1].text(conf, acc + 0.02, str(count), ha='center', va='bottom', fontsize=8)\n",
    "        \n",
    "        axes[0,1].set_xlabel('Confidence')\n",
    "        axes[0,1].set_ylabel('Accuracy')\n",
    "        axes[0,1].set_title('Reliability Diagram')\n",
    "        axes[0,1].legend()\n",
    "        axes[0,1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 3. Confidence histogram\n",
    "        axes[1,0].hist(y_prob[y_true == 0, 1], bins=20, alpha=0.7, \n",
    "                      label='Non-Sarcastic', color=self.colors[2], density=True)\n",
    "        axes[1,0].hist(y_prob[y_true == 1, 1], bins=20, alpha=0.7, \n",
    "                      label='Sarcastic', color=self.colors[3], density=True)\n",
    "        axes[1,0].set_xlabel('Predicted Probability')\n",
    "        axes[1,0].set_ylabel('Density')\n",
    "        axes[1,0].set_title('Confidence Distribution by Class')\n",
    "        axes[1,0].legend()\n",
    "        axes[1,0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 4. Brier score decomposition\n",
    "        brier_score = brier_score_loss(y_true, y_prob[:, 1])\n",
    "        \n",
    "        # Calculate components\n",
    "        reliability = np.sum(bin_counts * (np.array(bin_accuracies) - np.array(bin_confidences))**2) / len(y_true)\n",
    "        resolution = np.sum(bin_counts * (np.array(bin_accuracies) - y_true.mean())**2) / len(y_true)\n",
    "        uncertainty = y_true.mean() * (1 - y_true.mean())\n",
    "        \n",
    "        components = ['Brier Score', 'Reliability', 'Resolution', 'Uncertainty']\n",
    "        values = [brier_score, reliability, resolution, uncertainty]\n",
    "        \n",
    "        bars = axes[1,1].bar(components, values, color=self.colors[:4], alpha=0.7)\n",
    "        axes[1,1].set_ylabel('Score')\n",
    "        axes[1,1].set_title('Brier Score Decomposition')\n",
    "        axes[1,1].grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar, value in zip(bars, values):\n",
    "            axes[1,1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,\n",
    "                         f'{value:.4f}', ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{save_prefix}_calibration_analysis.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        return {\n",
    "            'calibration_error': calibration_error,\n",
    "            'brier_score': brier_score,\n",
    "            'reliability': reliability,\n",
    "            'resolution': resolution,\n",
    "            'uncertainty': uncertainty\n",
    "        }\n",
    "    \n",
    "    def plot_threshold_analysis(self, y_true, y_prob, save_prefix='threshold'):\n",
    "        \"\"\"Analyze performance across different decision thresholds\"\"\"\n",
    "        \n",
    "        thresholds = np.linspace(0, 1, 101)\n",
    "        metrics = {'precision': [], 'recall': [], 'f1': [], 'accuracy': [], 'specificity': []}\n",
    "        \n",
    "        for threshold in thresholds:\n",
    "            y_pred = (y_prob[:, 1] >= threshold).astype(int)\n",
    "            \n",
    "            tp = np.sum((y_pred == 1) & (y_true == 1))\n",
    "            fp = np.sum((y_pred == 1) & (y_true == 0))\n",
    "            tn = np.sum((y_pred == 0) & (y_true == 0))\n",
    "            fn = np.sum((y_pred == 0) & (y_true == 1))\n",
    "            \n",
    "            precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "            recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "            f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "            accuracy = (tp + tn) / len(y_true)\n",
    "            specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "            \n",
    "            metrics['precision'].append(precision)\n",
    "            metrics['recall'].append(recall)\n",
    "            metrics['f1'].append(f1)\n",
    "            metrics['accuracy'].append(accuracy)\n",
    "            metrics['specificity'].append(specificity)\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        \n",
    "        # 1. All metrics vs threshold\n",
    "        for i, (metric_name, values) in enumerate(metrics.items()):\n",
    "            axes[0,0].plot(thresholds, values, label=metric_name.capitalize(), \n",
    "                          color=self.colors[i], linewidth=2)\n",
    "        \n",
    "        axes[0,0].set_xlabel('Threshold')\n",
    "        axes[0,0].set_ylabel('Score')\n",
    "        axes[0,0].set_title('Performance Metrics vs Threshold')\n",
    "        axes[0,0].legend()\n",
    "        axes[0,0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Find optimal threshold for F1\n",
    "        optimal_f1_idx = np.argmax(metrics['f1'])\n",
    "        optimal_threshold = thresholds[optimal_f1_idx]\n",
    "        axes[0,0].axvline(x=optimal_threshold, color='red', linestyle='--', \n",
    "                         label=f'Optimal F1 threshold: {optimal_threshold:.3f}')\n",
    "        axes[0,0].legend()\n",
    "        \n",
    "        # 2. Precision-Recall trade-off\n",
    "        axes[0,1].plot(metrics['recall'], metrics['precision'], \n",
    "                      color=self.colors[0], linewidth=3)\n",
    "        axes[0,1].set_xlabel('Recall')\n",
    "        axes[0,1].set_ylabel('Precision')\n",
    "        axes[0,1].set_title('Precision-Recall Trade-off')\n",
    "        axes[0,1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Mark optimal point\n",
    "        optimal_precision = metrics['precision'][optimal_f1_idx]\n",
    "        optimal_recall = metrics['recall'][optimal_f1_idx]\n",
    "        axes[0,1].scatter([optimal_recall], [optimal_precision], \n",
    "                         color='red', s=100, zorder=5, \n",
    "                         label=f'Optimal (P={optimal_precision:.3f}, R={optimal_recall:.3f})')\n",
    "        axes[0,1].legend()\n",
    "        \n",
    "        # 3. ROC-like plot (Sensitivity vs 1-Specificity)\n",
    "        fpr = [1 - spec for spec in metrics['specificity']]\n",
    "        axes[1,0].plot(fpr, metrics['recall'], color=self.colors[1], linewidth=3)\n",
    "        axes[1,0].plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
    "        axes[1,0].set_xlabel('1 - Specificity (FPR)')\n",
    "        axes[1,0].set_ylabel('Sensitivity (TPR)')\n",
    "        axes[1,0].set_title('ROC-like Curve')\n",
    "        axes[1,0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 4. Threshold distribution with optimal point\n",
    "        axes[1,1].hist(y_prob[:, 1], bins=50, alpha=0.7, color=self.colors[2], density=True)\n",
    "        axes[1,1].axvline(x=optimal_threshold, color='red', linestyle='--', linewidth=2,\n",
    "                         label=f'Optimal threshold: {optimal_threshold:.3f}')\n",
    "        axes[1,1].axvline(x=0.5, color='blue', linestyle='--', linewidth=2,\n",
    "                         label='Default threshold: 0.5')\n",
    "        axes[1,1].set_xlabel('Predicted Probability')\n",
    "        axes[1,1].set_ylabel('Density')\n",
    "        axes[1,1].set_title('Prediction Distribution with Thresholds')\n",
    "        axes[1,1].legend()\n",
    "        axes[1,1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{save_prefix}_threshold_analysis.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        return {\n",
    "            'optimal_threshold': optimal_threshold,\n",
    "            'optimal_f1': metrics['f1'][optimal_f1_idx],\n",
    "            'optimal_precision': optimal_precision,\n",
    "            'optimal_recall': optimal_recall,\n",
    "            'metrics_by_threshold': dict(zip(thresholds, zip(*metrics.values())))\n",
    "        }\n",
    "\n",
    "# =============================================\n",
    "# Interactive Visualization Tools\n",
    "# =============================================\n",
    "\n",
    "class InteractiveVisualizer:\n",
    "    \"\"\"Interactive visualization tools using Plotly\"\"\"\n",
    "    \n",
    "    def create_interactive_attention_heatmap(self, attention_weights, tokens, save_path='attention_interactive.html'):\n",
    "        \"\"\"Create interactive attention heatmap\"\"\"\n",
    "        \n",
    "        fig = go.Figure(data=go.Heatmap(\n",
    "            z=attention_weights,\n",
    "            x=tokens,\n",
    "            y=tokens,\n",
    "            colorscale='Reds',\n",
    "            hoverongaps=False,\n",
    "            hovertemplate='Query: %{y}<br>Key: %{x}<br>Attention: %{z:.4f}<extra></extra>'\n",
    "        ))\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title='Interactive Attention Heatmap',\n",
    "            xaxis_title='Key Tokens',\n",
    "            yaxis_title='Query Tokens',\n",
    "            width=800,\n",
    "            height=600\n",
    "        )\n",
    "        \n",
    "        fig.write_html(save_path)\n",
    "        return fig\n",
    "    \n",
    "    def create_3d_feature_plot(self, features, labels, feature_names, save_path='features_3d.html'):\n",
    "        \"\"\"Create 3D feature visualization\"\"\"\n",
    "        \n",
    "        from sklearn.decomposition import PCA\n",
    "        \n",
    "        if features.shape[1] > 3:\n",
    "            pca = PCA(n_components=3)\n",
    "            features_3d = pca.fit_transform(features)\n",
    "            feature_names = [f'PC{i+1} ({pca.explained_variance_ratio_[i]:.3f})' \n",
    "                           for i in range(3)]\n",
    "        else:\n",
    "            features_3d = features[:, :3]\n",
    "        \n",
    "        colors = ['blue' if label == 0 else 'red' for label in labels]\n",
    "        \n",
    "        fig = go.Figure(data=go.Scatter3d(\n",
    "            x=features_3d[:, 0],\n",
    "            y=features_3d[:, 1],\n",
    "            z=features_3d[:, 2],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=5,\n",
    "                color=colors,\n",
    "                opacity=0.7\n",
    "            ),\n",
    "            text=[f'Sample {i}: {\"Sarcastic\" if labels[i] else \"Non-Sarcastic\"}' \n",
    "                  for i in range(len(labels))],\n",
    "            hovertemplate='%{text}<br>%{xaxis.title.text}: %{x:.3f}<br>%{yaxis.title.text}: %{y:.3f}<br>%{zaxis.title.text}: %{z:.3f}<extra></extra>'\n",
    "        ))\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title='3D Feature Visualization',\n",
    "            scene=dict(\n",
    "                xaxis_title=feature_names[0],\n",
    "                yaxis_title=feature_names[1],\n",
    "                zaxis_title=feature_names[2]\n",
    "            ),\n",
    "            width=900,\n",
    "            height=700\n",
    "        )\n",
    "        \n",
    "        fig.write_html(save_path)\n",
    "        return fig\n",
    "    \n",
    "    def create_performance_dashboard(self, results_dict, save_path='dashboard.html'):\n",
    "        \"\"\"Create interactive performance dashboard\"\"\"\n",
    "        \n",
    "        fig = make_subplots(\n",
    "            rows=2, cols=2,\n",
    "            subplot_titles=('Model Comparison', 'Metrics Over Time', \n",
    "                          'Feature Importance', 'Error Analysis'),\n",
    "            specs=[[{'type': 'bar'}, {'type': 'scatter'}],\n",
    "                   [{'type': 'bar'}, {'type': 'heatmap'}]]\n",
    "        )\n",
    "        \n",
    "        # Model comparison\n",
    "        models = list(results_dict.keys())\n",
    "        accuracies = [results_dict[model].get('accuracy', 0) for model in models]\n",
    "        f1_scores = [results_dict[model].get('f1_score', 0) for model in models]\n",
    "        \n",
    "        fig.add_trace(go.Bar(name='Accuracy', x=models, y=accuracies), row=1, col=1)\n",
    "        fig.add_trace(go.Bar(name='F1-Score', x=models, y=f1_scores), row=1, col=1)\n",
    "        \n",
    "        # Metrics over time (dummy data for demo)\n",
    "        epochs = list(range(1, 11))\n",
    "        train_acc = [0.5 + 0.03*i + np.random.normal(0, 0.01) for i in epochs]\n",
    "        val_acc = [0.5 + 0.025*i + np.random.normal(0, 0.02) for i in epochs]\n",
    "        \n",
    "        fig.add_trace(go.Scatter(x=epochs, y=train_acc, name='Train Acc', mode='lines+markers'), row=1, col=2)\n",
    "        fig.add_trace(go.Scatter(x=epochs, y=val_acc, name='Val Acc', mode='lines+markers'), row=1, col=2)\n",
    "        \n",
    "        # Feature importance\n",
    "        features = ['Text', 'Image', 'Emotion', 'Attention', 'Incongruity']\n",
    "        importance = [0.35, 0.25, 0.15, 0.15, 0.10]\n",
    "        \n",
    "        fig.add_trace(go.Bar(x=features, y=importance, name='Importance'), row=2, col=1)\n",
    "        \n",
    "        # Error analysis heatmap\n",
    "        error_matrix = np.random.rand(5, 5)\n",
    "        fig.add_trace(go.Heatmap(z=error_matrix, colorscale='Reds'), row=2, col=2)\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title='HCI-EASD Performance Dashboard',\n",
    "            showlegend=True,\n",
    "            height=800\n",
    "        )\n",
    "        \n",
    "        fig.write_html(save_path)\n",
    "        return fig\n",
    "\n",
    "# =============================================\n",
    "# Text Analysis and Visualization\n",
    "# =============================================\n",
    "\n",
    "class TextAnalysisVisualizer:\n",
    "    \"\"\"Specialized text analysis and visualization\"\"\"\n",
    "    \n",
    "    def plot_sarcasm_patterns(self, texts, labels, predictions, save_prefix='text_analysis'):\n",
    "        \"\"\"Analyze and visualize sarcasm patterns in text\"\"\"\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        \n",
    "        # 1. Text length analysis\n",
    "        text_lengths = [len(text.split()) for text in texts]\n",
    "        sarcastic_lengths = [length for length, label in zip(text_lengths, labels) if label == 1]\n",
    "        non_sarcastic_lengths = [length for length, label in zip(text_lengths, labels) if label == 0]\n",
    "        \n",
    "        axes[0,0].hist(non_sarcastic_lengths, bins=30, alpha=0.7, label='Non-Sarcastic', density=True)\n",
    "        axes[0,0].hist(sarcastic_lengths, bins=30, alpha=0.7, label='Sarcastic', density=True)\n",
    "        axes[0,0].set_xlabel('Text Length (words)')\n",
    "        axes[0,0].set_ylabel('Density')\n",
    "        axes[0,0].set_title('Text Length Distribution')\n",
    "        axes[0,0].legend()\n",
    "        axes[0,0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Statistical test\n",
    "        from scipy.stats import mannwhitneyu\n",
    "        statistic, p_value = mannwhitneyu(sarcastic_lengths, non_sarcastic_lengths)\n",
    "        axes[0,0].text(0.7, 0.8, f'Mann-Whitney U\\np-value: {p_value:.3f}', \n",
    "                      transform=axes[0,0].transAxes, bbox=dict(boxstyle='round', facecolor='yellow'))\n",
    "        \n",
    "        # 2. Common words analysis\n",
    "        from collections import Counter\n",
    "        import re\n",
    "        \n",
    "        def extract_words(text_list):\n",
    "            words = []\n",
    "            for text in text_list:\n",
    "                words.extend(re.findall(r'\\b[a-zA-Z]+\\b', text.lower()))\n",
    "            return Counter(words)\n",
    "        \n",
    "        sarcastic_texts = [text for text, label in zip(texts, labels) if label == 1]\n",
    "        non_sarcastic_texts = [text for text, label in zip(texts, labels) if label == 0]\n",
    "        \n",
    "        sarcastic_words = extract_words(sarcastic_texts)\n",
    "        non_sarcastic_words = extract_words(non_sarcastic_texts)\n",
    "        \n",
    "        # Find words more common in sarcastic texts\n",
    "        common_words = set(sarcastic_words.keys()) & set(non_sarcastic_words.keys())\n",
    "        sarcasm_indicators = {}\n",
    "        \n",
    "        for word in common_words:\n",
    "            if sarcastic_words[word] > 5 and non_sarcastic_words[word] > 5:  # Minimum frequency\n",
    "                ratio = (sarcastic_words[word] / len(sarcastic_texts)) / (non_sarcastic_words[word] / len(non_sarcastic_texts))\n",
    "                if ratio > 1.5:  # At least 50% more frequent in sarcastic texts\n",
    "                    sarcasm_indicators[word] = ratio\n",
    "        \n",
    "        # Plot top sarcasm indicators\n",
    "        top_indicators = sorted(sarcasm_indicators.items(), key=lambda x: x[1], reverse=True)[:15]\n",
    "        if top_indicators:\n",
    "            words, ratios = zip(*top_indicators)\n",
    "            bars = axes[0,1].barh(range(len(words)), ratios, color='orange', alpha=0.7)\n",
    "            axes[0,1].set_yticks(range(len(words)))\n",
    "            axes[0,1].set_yticklabels(words)\n",
    "            axes[0,1].set_xlabel('Frequency Ratio (Sarcastic/Non-Sarcastic)')\n",
    "            axes[0,1].set_title('Top Sarcasm Indicator Words')\n",
    "            axes[0,1].grid(True, alpha=0.3, axis='x')\n",
    "            \n",
    "            # Add value labels\n",
    "            for i, (bar, ratio) in enumerate(zip(bars, ratios)):\n",
    "                axes[0,1].text(bar.get_width() + 0.05, bar.get_y() + bar.get_height()/2,\n",
    "                              f'{ratio:.2f}', va='center', fontsize=8)\n",
    "        \n",
    "        # 3. Punctuation analysis\n",
    "        punctuation_counts = {'!': [], '?': [], '...': [], 'ALL_CAPS': []}\n",
    "        \n",
    "        for text, label in zip(texts, labels):\n",
    "            punct_count = {\n",
    "                '!': text.count('!'),\n",
    "                '?': text.count('?'),\n",
    "                '...': text.count('...'),\n",
    "                'ALL_CAPS': len([word for word in text.split() if word.isupper() and len(word) > 2])\n",
    "            }\n",
    "            \n",
    "            for punct in punctuation_counts:\n",
    "                punctuation_counts[punct].append((punct_count[punct], label))\n",
    "        \n",
    "        # Plot punctuation usage\n",
    "        punct_names = list(punctuation_counts.keys())\n",
    "        sarc_punct = [[count for count, label in punctuation_counts[punct] if label == 1] for punct in punct_names]\n",
    "        non_sarc_punct = [[count for count, label in punctuation_counts[punct] if label == 0] for punct in punct_names]\n",
    "        \n",
    "        sarc_means = [np.mean(counts) if counts else 0 for counts in sarc_punct]\n",
    "        non_sarc_means = [np.mean(counts) if counts else 0 for counts in non_sarc_punct]\n",
    "        \n",
    "        x = np.arange(len(punct_names))\n",
    "        width = 0.35\n",
    "        \n",
    "        bars1 = axes[1,0].bar(x - width/2, non_sarc_means, width, label='Non-Sarcastic', alpha=0.8)\n",
    "        bars2 = axes[1,0].bar(x + width/2, sarc_means, width, label='Sarcastic', alpha=0.8)\n",
    "        \n",
    "        axes[1,0].set_xlabel('Punctuation Type')\n",
    "        axes[1,0].set_ylabel('Average Count per Text')\n",
    "        axes[1,0].set_title('Punctuation Usage Patterns')\n",
    "        axes[1,0].set_xticks(x)\n",
    "        axes[1,0].set_xticklabels(punct_names)\n",
    "        axes[1,0].legend()\n",
    "        axes[1,0].grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Add value labels\n",
    "        for bars in [bars1, bars2]:\n",
    "            for bar in bars:\n",
    "                height = bar.get_height()\n",
    "                axes[1,0].text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                              f'{height:.2f}', ha='center', va='bottom', fontsize=8)\n",
    "        \n",
    "        # 4. Sentiment polarity analysis (simplified)\n",
    "        def simple_sentiment(text):\n",
    "            positive_words = ['good', 'great', 'excellent', 'amazing', 'wonderful', 'fantastic', 'love']\n",
    "            negative_words = ['bad', 'terrible', 'awful', 'hate', 'horrible', 'disgusting', 'worst']\n",
    "            \n",
    "            words = text.lower().split()\n",
    "            pos_count = sum(1 for word in words if word in positive_words)\n",
    "            neg_count = sum(1 for word in words if word in negative_words)\n",
    "            \n",
    "            return pos_count - neg_count\n",
    "        \n",
    "        sentiments = [simple_sentiment(text) for text in texts]\n",
    "        sarc_sentiments = [sentiment for sentiment, label in zip(sentiments, labels) if label == 1]\n",
    "        non_sarc_sentiments = [sentiment for sentiment, label in zip(sentiments, labels) if label == 0]\n",
    "        \n",
    "        axes[1,1].boxplot([non_sarc_sentiments, sarc_sentiments], \n",
    "                         labels=['Non-Sarcastic', 'Sarcastic'])\n",
    "        axes[1,1].set_ylabel('Sentiment Polarity Score')\n",
    "        axes[1,1].set_title('Sentiment Polarity by Class')\n",
    "        axes[1,1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add means\n",
    "        axes[1,1].scatter([1, 2], [np.mean(non_sarc_sentiments), np.mean(sarc_sentiments)], \n",
    "                         color='red', s=100, zorder=5)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{save_prefix}_text_patterns.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        return {\n",
    "            'sarcasm_indicators': dict(top_indicators) if top_indicators else {},\n",
    "            'length_stats': {\n",
    "                'sarcastic_mean': np.mean(sarcastic_lengths),\n",
    "                'non_sarcastic_mean': np.mean(non_sarcastic_lengths),\n",
    "                'p_value': p_value\n",
    "            },\n",
    "            'punctuation_patterns': {\n",
    "                'sarcastic': dict(zip(punct_names, sarc_means)),\n",
    "                'non_sarcastic': dict(zip(punct_names, non_sarc_means))\n",
    "            },\n",
    "            'sentiment_analysis': {\n",
    "                'sarcastic_mean': np.mean(sarc_sentiments),\n",
    "                'non_sarcastic_mean': np.mean(non_sarc_sentiments)\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def create_word_clouds(self, texts, labels, save_prefix='wordcloud'):\n",
    "        \"\"\"Create word clouds for sarcastic and non-sarcastic texts\"\"\"\n",
    "        \n",
    "        sarcastic_texts = [text for text, label in zip(texts, labels) if label == 1]\n",
    "        non_sarcastic_texts = [text for text, label in zip(texts, labels) if label == 0]\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "        \n",
    "        # Non-sarcastic word cloud\n",
    "        if non_sarcastic_texts:\n",
    "            non_sarc_text = ' '.join(non_sarcastic_texts)\n",
    "            wordcloud_non_sarc = WordCloud(width=800, height=400, \n",
    "                                         background_color='white',\n",
    "                                         colormap='Blues').generate(non_sarc_text)\n",
    "            \n",
    "            axes[0].imshow(wordcloud_non_sarc, interpolation='bilinear')\n",
    "            axes[0].set_title('Non-Sarcastic Texts Word Cloud', fontsize=16)\n",
    "            axes[0].axis('off')\n",
    "        \n",
    "        # Sarcastic word cloud\n",
    "        if sarcastic_texts:\n",
    "            sarc_text = ' '.join(sarcastic_texts)\n",
    "            wordcloud_sarc = WordCloud(width=800, height=400, \n",
    "                                     background_color='white',\n",
    "                                     colormap='Reds').generate(sarc_text)\n",
    "            \n",
    "            axes[1].imshow(wordcloud_sarc, interpolation='bilinear')\n",
    "            axes[1].set_title('Sarcastic Texts Word Cloud', fontsize=16)\n",
    "            axes[1].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{save_prefix}_wordclouds.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        return fig\n",
    "\n",
    "# =============================================\n",
    "# Error Analysis Tools\n",
    "# =============================================\n",
    "\n",
    "class ErrorAnalysisTools:\n",
    "    \"\"\"Advanced error analysis and debugging tools\"\"\"\n",
    "    \n",
    "    def analyze_prediction_errors(self, texts, labels, predictions, probabilities, \n",
    "                                 incongruity_scores, save_prefix='error_analysis'):\n",
    "        \"\"\"Comprehensive error analysis\"\"\"\n",
    "        \n",
    "        # Identify different types of errors\n",
    "        correct_mask = (predictions == labels)\n",
    "        false_positives = (predictions == 1) & (labels == 0)\n",
    "        false_negatives = (predictions == 0) & (labels == 1)\n",
    "        true_positives = (predictions == 1) & (labels == 1)\n",
    "        true_negatives = (predictions == 0) & (labels == 0)\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "        \n",
    "        # 1. Error distribution by confidence\n",
    "        conf_scores = np.max(probabilities, axis=1)\n",
    "        \n",
    "        axes[0,0].scatter(conf_scores[true_positives], incongruity_scores[true_positives], \n",
    "                         c='green', alpha=0.6, label='True Positive', s=30)\n",
    "        axes[0,0].scatter(conf_scores[true_negatives], incongruity_scores[true_negatives], \n",
    "                         c='blue', alpha=0.6, label='True Negative', s=30)\n",
    "        axes[0,0].scatter(conf_scores[false_positives], incongruity_scores[false_positives], \n",
    "                         c='red', alpha=0.8, label='False Positive', s=50)\n",
    "        axes[0,0].scatter(conf_scores[false_negatives], incongruity_scores[false_negatives], \n",
    "                         c='orange', alpha=0.8, label='False Negative', s=50)\n",
    "        \n",
    "        axes[0,0].set_xlabel('Confidence Score')\n",
    "        axes[0,0].set_ylabel('Incongruity Score')\n",
    "        axes[0,0].set_title('Error Analysis: Confidence vs Incongruity')\n",
    "        axes[0,0].legend()\n",
    "        axes[0,0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 2. Error types distribution\n",
    "        error_counts = [\n",
    "            np.sum(true_positives), np.sum(true_negatives),\n",
    "            np.sum(false_positives), np.sum(false_negatives)\n",
    "        ]\n",
    "        error_labels = ['True Positive', 'True Negative', 'False Positive', 'False Negative']\n",
    "        colors = ['green', 'blue', 'red', 'orange']\n",
    "        \n",
    "        wedges, texts_pie, autotexts = axes[0,1].pie(error_counts, labels=error_labels, \n",
    "                                                    colors=colors, autopct='%1.1f%%', \n",
    "                                                    startangle=90)\n",
    "        axes[0,1].set_title('Prediction Distribution')\n",
    "        \n",
    "        # 3. Confidence distribution by error type\n",
    "        fp_conf = conf_scores[false_positives]\n",
    "        fn_conf = conf_scores[false_negatives]\n",
    "        tp_conf = conf_scores[true_positives]\n",
    "        tn_conf = conf_scores[true_negatives]\n",
    "        \n",
    "        axes[0,2].hist([tp_conf, tn_conf, fp_conf, fn_conf], \n",
    "                      bins=20, alpha=0.7, label=error_labels, \n",
    "                      color=colors, density=True)\n",
    "        axes[0,2].set_xlabel('Confidence Score')\n",
    "        axes[0,2].set_ylabel('Density')\n",
    "        axes[0,2].set_title('Confidence Distribution by Error Type')\n",
    "        axes[0,2].legend()\n",
    "        axes[0,2].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 4. Text length analysis for errors\n",
    "        text_lengths = np.array([len(text.split()) for text in texts])\n",
    "        \n",
    "        length_data = [\n",
    "            text_lengths[true_positives], text_lengths[true_negatives],\n",
    "            text_lengths[false_positives], text_lengths[false_negatives]\n",
    "        ]\n",
    "        \n",
    "        axes[1,0].boxplot(length_data, labels=['TP', 'TN', 'FP', 'FN'])\n",
    "        axes[1,0].set_ylabel('Text Length (words)')\n",
    "        axes[1,0].set_title('Text Length by Prediction Type')\n",
    "        axes[1,0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 5. Hardest examples analysis\n",
    "        # Define \"hardness\" as low confidence correct predictions or high confidence wrong predictions\n",
    "        hardness_scores = np.where(correct_mask, 1 - conf_scores, conf_scores)\n",
    "        hardest_indices = np.argsort(hardness_scores)[-20:]  # Top 20 hardest\n",
    "        \n",
    "        hardest_confs = conf_scores[hardest_indices]\n",
    "        hardest_correct = correct_mask[hardest_indices]\n",
    "        \n",
    "        colors_hard = ['red' if not correct else 'orange' for correct in hardest_correct]\n",
    "        bars = axes[1,1].bar(range(len(hardest_indices)), hardest_confs, \n",
    "                           color=colors_hard, alpha=0.7)\n",
    "        axes[1,1].set_xlabel('Hardest Examples (ranked)')\n",
    "        axes[1,1].set_ylabel('Confidence Score')\n",
    "        axes[1,1].set_title('Hardest Examples Analysis')\n",
    "        axes[1,1].grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # 6. Error correlation matrix\n",
    "        error_features = np.column_stack([\n",
    "            conf_scores, \n",
    "            incongruity_scores.flatten(),\n",
    "            text_lengths,\n",
    "            probabilities[:, 1],  # sarcasm probability\n",
    "            correct_mask.astype(int)\n",
    "        ])\n",
    "        \n",
    "        corr_matrix = np.corrcoef(error_features.T)\n",
    "        \n",
    "        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, ax=axes[1,2],\n",
    "                   xticklabels=['Confidence', 'Incongruity', 'Length', 'Sarc_Prob', 'Correct'],\n",
    "                   yticklabels=['Confidence', 'Incongruity', 'Length', 'Sarc_Prob', 'Correct'])\n",
    "        axes[1,2].set_title('Error Feature Correlation')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{save_prefix}_error_analysis.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        # Extract hardest examples text for further analysis\n",
    "        hardest_examples = []\n",
    "        for idx in hardest_indices[-10:]:  # Top 10 hardest\n",
    "            hardest_examples.append({\n",
    "                'text': texts[idx],\n",
    "                'true_label': 'Sarcastic' if labels[idx] else 'Non-Sarcastic',\n",
    "                'predicted_label': 'Sarcastic' if predictions[idx] else 'Non-Sarcastic',\n",
    "                'confidence': conf_scores[idx],\n",
    "                'incongruity_score': incongruity_scores[idx],\n",
    "                'sarcasm_probability': probabilities[idx, 1]\n",
    "            })\n",
    "        \n",
    "        return {\n",
    "            'error_distribution': dict(zip(error_labels, error_counts)),\n",
    "            'hardest_examples': hardest_examples,\n",
    "            'correlation_matrix': corr_matrix\n",
    "        }\n",
    "\n",
    "# =============================================\n",
    "# Model Interpretability Tools\n",
    "# =============================================\n",
    "\n",
    "class ModelInterpretabilityTools:\n",
    "    \"\"\"Tools for model interpretability and explainability\"\"\"\n",
    "    \n",
    "    def plot_feature_attribution(self, sample_features, feature_names, \n",
    "                                attribution_scores, save_prefix='attribution'):\n",
    "        \"\"\"Plot feature attribution analysis\"\"\"\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        \n",
    "        # 1. Feature importance bar plot\n",
    "        sorted_idx = np.argsort(np.abs(attribution_scores))[-20:]  # Top 20\n",
    "        sorted_scores = attribution_scores[sorted_idx]\n",
    "        sorted_names = [feature_names[i] for i in sorted_idx]\n",
    "        \n",
    "        colors = ['red' if score < 0 else 'blue' for score in sorted_scores]\n",
    "        bars = axes[0,0].barh(range(len(sorted_scores)), sorted_scores, color=colors, alpha=0.7)\n",
    "        axes[0,0].set_yticks(range(len(sorted_names)))\n",
    "        axes[0,0].set_yticklabels(sorted_names, fontsize=8)\n",
    "        axes[0,0].set_xlabel('Attribution Score')\n",
    "        axes[0,0].set_title('Feature Attribution (Top 20)')\n",
    "        axes[0,0].grid(True, alpha=0.3, axis='x')\n",
    "        axes[0,0].axvline(x=0, color='black', linestyle='-', alpha=0.5)\n",
    "        \n",
    "        # 2. Attribution distribution\n",
    "        axes[0,1].hist(attribution_scores, bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "        axes[0,1].axvline(x=np.mean(attribution_scores), color='red', linestyle='--', \n",
    "                         label=f'Mean: {np.mean(attribution_scores):.4f}')\n",
    "        axes[0,1].axvline(x=np.median(attribution_scores), color='green', linestyle='--', \n",
    "                         label=f'Median: {np.median(attribution_scores):.4f}')\n",
    "        axes[0,1].set_xlabel('Attribution Score')\n",
    "        axes[0,1].set_ylabel('Frequency')\n",
    "        axes[0,1].set_title('Attribution Score Distribution')\n",
    "        axes[0,1].legend()\n",
    "        axes[0,1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 3. Feature value vs attribution scatter\n",
    "        if len(sample_features) > 20:\n",
    "            top_indices = sorted_idx[-10:]  # Top 10 for clarity\n",
    "            top_features = sample_features[top_indices]\n",
    "            top_attributions = attribution_scores[top_indices]\n",
    "            top_names_scatter = [feature_names[i] for i in top_indices]\n",
    "        else:\n",
    "            top_features = sample_features\n",
    "            top_attributions = attribution_scores\n",
    "            top_names_scatter = feature_names\n",
    "        \n",
    "        colors_scatter = ['red' if attr < 0 else 'blue' for attr in top_attributions]\n",
    "        scatter = axes[1,0].scatter(top_features, top_attributions, \n",
    "                                   c=colors_scatter, s=60, alpha=0.7)\n",
    "        \n",
    "        # Add feature names as annotations\n",
    "        for i, name in enumerate(top_names_scatter):\n",
    "            axes[1,0].annotate(name, (top_features[i], top_attributions[i]), \n",
    "                              xytext=(5, 5), textcoords='offset points', \n",
    "                              fontsize=8, alpha=0.8)\n",
    "        \n",
    "        axes[1,0].set_xlabel('Feature Value')\n",
    "        axes[1,0].set_ylabel('Attribution Score')\n",
    "        axes[1,0].set_title('Feature Value vs Attribution')\n",
    "        axes[1,0].grid(True, alpha=0.3)\n",
    "        axes[1,0].axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "        \n",
    "        # 4. Cumulative attribution\n",
    "        cumulative_attr = np.cumsum(np.sort(np.abs(attribution_scores))[::-1])\n",
    "        cumulative_attr_norm = cumulative_attr / cumulative_attr[-1]\n",
    "        \n",
    "        axes[1,1].plot(range(1, len(cumulative_attr_norm) + 1), cumulative_attr_norm, \n",
    "                      'b-', linewidth=2)\n",
    "        axes[1,1].axhline(y=0.8, color='red', linestyle='--', \n",
    "                         label='80% threshold')\n",
    "        axes[1,1].axhline(y=0.9, color='orange', linestyle='--', \n",
    "                         label='90% threshold')\n",
    "        \n",
    "        # Find 80% and 90% points\n",
    "        idx_80 = np.argmax(cumulative_attr_norm >= 0.8)\n",
    "        idx_90 = np.argmax(cumulative_attr_norm >= 0.9)\n",
    "        \n",
    "        axes[1,1].axvline(x=idx_80, color='red', linestyle=':', alpha=0.7)\n",
    "        axes[1,1].axvline(x=idx_90, color='orange', linestyle=':', alpha=0.7)\n",
    "        \n",
    "        axes[1,1].set_xlabel('Number of Features')\n",
    "        axes[1,1].set_ylabel('Cumulative Attribution (normalized)')\n",
    "        axes[1,1].set_title('Cumulative Feature Attribution')\n",
    "        axes[1,1].legend()\n",
    "        axes[1,1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add text annotations for key points\n",
    "        axes[1,1].text(idx_80, 0.82, f'{idx_80} features\\n(80%)', ha='center', va='bottom', \n",
    "                      bbox=dict(boxstyle='round,pad=0.3', facecolor='red', alpha=0.3))\n",
    "        axes[1,1].text(idx_90, 0.92, f'{idx_90} features\\n(90%)', ha='center', va='bottom',\n",
    "                      bbox=dict(boxstyle='round,pad=0.3', facecolor='orange', alpha=0.3))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{save_prefix}_feature_attribution.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        return {\n",
    "            'top_positive_features': [(feature_names[i], attribution_scores[i]) \n",
    "                                    for i in sorted_idx[-10:] if attribution_scores[i] > 0],\n",
    "            'top_negative_features': [(feature_names[i], attribution_scores[i]) \n",
    "                                    for i in sorted_idx[-10:] if attribution_scores[i] < 0],\n",
    "            'features_for_80_percent': idx_80,\n",
    "            'features_for_90_percent': idx_90\n",
    "        }\n",
    "    \n",
    "    def create_lime_explanation_plot(self, text, tokens, lime_scores, prediction, \n",
    "                                   save_prefix='lime_explanation'):\n",
    "        \"\"\"Create LIME-style explanation visualization\"\"\"\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "        \n",
    "        # 1. Token importance visualization\n",
    "        colors = ['red' if score < 0 else 'green' for score in lime_scores]\n",
    "        alphas = [min(abs(score) * 2, 1.0) for score in lime_scores]  # Normalize for alpha\n",
    "        \n",
    "        bars = axes[0].barh(range(len(tokens)), lime_scores, \n",
    "                           color=colors, alpha=0.7)\n",
    "        axes[0].set_yticks(range(len(tokens)))\n",
    "        axes[0].set_yticklabels(tokens, fontsize=10)\n",
    "        axes[0].set_xlabel('Importance Score')\n",
    "        axes[0].set_title(f'Token Importance for Prediction: {prediction}\\n'\n",
    "                         f'Text: \"{text[:100]}...\"')\n",
    "        axes[0].grid(True, alpha=0.3, axis='x')\n",
    "        axes[0].axvline(x=0, color='black', linestyle='-', alpha=0.5)\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar, score in zip(bars, lime_scores):\n",
    "            width = bar.get_width()\n",
    "            axes[0].text(width + (0.01 if width >= 0 else -0.01), \n",
    "                        bar.get_y() + bar.get_height()/2,\n",
    "                        f'{score:.3f}', ha='left' if width >= 0 else 'right', \n",
    "                        va='center', fontsize=8)\n",
    "        \n",
    "        # 2. Text highlighting visualization\n",
    "        # Create a text visualization with color-coded importance\n",
    "        ax_text = axes[1]\n",
    "        ax_text.set_xlim(0, 10)\n",
    "        ax_text.set_ylim(0, 1)\n",
    "        ax_text.axis('off')\n",
    "        \n",
    "        # Split text into lines for better visualization\n",
    "        words_per_line = 15\n",
    "        lines = [tokens[i:i+words_per_line] for i in range(0, len(tokens), words_per_line)]\n",
    "        line_scores = [lime_scores[i:i+words_per_line] for i in range(0, len(lime_scores), words_per_line)]\n",
    "        \n",
    "        for line_idx, (line, scores) in enumerate(zip(lines, line_scores)):\n",
    "            y_pos = 0.9 - line_idx * 0.15\n",
    "            x_pos = 0.1\n",
    "            \n",
    "            for word, score in zip(line, scores):\n",
    "                # Determine color and intensity\n",
    "                if score > 0:\n",
    "                    color = 'green'\n",
    "                    alpha = min(score * 2, 1.0)\n",
    "                else:\n",
    "                    color = 'red'\n",
    "                    alpha = min(abs(score) * 2, 1.0)\n",
    "                \n",
    "                # Add highlighted background\n",
    "                bbox_props = dict(boxstyle=\"round,pad=0.1\", facecolor=color, alpha=alpha * 0.3)\n",
    "                ax_text.text(x_pos, y_pos, word, fontsize=12, \n",
    "                           bbox=bbox_props, ha='left', va='center')\n",
    "                \n",
    "                # Update x position (rough estimate)\n",
    "                x_pos += len(word) * 0.08 + 0.1\n",
    "                if x_pos > 9:  # Wrap to next line if needed\n",
    "                    break\n",
    "        \n",
    "        axes[1].set_title('Text with Importance Highlighting\\n'\n",
    "                         'Green: Supports prediction, Red: Opposes prediction')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{save_prefix}_lime_explanation.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        return fig\n",
    "\n",
    "# =============================================\n",
    "# Advanced Statistical Tests\n",
    "# =============================================\n",
    "\n",
    "class AdvancedStatisticalTests:\n",
    "    \"\"\"Advanced statistical tests for model evaluation\"\"\"\n",
    "    \n",
    "    def permutation_test(self, metric_func, y_true, y_pred1, y_pred2, n_permutations=10000):\n",
    "        \"\"\"Permutation test to compare two models\"\"\"\n",
    "        \n",
    "        # Original difference\n",
    "        original_diff = metric_func(y_true, y_pred1) - metric_func(y_true, y_pred2)\n",
    "        \n",
    "        # Permutation test\n",
    "        differences = []\n",
    "        for _ in range(n_permutations):\n",
    "            # Randomly swap predictions between models\n",
    "            mask = np.random.choice([True, False], size=len(y_true))\n",
    "            perm_pred1 = np.where(mask, y_pred1, y_pred2)\n",
    "            perm_pred2 = np.where(mask, y_pred2, y_pred1)\n",
    "            \n",
    "            diff = metric_func(y_true, perm_pred1) - metric_func(y_true, perm_pred2)\n",
    "            differences.append(diff)\n",
    "        \n",
    "        # Calculate p-value\n",
    "        p_value = np.mean(np.abs(differences) >= np.abs(original_diff))\n",
    "        \n",
    "        return {\n",
    "            'original_difference': original_diff,\n",
    "            'p_value': p_value,\n",
    "            'permutation_differences': differences\n",
    "        }\n",
    "    \n",
    "    def cross_validation_paired_t_test(self, scores1, scores2):\n",
    "        \"\"\"Paired t-test for cross-validation scores\"\"\"\n",
    "        from scipy.stats import ttest_rel\n",
    "        \n",
    "        differences = np.array(scores1) - np.array(scores2)\n",
    "        statistic, p_value = ttest_rel(scores1, scores2)\n",
    "        \n",
    "        return {\n",
    "            'mean_difference': np.mean(differences),\n",
    "            'std_difference': np.std(differences),\n",
    "            'statistic': statistic,\n",
    "            'p_value': p_value,\n",
    "            'cohen_d': np.mean(differences) / np.std(differences)\n",
    "        }\n",
    "    \n",
    "    def wilcoxon_signed_rank_test(self, scores1, scores2):\n",
    "        \"\"\"Non-parametric alternative to paired t-test\"\"\"\n",
    "        from scipy.stats import wilcoxon\n",
    "        \n",
    "        differences = np.array(scores1) - np.array(scores2)\n",
    "        statistic, p_value = wilcoxon(scores1, scores2, alternative='two-sided')\n",
    "        \n",
    "        return {\n",
    "            'statistic': statistic,\n",
    "            'p_value': p_value,\n",
    "            'median_difference': np.median(differences),\n",
    "            'effect_size': np.median(differences) / np.std(differences)  # Rough effect size\n",
    "        }\n",
    "\n",
    "# =============================================\n",
    "# Comprehensive Demo Function\n",
    "# =============================================\n",
    "\n",
    "def run_specialized_analysis_demo():\n",
    "    \"\"\"Run demonstration of all specialized analysis tools\"\"\"\n",
    "    \n",
    "    print(\"HCI-EASD Specialized Analysis Tools Demo\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Generate dummy data for demonstration\n",
    "    np.random.seed(42)\n",
    "    n_samples = 1000\n",
    "    \n",
    "    # Dummy data\n",
    "    y_true = np.random.choice([0, 1], n_samples, p=[0.6, 0.4])\n",
    "    y_prob = np.random.rand(n_samples, 2)\n",
    "    y_prob = y_prob / y_prob.sum(axis=1, keepdims=True)  # Normalize\n",
    "    y_pred = np.argmax(y_prob, axis=1)\n",
    "    \n",
    "    # Add some correlation with true labels for realistic results\n",
    "    y_prob[y_true == 1, 1] += np.random.normal(0.2, 0.1, np.sum(y_true == 1))\n",
    "    y_prob[y_true == 0, 0] += np.random.normal(0.2, 0.1, np.sum(y_true == 0))\n",
    "    y_prob = np.clip(y_prob, 0, 1)\n",
    "    y_prob = y_prob / y_prob.sum(axis=1, keepdims=True)\n",
    "    \n",
    "    texts = [f\"Sample text {i} with some content\" for i in range(n_samples)]\n",
    "    incongruity_scores = np.random.rand(n_samples, 1)\n",
    "    features = np.random.rand(n_samples, 100)\n",
    "    \n",
    "    print(\"1. Advanced Performance Analysis\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    analyzer = AdvancedPerformanceAnalyzer()\n",
    "    \n",
    "    # Calibration analysis\n",
    "    calibration_results = analyzer.plot_calibration_analysis(y_true, y_prob, 'demo_calibration')\n",
    "    print(f\"   Calibration Error: {calibration_results['calibration_error']:.4f}\")\n",
    "    print(f\"   Brier Score: {calibration_results['brier_score']:.4f}\")\n",
    "    \n",
    "    # Threshold analysis\n",
    "    threshold_results = analyzer.plot_threshold_analysis(y_true, y_prob, 'demo_threshold')\n",
    "    print(f\"   Optimal Threshold: {threshold_results['optimal_threshold']:.3f}\")\n",
    "    print(f\"   Optimal F1-Score: {threshold_results['optimal_f1']:.4f}\")\n",
    "    \n",
    "    print(\"\\n2. Text Analysis\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    text_analyzer = TextAnalysisVisualizer()\n",
    "    \n",
    "    # Generate more realistic text for demo\n",
    "    sarcastic_phrases = [\"What a wonderful day\", \"Perfect timing\", \"Just great\", \n",
    "                        \"Oh fantastic\", \"Absolutely brilliant\"]\n",
    "    normal_phrases = [\"Good morning\", \"Thank you\", \"Nice weather\", \n",
    "                     \"Have a good day\", \"See you later\"]\n",
    "    \n",
    "    demo_texts = []\n",
    "    demo_labels = []\n",
    "    for i in range(200):\n",
    "        if np.random.rand() < 0.4:  # 40% sarcastic\n",
    "            text = np.random.choice(sarcastic_phrases) + f\" example {i}\"\n",
    "            label = 1\n",
    "        else:\n",
    "            text = np.random.choice(normal_phrases) + f\" sample {i}\"\n",
    "            label = 0\n",
    "        demo_texts.append(text)\n",
    "        demo_labels.append(label)\n",
    "    \n",
    "    demo_predictions = np.random.choice([0, 1], len(demo_texts))\n",
    "    \n",
    "    text_patterns = text_analyzer.plot_sarcasm_patterns(\n",
    "        demo_texts, demo_labels, demo_predictions, 'demo_text'\n",
    "    )\n",
    "    print(f\"   Found {len(text_patterns.get('sarcasm_indicators', {}))} sarcasm indicator words\")\n",
    "    \n",
    "    print(\"\\n3. Error Analysis\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    error_analyzer = ErrorAnalysisTools()\n",
    "    error_results = error_analyzer.analyze_prediction_errors(\n",
    "        texts[:200], y_true[:200], y_pred[:200], y_prob[:200], \n",
    "        incongruity_scores[:200], 'demo_errors'\n",
    "    )\n",
    "    print(f\"   Identified {len(error_results['hardest_examples'])} hardest examples\")\n",
    "    \n",
    "    print(\"\\n4. Model Interpretability\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    interp_tools = ModelInterpretabilityTools()\n",
    "    \n",
    "    # Feature attribution analysis\n",
    "    feature_names = [f'Feature_{i}' for i in range(100)]\n",
    "    attribution_scores = np.random.normal(0, 0.5, 100)  # Centered around 0\n",
    "    \n",
    "    attribution_results = interp_tools.plot_feature_attribution(\n",
    "        features[0], feature_names, attribution_scores, 'demo_attribution'\n",
    "    )\n",
    "    print(f\"   {attribution_results['features_for_80_percent']} features explain 80% of attribution\")\n",
    "    \n",
    "    # LIME explanation\n",
    "    sample_text = \"What a wonderful day this is turning out to be\"\n",
    "    tokens = sample_text.split()\n",
    "    lime_scores = np.random.normal(0, 0.3, len(tokens))\n",
    "    lime_scores[1] = 0.8  # \"wonderful\" gets high positive score\n",
    "    lime_scores[0] = -0.6  # \"What\" gets negative score (sarcastic indicator)\n",
    "    \n",
    "    interp_tools.create_lime_explanation_plot(\n",
    "        sample_text, tokens, lime_scores, \"Sarcastic (0.85)\", 'demo_lime'\n",
    "    )\n",
    "    \n",
    "    print(\"\\n5. Statistical Tests\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    stat_tests = AdvancedStatisticalTests()\n",
    "    \n",
    "    # Generate two model predictions for comparison\n",
    "    model1_pred = y_pred[:100]\n",
    "    model2_pred = np.random.choice([0, 1], 100)\n",
    "    y_true_subset = y_true[:100]\n",
    "    \n",
    "    from sklearn.metrics import accuracy_score\n",
    "    \n",
    "    perm_result = stat_tests.permutation_test(\n",
    "        accuracy_score, y_true_subset, model1_pred, model2_pred, n_permutations=1000\n",
    "    )\n",
    "    print(f\"   Permutation test p-value: {perm_result['p_value']:.4f}\")\n",
    "    \n",
    "    print(\"\\n6. Interactive Visualizations\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    interactive_viz = InteractiveVisualizer()\n",
    "    \n",
    "    # Create mock results for dashboard\n",
    "    mock_results = {\n",
    "        'model_a': {'accuracy': 0.85, 'f1_score': 0.83},\n",
    "        'model_b': {'accuracy': 0.82, 'f1_score': 0.80},\n",
    "        'model_c': {'accuracy': 0.88, 'f1_score': 0.86}\n",
    "    }\n",
    "    \n",
    "    dashboard_fig = interactive_viz.create_performance_dashboard(\n",
    "        mock_results, 'demo_dashboard.html'\n",
    "    )\n",
    "    print(\"   Created interactive dashboard: demo_dashboard.html\")\n",
    "    \n",
    "    # 3D feature visualization\n",
    "    feature_3d_fig = interactive_viz.create_3d_feature_plot(\n",
    "        features[:200, :3], y_true[:200], ['Feature_0', 'Feature_1', 'Feature_2'],\n",
    "        'demo_features_3d.html'\n",
    "    )\n",
    "    print(\"   Created 3D feature plot: demo_features_3d.html\")\n",
    "    \n",
    "    print(\"\\nSpecialized Analysis Demo Completed!\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"Summary of generated files:\")\n",
    "    print(\"- demo_calibration_calibration_analysis.png\")\n",
    "    print(\"- demo_threshold_threshold_analysis.png\") \n",
    "    print(\"- demo_text_text_patterns.png\")\n",
    "    print(\"- demo_errors_error_analysis.png\")\n",
    "    print(\"- demo_attribution_feature_attribution.png\")\n",
    "    print(\"- demo_lime_lime_explanation.png\")\n",
    "    print(\"- demo_dashboard.html\")\n",
    "    print(\"- demo_features_3d.html\")\n",
    "    \n",
    "    return {\n",
    "        'calibration_results': calibration_results,\n",
    "        'threshold_results': threshold_results,\n",
    "        'text_patterns': text_patterns,\n",
    "        'error_results': error_results,\n",
    "        'attribution_results': attribution_results,\n",
    "        'statistical_tests': perm_result\n",
    "    }\n",
    "\n",
    "# =============================================\n",
    "# Usage Instructions\n",
    "# =============================================\n",
    "\n",
    "def print_usage_instructions():\n",
    "    \"\"\"Print comprehensive usage instructions\"\"\"\n",
    "    \n",
    "    print(\"\\nHCI-EASD SPECIALIZED ANALYSIS TOOLS\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"\\nThis module provides advanced analysis tools for the HCI-EASD model:\")\n",
    "    print(\"\\n1. ADVANCED PERFORMANCE ANALYSIS\")\n",
    "    print(\"   - Model calibration analysis and reliability diagrams\")\n",
    "    print(\"   - Brier score decomposition\")\n",
    "    print(\"   - Threshold optimization analysis\")\n",
    "    print(\"   - Confidence distribution analysis\")\n",
    "    \n",
    "    print(\"\\n2. INTERACTIVE VISUALIZATIONS\")\n",
    "    print(\"   - Interactive attention heatmaps with Plotly\")\n",
    "    print(\"   - 3D feature space visualization\")\n",
    "    print(\"   - Performance dashboard with multiple metrics\")\n",
    "    \n",
    "    print(\"\\n3. TEXT ANALYSIS TOOLS\")\n",
    "    print(\"   - Sarcasm pattern detection in text\")\n",
    "    print(\"   - Word cloud generation for different classes\")\n",
    "    print(\"   - Punctuation and sentiment analysis\")\n",
    "    print(\"   - Statistical significance testing for text features\")\n",
    "    \n",
    "    print(\"\\n4. ERROR ANALYSIS\")\n",
    "    print(\"   - Comprehensive error type analysis\")\n",
    "    print(\"   - Hard example identification\")\n",
    "    print(\"   - Error correlation with model features\")\n",
    "    print(\"   - Confidence vs. correctness analysis\")\n",
    "    \n",
    "    print(\"\\n5. MODEL INTERPRETABILITY\")\n",
    "    print(\"   - Feature attribution visualization\")\n",
    "    print(\"   - LIME-style explanations\")\n",
    "    print(\"   - Token importance analysis\")\n",
    "    print(\"   - Cumulative feature importance\")\n",
    "    \n",
    "    print(\"\\n6. STATISTICAL TESTS\")\n",
    "    print(\"   - Permutation tests for model comparison\")\n",
    "    print(\"   - Paired t-tests for cross-validation\")\n",
    "    print(\"   - Wilcoxon signed-rank tests\")\n",
    "    print(\"   - Effect size calculations\")\n",
    "    \n",
    "    print(\"\\nUSAGE EXAMPLE:\")\n",
    "    print(\"-\"*20)\n",
    "    print(\"# Initialize analyzers\")\n",
    "    print(\"perf_analyzer = AdvancedPerformanceAnalyzer()\")\n",
    "    print(\"text_analyzer = TextAnalysisVisualizer()\")\n",
    "    print(\"error_analyzer = ErrorAnalysisTools()\")\n",
    "    print(\"interp_tools = ModelInterpretabilityTools()\")\n",
    "    print(\"\")\n",
    "    print(\"# Run analyses\")\n",
    "    print(\"calibration_results = perf_analyzer.plot_calibration_analysis(y_true, y_prob)\")\n",
    "    print(\"text_patterns = text_analyzer.plot_sarcasm_patterns(texts, labels, predictions)\")\n",
    "    print(\"error_analysis = error_analyzer.analyze_prediction_errors(...)\")\n",
    "    print(\"attribution = interp_tools.plot_feature_attribution(...)\")\n",
    "    \n",
    "    print(\"\\nTo run the complete demo:\")\n",
    "    print(\"results = run_specialized_analysis_demo()\")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    print_usage_instructions()\n",
    "    \n",
    "    # Ask user if they want to run the demo\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Run the specialized analysis demo? (This will generate example plots)\")\n",
    "    response = input(\"Enter 'y' to run demo, any other key to skip: \").lower()\n",
    "    \n",
    "    if response == 'y':\n",
    "        demo_results = run_specialized_analysis_demo()\n",
    "        print(f\"\\nDemo completed! Generated {len([k for k in demo_results.keys()])} analysis results.\")\n",
    "    else:\n",
    "        print(\"Demo skipped. Use the classes above with your real model data.\")\n",
    "        print(\"Remember to install required dependencies:\")\n",
    "        print(\"pip install plotly wordcloud scipy scikit-learn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c87b6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T16:18:33.759521Z",
     "iopub.status.busy": "2025-08-06T16:18:33.759136Z",
     "iopub.status.idle": "2025-08-06T16:18:33.763663Z",
     "shell.execute_reply": "2025-08-06T16:18:33.762810Z",
     "shell.execute_reply.started": "2025-08-06T16:18:33.759489Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "perf_analyzer = AdvancedPerformanceAnalyzer()\n",
    "text_analyzer = TextAnalysisVisualizer()\n",
    "error_analyzer = ErrorAnalysisTools()\n",
    "interp_tools = ModelInterpretabilityTools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6379e482",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T16:18:50.242063Z",
     "iopub.status.busy": "2025-08-06T16:18:50.241770Z",
     "iopub.status.idle": "2025-08-06T16:19:07.975239Z",
     "shell.execute_reply": "2025-08-06T16:19:07.974517Z",
     "shell.execute_reply.started": "2025-08-06T16:18:50.242042Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = run_specialized_analysis_demo()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0a502b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T16:39:31.569202Z",
     "iopub.status.busy": "2025-08-06T16:39:31.568842Z",
     "iopub.status.idle": "2025-08-06T16:39:31.645823Z",
     "shell.execute_reply": "2025-08-06T16:39:31.644898Z",
     "shell.execute_reply.started": "2025-08-06T16:39:31.569178Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import json\n",
    "import re\n",
    "from wordcloud import WordCloud\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# =============================================\n",
    "# Dataset Overview and Analysis\n",
    "# =============================================\n",
    "\n",
    "def analyze_datasets(memotion_labels_df, memotion_reference_df, mustard_data):\n",
    "    \"\"\"Complete analysis of MEMOTION and MUStARD datasets\"\"\"\n",
    "    \n",
    "    print(\"Starting comprehensive dataset analysis...\")\n",
    "    \n",
    "    # Merge MEMOTION datasets\n",
    "    memotion_df = pd.merge(memotion_labels_df, memotion_reference_df, on='image_name', how='inner')\n",
    "    \n",
    "    # Process MUStARD data\n",
    "    mustard_records = []\n",
    "    for key, value in mustard_data.items():\n",
    "        record = {\n",
    "            'id': key,\n",
    "            'text': value.get('utterance', ''),\n",
    "            'sarcastic': 1 if value.get('sarcasm', False) else 0,\n",
    "            'context': value.get('context', ''),\n",
    "            'speaker': value.get('speaker', ''),\n",
    "            'show': value.get('show', ''),\n",
    "        }\n",
    "        mustard_records.append(record)\n",
    "    mustard_df = pd.DataFrame(mustard_records)\n",
    "    \n",
    "    # Create comprehensive visualizations\n",
    "    create_dataset_overview_plots(memotion_df, mustard_df)\n",
    "    create_sarcasm_analysis_plots(memotion_df, mustard_df)\n",
    "    create_text_analysis_plots(memotion_df, mustard_df)\n",
    "    create_interactive_plots(memotion_df, mustard_df)\n",
    "    \n",
    "    return memotion_df, mustard_df\n",
    "\n",
    "def create_dataset_overview_plots(memotion_df, mustard_df):\n",
    "    \"\"\"Create dataset overview visualization\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    fig.suptitle('Dataset Overview Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Dataset sizes comparison\n",
    "    sizes = [len(memotion_df), len(mustard_df)]\n",
    "    names = ['MEMOTION', 'MUStARD']\n",
    "    colors = ['#FF6B6B', '#4ECDC4']\n",
    "    \n",
    "    bars = axes[0,0].bar(names, sizes, color=colors, alpha=0.8, edgecolor='black')\n",
    "    axes[0,0].set_title('Dataset Sizes', fontweight='bold')\n",
    "    axes[0,0].set_ylabel('Number of Samples')\n",
    "    axes[0,0].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, size in zip(bars, sizes):\n",
    "        axes[0,0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 50,\n",
    "                      f'{size:,}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # 2. MEMOTION sarcasm distribution\n",
    "    if 'sarcastic' in memotion_df.columns:\n",
    "        memotion_sarc = memotion_df['sarcastic'].value_counts()\n",
    "        labels = ['Non-Sarcastic', 'Sarcastic']\n",
    "        sizes_memo = [memotion_sarc.get(0, 0), memotion_sarc.get(1, 0)]\n",
    "        \n",
    "        wedges, texts, autotexts = axes[0,1].pie(sizes_memo, labels=labels, autopct='%1.1f%%',\n",
    "                                                colors=['lightblue', 'lightcoral'],\n",
    "                                                explode=(0, 0.1))\n",
    "        axes[0,1].set_title('MEMOTION: Sarcasm Distribution', fontweight='bold')\n",
    "    \n",
    "    # 3. MUStARD sarcasm distribution\n",
    "    mustard_sarc = mustard_df['sarcastic'].value_counts()\n",
    "    sizes_must = [mustard_sarc.get(0, 0), mustard_sarc.get(1, 0)]\n",
    "    \n",
    "    wedges, texts, autotexts = axes[0,2].pie(sizes_must, labels=labels, autopct='%1.1f%%',\n",
    "                                            colors=['lightgreen', 'orange'],\n",
    "                                            explode=(0, 0.1))\n",
    "    axes[0,2].set_title('MUStARD: Sarcasm Distribution', fontweight='bold')\n",
    "    \n",
    "    # 4. Text length distributions\n",
    "    memotion_text_col = 'text_corrected' if 'text_corrected' in memotion_df.columns else 'text'\n",
    "    \n",
    "    if memotion_text_col in memotion_df.columns:\n",
    "        memotion_lengths = [len(str(text).split()) for text in memotion_df[memotion_text_col].fillna('')]\n",
    "        mustard_lengths = [len(str(text).split()) for text in mustard_df['text'].fillna('')]\n",
    "        \n",
    "        axes[1,0].hist(memotion_lengths, bins=30, alpha=0.7, label='MEMOTION', \n",
    "                      color=colors[0], density=True)\n",
    "        axes[1,0].hist(mustard_lengths, bins=30, alpha=0.7, label='MUStARD', \n",
    "                      color=colors[1], density=True)\n",
    "        axes[1,0].set_xlabel('Text Length (words)')\n",
    "        axes[1,0].set_ylabel('Density')\n",
    "        axes[1,0].set_title('Text Length Distribution', fontweight='bold')\n",
    "        axes[1,0].legend()\n",
    "        axes[1,0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add statistics\n",
    "        stats_text = f'MEMOTION: μ={np.mean(memotion_lengths):.1f}\\n'\n",
    "        stats_text += f'MUStARD: μ={np.mean(mustard_lengths):.1f}'\n",
    "        axes[1,0].text(0.7, 0.8, stats_text, transform=axes[1,0].transAxes,\n",
    "                      bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "    \n",
    "    # 5. MEMOTION categories\n",
    "    emotion_cols = [col for col in memotion_df.columns if col in \n",
    "                   ['humour', 'sarcastic', 'offensive', 'motivational']]\n",
    "    \n",
    "    if emotion_cols:\n",
    "        emotion_counts = [memotion_df[col].sum() if col in memotion_df.columns else 0 \n",
    "                         for col in emotion_cols]\n",
    "        \n",
    "        bars = axes[1,1].bar(emotion_cols, emotion_counts, color='skyblue', alpha=0.8)\n",
    "        axes[1,1].set_title('MEMOTION: Category Distribution', fontweight='bold')\n",
    "        axes[1,1].set_ylabel('Count')\n",
    "        axes[1,1].tick_params(axis='x', rotation=45)\n",
    "        axes[1,1].grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        for bar, count in zip(bars, emotion_counts):\n",
    "            axes[1,1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 10,\n",
    "                          f'{count}', ha='center', va='bottom')\n",
    "    \n",
    "    # 6. MUStARD TV shows\n",
    "    if 'show' in mustard_df.columns:\n",
    "        show_counts = mustard_df['show'].value_counts().head(8)\n",
    "        \n",
    "        bars = axes[1,2].barh(range(len(show_counts)), show_counts.values, \n",
    "                             color='lightcoral', alpha=0.8)\n",
    "        axes[1,2].set_yticks(range(len(show_counts)))\n",
    "        axes[1,2].set_yticklabels(show_counts.index, fontsize=9)\n",
    "        axes[1,2].set_xlabel('Number of Samples')\n",
    "        axes[1,2].set_title('MUStARD: Top TV Shows', fontweight='bold')\n",
    "        axes[1,2].grid(True, alpha=0.3, axis='x')\n",
    "        \n",
    "        for i, (bar, count) in enumerate(zip(bars, show_counts.values)):\n",
    "            axes[1,2].text(bar.get_width() + 1, bar.get_y() + bar.get_height()/2,\n",
    "                          f'{count}', ha='left', va='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('dataset_overview.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def create_sarcasm_analysis_plots(memotion_df, mustard_df):\n",
    "    \"\"\"Analyze sarcasm patterns in detail\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    fig.suptitle('Sarcasm Pattern Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Get text columns\n",
    "    memotion_text_col = 'text_corrected' if 'text_corrected' in memotion_df.columns else 'text'\n",
    "    \n",
    "    # 1. Text length by sarcasm - MEMOTION\n",
    "    if memotion_text_col in memotion_df.columns and 'sarcastic' in memotion_df.columns:\n",
    "        memotion_df['text_length'] = memotion_df[memotion_text_col].fillna('').str.split().str.len()\n",
    "        \n",
    "        sarc_lengths = memotion_df[memotion_df['sarcastic'] == 1]['text_length'].dropna()\n",
    "        non_sarc_lengths = memotion_df[memotion_df['sarcastic'] == 0]['text_length'].dropna()\n",
    "        \n",
    "        data_to_plot = [non_sarc_lengths, sarc_lengths]\n",
    "        bp = axes[0,0].boxplot(data_to_plot, labels=['Non-Sarcastic', 'Sarcastic'], patch_artist=True)\n",
    "        bp['boxes'][0].set_facecolor('lightblue')\n",
    "        bp['boxes'][1].set_facecolor('lightcoral')\n",
    "        \n",
    "        axes[0,0].set_title('MEMOTION: Text Length by Sarcasm', fontweight='bold')\n",
    "        axes[0,0].set_ylabel('Text Length (words)')\n",
    "        axes[0,0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Statistical test\n",
    "        from scipy.stats import mannwhitneyu\n",
    "        if len(sarc_lengths) > 0 and len(non_sarc_lengths) > 0:\n",
    "            stat, p_value = mannwhitneyu(sarc_lengths, non_sarc_lengths)\n",
    "            axes[0,0].text(0.5, 0.95, f'p-value: {p_value:.3f}', \n",
    "                          transform=axes[0,0].transAxes, ha='center',\n",
    "                          bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))\n",
    "    \n",
    "    # 2. Text length by sarcasm - MUStARD\n",
    "    mustard_df['text_length'] = mustard_df['text'].fillna('').str.split().str.len()\n",
    "    \n",
    "    must_sarc_lengths = mustard_df[mustard_df['sarcastic'] == 1]['text_length'].dropna()\n",
    "    must_non_sarc_lengths = mustard_df[mustard_df['sarcastic'] == 0]['text_length'].dropna()\n",
    "    \n",
    "    data_to_plot = [must_non_sarc_lengths, must_sarc_lengths]\n",
    "    bp = axes[0,1].boxplot(data_to_plot, labels=['Non-Sarcastic', 'Sarcastic'], patch_artist=True)\n",
    "    bp['boxes'][0].set_facecolor('lightgreen')\n",
    "    bp['boxes'][1].set_facecolor('orange')\n",
    "    \n",
    "    axes[0,1].set_title('MUStARD: Text Length by Sarcasm', fontweight='bold')\n",
    "    axes[0,1].set_ylabel('Text Length (words)')\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    if len(must_sarc_lengths) > 0 and len(must_non_sarc_lengths) > 0:\n",
    "        stat, p_value = mannwhitneyu(must_sarc_lengths, must_non_sarc_lengths)\n",
    "        axes[0,1].text(0.5, 0.95, f'p-value: {p_value:.3f}', \n",
    "                      transform=axes[0,1].transAxes, ha='center',\n",
    "                      bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))\n",
    "    \n",
    "    # 3. Combined sarcasm rate by text length bins\n",
    "    combined_df = pd.concat([\n",
    "        memotion_df[['text_length', 'sarcastic']].assign(dataset='MEMOTION') if 'sarcastic' in memotion_df.columns else pd.DataFrame(),\n",
    "        mustard_df[['text_length', 'sarcastic']].assign(dataset='MUStARD')\n",
    "    ], ignore_index=True)\n",
    "    \n",
    "    # Create length bins\n",
    "    combined_df['length_bin'] = pd.cut(combined_df['text_length'], \n",
    "                                      bins=[0, 5, 10, 15, 20, 100], \n",
    "                                      labels=['1-5', '6-10', '11-15', '16-20', '20+'])\n",
    "    \n",
    "    sarcasm_by_length = combined_df.groupby('length_bin')['sarcastic'].agg(['mean', 'count'])\n",
    "    \n",
    "    bars = axes[0,2].bar(range(len(sarcasm_by_length)), sarcasm_by_length['mean'], \n",
    "                        alpha=0.8, color='purple')\n",
    "    axes[0,2].set_xticks(range(len(sarcasm_by_length)))\n",
    "    axes[0,2].set_xticklabels(sarcasm_by_length.index)\n",
    "    axes[0,2].set_xlabel('Text Length Bins (words)')\n",
    "    axes[0,2].set_ylabel('Sarcasm Rate')\n",
    "    axes[0,2].set_title('Sarcasm Rate by Text Length', fontweight='bold')\n",
    "    axes[0,2].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add count labels\n",
    "    for bar, count in zip(bars, sarcasm_by_length['count']):\n",
    "        axes[0,2].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                      f'n={count}', ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    # 4. Punctuation analysis - MEMOTION\n",
    "    if memotion_text_col in memotion_df.columns:\n",
    "        punct_data = analyze_punctuation_patterns(memotion_df, memotion_text_col)\n",
    "        \n",
    "        if punct_data:\n",
    "            patterns = list(punct_data['non_sarcastic'].keys())\n",
    "            non_sarc_vals = list(punct_data['non_sarcastic'].values())\n",
    "            sarc_vals = list(punct_data['sarcastic'].values())\n",
    "            \n",
    "            x = np.arange(len(patterns))\n",
    "            width = 0.35\n",
    "            \n",
    "            axes[1,0].bar(x - width/2, non_sarc_vals, width, label='Non-Sarcastic', alpha=0.8)\n",
    "            axes[1,0].bar(x + width/2, sarc_vals, width, label='Sarcastic', alpha=0.8)\n",
    "            \n",
    "            axes[1,0].set_xlabel('Punctuation Pattern')\n",
    "            axes[1,0].set_ylabel('Average Count per Text')\n",
    "            axes[1,0].set_title('MEMOTION: Punctuation Usage', fontweight='bold')\n",
    "            axes[1,0].set_xticks(x)\n",
    "            axes[1,0].set_xticklabels(patterns)\n",
    "            axes[1,0].legend()\n",
    "            axes[1,0].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # 5. Punctuation analysis - MUStARD\n",
    "    punct_data_mustard = analyze_punctuation_patterns(mustard_df, 'text')\n",
    "    \n",
    "    if punct_data_mustard:\n",
    "        patterns = list(punct_data_mustard['non_sarcastic'].keys())\n",
    "        non_sarc_vals = list(punct_data_mustard['non_sarcastic'].values())\n",
    "        sarc_vals = list(punct_data_mustard['sarcastic'].values())\n",
    "        \n",
    "        axes[1,1].bar(x - width/2, non_sarc_vals, width, label='Non-Sarcastic', alpha=0.8)\n",
    "        axes[1,1].bar(x + width/2, sarc_vals, width, label='Sarcastic', alpha=0.8)\n",
    "        \n",
    "        axes[1,1].set_xlabel('Punctuation Pattern')\n",
    "        axes[1,1].set_ylabel('Average Count per Text')\n",
    "        axes[1,1].set_title('MUStARD: Punctuation Usage', fontweight='bold')\n",
    "        axes[1,1].set_xticks(x)\n",
    "        axes[1,1].set_xticklabels(patterns)\n",
    "        axes[1,1].legend()\n",
    "        axes[1,1].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # 6. Dataset comparison summary\n",
    "    summary_data = {\n",
    "        'Metric': ['Total Samples', 'Sarcastic %', 'Avg Length', 'Unique Words'],\n",
    "        'MEMOTION': [\n",
    "            len(memotion_df),\n",
    "            f\"{memotion_df['sarcastic'].mean()*100:.1f}%\" if 'sarcastic' in memotion_df.columns else \"N/A\",\n",
    "            f\"{memotion_df['text_length'].mean():.1f}\" if 'text_length' in memotion_df.columns else \"N/A\",\n",
    "            \"N/A\"\n",
    "        ],\n",
    "        'MUStARD': [\n",
    "            len(mustard_df),\n",
    "            f\"{mustard_df['sarcastic'].mean()*100:.1f}%\",\n",
    "            f\"{mustard_df['text_length'].mean():.1f}\",\n",
    "            \"N/A\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    axes[1,2].axis('tight')\n",
    "    axes[1,2].axis('off')\n",
    "    table = axes[1,2].table(cellText=[summary_data['MEMOTION'], summary_data['MUStARD']],\n",
    "                           rowLabels=['MEMOTION', 'MUStARD'],\n",
    "                           colLabels=summary_data['Metric'],\n",
    "                           cellLoc='center',\n",
    "                           loc='center')\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    axes[1,2].set_title('Dataset Comparison Summary', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('sarcasm_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def analyze_punctuation_patterns(df, text_col):\n",
    "    \"\"\"Analyze punctuation usage patterns\"\"\"\n",
    "    try:\n",
    "        patterns = {'!': 0, '?': 0, '...': 0, 'CAPS': 0}\n",
    "        result = {'sarcastic': patterns.copy(), 'non_sarcastic': patterns.copy()}\n",
    "        \n",
    "        for sarcastic in [0, 1]:\n",
    "            texts = df[df['sarcastic'] == sarcastic][text_col].fillna('').astype(str)\n",
    "            key = 'sarcastic' if sarcastic == 1 else 'non_sarcastic'\n",
    "            \n",
    "            result[key]['!'] = texts.str.count('!').mean()\n",
    "            result[key]['?'] = texts.str.count(r'\\?').mean()\n",
    "            result[key]['...'] = texts.str.count(r'\\.\\.\\.').mean()\n",
    "            \n",
    "            # Count ALL_CAPS words\n",
    "            caps_counts = []\n",
    "            for text in texts:\n",
    "                words = str(text).split()\n",
    "                caps_count = sum(1 for word in words if word.isupper() and len(word) > 2)\n",
    "                caps_counts.append(caps_count)\n",
    "            result[key]['CAPS'] = np.mean(caps_counts) if caps_counts else 0\n",
    "        \n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing punctuation: {e}\")\n",
    "        return None\n",
    "\n",
    "def create_text_analysis_plots(memotion_df, mustard_df):\n",
    "    \"\"\"Create detailed text analysis plots\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('Text Analysis and Word Patterns', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Get text columns\n",
    "    memotion_text_col = 'text_corrected' if 'text_corrected' in memotion_df.columns else 'text'\n",
    "    \n",
    "    # 1. Top words in sarcastic texts - MEMOTION\n",
    "    if memotion_text_col in memotion_df.columns:\n",
    "        memotion_sarc_words = get_top_words(memotion_df, memotion_text_col, 'sarcastic', 1)\n",
    "        \n",
    "        if memotion_sarc_words and len(memotion_sarc_words) > 0:\n",
    "            words, counts = zip(*memotion_sarc_words[:10])\n",
    "            bars = axes[0,0].barh(range(len(words)), counts, color='lightcoral', alpha=0.8)\n",
    "            axes[0,0].set_yticks(range(len(words)))\n",
    "            axes[0,0].set_yticklabels(words)\n",
    "            axes[0,0].set_xlabel('Frequency')\n",
    "            axes[0,0].set_title('MEMOTION: Top Words in Sarcastic Texts', fontweight='bold')\n",
    "            axes[0,0].grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # 2. Top words in sarcastic texts - MUStARD\n",
    "    mustard_sarc_words = get_top_words(mustard_df, 'text', 'sarcastic', 1)\n",
    "    \n",
    "    if mustard_sarc_words and len(mustard_sarc_words) > 0:\n",
    "        words, counts = zip(*mustard_sarc_words[:10])\n",
    "        bars = axes[0,1].barh(range(len(words)), counts, color='lightgreen', alpha=0.8)\n",
    "        axes[0,1].set_yticks(range(len(words)))\n",
    "        axes[0,1].set_yticklabels(words)\n",
    "        axes[0,1].set_xlabel('Frequency')\n",
    "        axes[0,1].set_title('MUStARD: Top Words in Sarcastic Texts', fontweight='bold')\n",
    "        axes[0,1].grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # 3. Word clouds for sarcastic texts\n",
    "    try:\n",
    "        if memotion_text_col in memotion_df.columns:\n",
    "            sarc_texts = memotion_df[memotion_df['sarcastic'] == 1][memotion_text_col].fillna('')\n",
    "            sarc_text_combined = ' '.join(sarc_texts.astype(str))\n",
    "            \n",
    "            if len(sarc_text_combined.strip()) > 0:\n",
    "                wordcloud = WordCloud(width=400, height=300, background_color='white',\n",
    "                                    colormap='Reds').generate(sarc_text_combined)\n",
    "                axes[1,0].imshow(wordcloud, interpolation='bilinear')\n",
    "                axes[1,0].set_title('MEMOTION: Sarcastic Text Word Cloud', fontweight='bold')\n",
    "            axes[1,0].axis('off')\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating MEMOTION word cloud: {e}\")\n",
    "        axes[1,0].text(0.5, 0.5, 'WordCloud not available', ha='center', va='center',\n",
    "                      transform=axes[1,0].transAxes)\n",
    "        axes[1,0].axis('off')\n",
    "    \n",
    "    try:\n",
    "        mustard_sarc_texts = mustard_df[mustard_df['sarcastic'] == 1]['text'].fillna('')\n",
    "        mustard_sarc_combined = ' '.join(mustard_sarc_texts.astype(str))\n",
    "        \n",
    "        if len(mustard_sarc_combined.strip()) > 0:\n",
    "            wordcloud = WordCloud(width=400, height=300, background_color='white',\n",
    "                                colormap='Greens').generate(mustard_sarc_combined)\n",
    "            axes[1,1].imshow(wordcloud, interpolation='bilinear')\n",
    "            axes[1,1].set_title('MUStARD: Sarcastic Text Word Cloud', fontweight='bold')\n",
    "        axes[1,1].axis('off')\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating MUStARD word cloud: {e}\")\n",
    "        axes[1,1].text(0.5, 0.5, 'WordCloud not available', ha='center', va='center',\n",
    "                      transform=axes[1,1].transAxes)\n",
    "        axes[1,1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('text_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def get_top_words(df, text_col, label_col, label_value, top_n=20):\n",
    "    \"\"\"Extract top words for specific label\"\"\"\n",
    "    try:\n",
    "        texts = df[df[label_col] == label_value][text_col].fillna('')\n",
    "        all_text = ' '.join(texts.astype(str)).lower()\n",
    "        \n",
    "        # Extract words\n",
    "        words = re.findall(r'\\b[a-zA-Z]+\\b', all_text)\n",
    "        \n",
    "        # Remove stop words\n",
    "        stop_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', \n",
    "                     'of', 'with', 'by', 'is', 'are', 'was', 'were', 'be', 'been', 'have', \n",
    "                     'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should',\n",
    "                     'this', 'that', 'these', 'those', 'i', 'you', 'he', 'she', 'it', 'we', \n",
    "                     'they', 'me', 'him', 'her', 'us', 'them', 'my', 'your', 'his', 'its', 'our'}\n",
    "        \n",
    "        filtered_words = [word for word in words if word not in stop_words and len(word) > 2]\n",
    "        word_counts = Counter(filtered_words)\n",
    "        \n",
    "        return word_counts.most_common(top_n)\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting words: {e}\")\n",
    "        return []\n",
    "\n",
    "def create_interactive_plots(memotion_df, mustard_df):\n",
    "    \"\"\"Create interactive plots using Plotly\"\"\"\n",
    "    \n",
    "    # 1. Interactive dataset comparison\n",
    "    fig_comparison = go.Figure()\n",
    "    \n",
    "    # Add dataset sizes\n",
    "    fig_comparison.add_trace(go.Bar(\n",
    "        name='Dataset Size',\n",
    "        x=['MEMOTION', 'MUStARD'],\n",
    "        y=[len(memotion_df), len(mustard_df)],\n",
    "        marker_color=['#FF6B6B', '#4ECDC4']\n",
    "    ))\n",
    "    \n",
    "    fig_comparison.update_layout(\n",
    "        title='Interactive Dataset Size Comparison',\n",
    "        xaxis_title='Dataset',\n",
    "        yaxis_title='Number of Samples',\n",
    "        template='plotly_white'\n",
    "    )\n",
    "    \n",
    "    fig_comparison.write_html('dataset_comparison.html')\n",
    "    print(\"Created interactive dataset comparison: dataset_comparison.html\")\n",
    "    \n",
    "    # 2. Interactive sarcasm distribution\n",
    "    memotion_sarc_count = memotion_df['sarcastic'].sum() if 'sarcastic' in memotion_df.columns else 0\n",
    "    memotion_total = len(memotion_df)\n",
    "    mustard_sarc_count = mustard_df['sarcastic'].sum()\n",
    "    mustard_total = len(mustard_df)\n",
    "    \n",
    "    fig_sarc = go.Figure()\n",
    "    \n",
    "    fig_sarc.add_trace(go.Bar(\n",
    "        name='Sarcastic',\n",
    "        x=['MEMOTION', 'MUStARD'],\n",
    "        y=[memotion_sarc_count, mustard_sarc_count],\n",
    "        marker_color='lightcoral'\n",
    "    ))\n",
    "    \n",
    "    fig_sarc.add_trace(go.Bar(\n",
    "        name='Non-Sarcastic',\n",
    "        x=['MEMOTION', 'MUStARD'],\n",
    "        y=[memotion_total - memotion_sarc_count, mustard_total - mustard_sarc_count],\n",
    "        marker_color='lightblue'\n",
    "    ))\n",
    "    \n",
    "    fig_sarc.update_layout(\n",
    "        title='Interactive Sarcasm Distribution Comparison',\n",
    "        xaxis_title='Dataset',\n",
    "        yaxis_title='Number of Samples',\n",
    "        barmode='stack',\n",
    "        template='plotly_white'\n",
    "    )\n",
    "    \n",
    "    fig_sarc.write_html('sarcasm_distribution.html')\n",
    "    print(\"Created interactive sarcasm distribution: sarcasm_distribution.html\")\n",
    "\n",
    "def print_dataset_summary(memotion_df, mustard_df):\n",
    "    \"\"\"Print comprehensive dataset summary\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"COMPREHENSIVE DATASET ANALYSIS SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(f\"\\n📊 DATASET SIZES:\")\n",
    "    print(f\"   MEMOTION: {len(memotion_df):,} samples\")\n",
    "    print(f\"   MUStARD:  {len(mustard_df):,} samples\")\n",
    "    print(f\"   TOTAL:    {len(memotion_df) + len(mustard_df):,} samples\")\n",
    "    \n",
    "    print(f\"\\n🎭 SARCASM DISTRIBUTION:\")\n",
    "    if 'sarcastic' in memotion_df.columns:\n",
    "        memotion_sarc_rate = memotion_df['sarcastic'].mean() * 100\n",
    "        print(f\"   MEMOTION sarcasm rate: {memotion_sarc_rate:.1f}%\")\n",
    "    \n",
    "    mustard_sarc_rate = mustard_df['sarcastic'].mean() * 100\n",
    "    print(f\"   MUStARD sarcasm rate:  {mustard_sarc_rate:.1f}%\")\n",
    "    \n",
    "    print(f\"\\n📝 TEXT CHARACTERISTICS:\")\n",
    "    memotion_text_col = 'text_corrected' if 'text_corrected' in memotion_df.columns else 'text'\n",
    "    \n",
    "    if memotion_text_col in memotion_df.columns:\n",
    "        memotion_avg_length = np.mean([len(str(text).split()) for text in memotion_df[memotion_text_col].fillna('')])\n",
    "        print(f\"   MEMOTION avg text length: {memotion_avg_length:.1f} words\")\n",
    "    \n",
    "    mustard_avg_length = np.mean([len(str(text).split()) for text in mustard_df['text'].fillna('')])\n",
    "    print(f\"   MUStARD avg text length:  {mustard_avg_length:.1f} words\")\n",
    "    \n",
    "    print(f\"\\n🏷️  MEMOTION COLUMNS:\")\n",
    "    print(f\"   Available columns: {', '.join(memotion_df.columns)}\")\n",
    "    \n",
    "    print(f\"\\n🏷️  MUStARD COLUMNS:\")\n",
    "    print(f\"   Available columns: {', '.join(mustard_df.columns)}\")\n",
    "    \n",
    "    # Show sample texts\n",
    "    print(f\"\\n📄 SAMPLE TEXTS:\")\n",
    "    print(\"   MEMOTION samples:\")\n",
    "    if memotion_text_col in memotion_df.columns:\n",
    "        for i, text in enumerate(memotion_df[memotion_text_col].head(3)):\n",
    "            print(f\"     {i+1}. {str(text)[:100]}...\")\n",
    "    \n",
    "    print(\"   MUStARD samples:\")\n",
    "    for i, text in enumerate(mustard_df['text'].head(3)):\n",
    "        print(f\"     {i+1}. {str(text)[:100]}...\")\n",
    "\n",
    "# =============================================\n",
    "# Main Execution Function\n",
    "# =============================================\n",
    "\n",
    "def main_analysis():\n",
    "    \"\"\"Main function to run all analyses\"\"\"\n",
    "    \n",
    "    print(\"🚀 Starting MEMOTION and MUStARD Dataset Analysis\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Load your datasets (replace with your actual loading code)\n",
    "    try:\n",
    "        # Load MEMOTION datasets\n",
    "        memotion_labels_path = \"/kaggle/input/memotion-dataset-7k/memotion_dataset_7k/labels.csv\"\n",
    "        memotion_reference_path = \"/kaggle/input/memotion-dataset-7k/memotion_dataset_7k/reference.csv\"\n",
    "        mustard_json_path = \"/kaggle/input/mustard-multimodal-sarcasm-detection-dataset/sarcasm_data.json\"\n",
    "        \n",
    "        memotion_labels_df = pd.read_csv(memotion_labels_path)\n",
    "        memotion_reference_df = pd.read_csv(memotion_reference_path)\n",
    "        \n",
    "        # Load MUStARD dataset\n",
    "        with open(mustard_json_path, 'r') as f:\n",
    "            mustard_data = json.load(f)\n",
    "        \n",
    "        # Run comprehensive analysis\n",
    "        memotion_df, mustard_df = analyze_datasets(memotion_labels_df, memotion_reference_df, mustard_data)\n",
    "        \n",
    "        # Print summary\n",
    "        print_dataset_summary(memotion_df, mustard_df)\n",
    "        \n",
    "        print(\"\\n✅ Analysis completed successfully!\")\n",
    "        print(\"Generated files:\")\n",
    "        print(\"   📊 dataset_overview.png\")\n",
    "        print(\"   🎭 sarcasm_analysis.png\") \n",
    "        print(\"   📝 text_analysis.png\")\n",
    "        print(\"   🌐 dataset_comparison.html\")\n",
    "        print(\"   🌐 sarcasm_distribution.html\")\n",
    "        \n",
    "        return memotion_df, mustard_df\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"❌ File not found: {e}\")\n",
    "        print(\"Running with demo data instead...\")\n",
    "        return create_demo_analysis()\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading data: {e}\")\n",
    "        print(\"Running with demo data instead...\")\n",
    "        return create_demo_analysis()\n",
    "\n",
    "def create_demo_analysis():\n",
    "    \"\"\"Create demo analysis with synthetic data\"\"\"\n",
    "    \n",
    "    print(\"\\n🔄 Creating demo analysis with synthetic data...\")\n",
    "    \n",
    "    # Create synthetic MEMOTION-like data\n",
    "    np.random.seed(42)\n",
    "    n_memotion = 5000\n",
    "    \n",
    "    memotion_demo = pd.DataFrame({\n",
    "        'image_name': [f'img_{i:04d}.jpg' for i in range(n_memotion)],\n",
    "        'text_corrected': [f'Sample meme text {i} with content' for i in range(n_memotion)],\n",
    "        'sarcastic': np.random.choice([0, 1], n_memotion, p=[0.7, 0.3]),\n",
    "        'humour': np.random.choice([0, 1], n_memotion, p=[0.6, 0.4]),\n",
    "        'offensive': np.random.choice([0, 1], n_memotion, p=[0.8, 0.2]),\n",
    "        'motivational': np.random.choice([0, 1], n_memotion, p=[0.9, 0.1])\n",
    "    })\n",
    "    \n",
    "    # Create synthetic MUStARD-like data\n",
    "    n_mustard = 3000\n",
    "    shows = ['Friends', 'The Office', 'Seinfeld', 'How I Met Your Mother', 'Big Bang Theory']\n",
    "    \n",
    "    mustard_demo = pd.DataFrame({\n",
    "        'text': [f'Sample dialogue {i} from TV show' for i in range(n_mustard)],\n",
    "        'sarcastic': np.random.choice([0, 1], n_mustard, p=[0.65, 0.35]),\n",
    "        'show': np.random.choice(shows, n_mustard),\n",
    "        'speaker': [f'Speaker_{i%10}' for i in range(n_mustard)],\n",
    "        'context': [f'Context for sample {i}' for i in range(n_mustard)]\n",
    "    })\n",
    "    \n",
    "    # Run analysis on demo data\n",
    "    create_dataset_overview_plots(memotion_demo, mustard_demo)\n",
    "    create_sarcasm_analysis_plots(memotion_demo, mustard_demo)\n",
    "    create_text_analysis_plots(memotion_demo, mustard_demo)\n",
    "    create_interactive_plots(memotion_demo, mustard_demo)\n",
    "    \n",
    "    print_dataset_summary(memotion_demo, mustard_demo)\n",
    "    \n",
    "    return memotion_demo, mustard_demo\n",
    "\n",
    "# =============================================\n",
    "# Quick Analysis Functions for Jupyter\n",
    "# =============================================\n",
    "\n",
    "def quick_memotion_analysis(memotion_labels_df, memotion_reference_df):\n",
    "    \"\"\"Quick analysis function for MEMOTION data only\"\"\"\n",
    "    \n",
    "    # Merge datasets\n",
    "    memotion_df = pd.merge(memotion_labels_df, memotion_reference_df, on='image_name', how='inner')\n",
    "    \n",
    "    # Basic info\n",
    "    print(\"📊 MEMOTION Dataset Quick Analysis\")\n",
    "    print(\"=\"*40)\n",
    "    print(f\"Total samples: {len(memotion_df):,}\")\n",
    "    print(f\"Columns: {list(memotion_df.columns)}\")\n",
    "    \n",
    "    # Check for sarcasm column\n",
    "    if 'sarcastic' in memotion_df.columns:\n",
    "        sarc_count = memotion_df['sarcastic'].sum()\n",
    "        sarc_rate = memotion_df['sarcastic'].mean() * 100\n",
    "        print(f\"Sarcastic samples: {sarc_count:,} ({sarc_rate:.1f}%)\")\n",
    "    \n",
    "    # Text analysis\n",
    "    text_col = 'text_corrected' if 'text_corrected' in memotion_df.columns else 'text'\n",
    "    if text_col in memotion_df.columns:\n",
    "        lengths = [len(str(text).split()) for text in memotion_df[text_col].fillna('')]\n",
    "        print(f\"Avg text length: {np.mean(lengths):.1f} words\")\n",
    "        print(f\"Text length range: {min(lengths)} - {max(lengths)} words\")\n",
    "    \n",
    "    # Sample texts\n",
    "    print(f\"\\n📝 Sample texts:\")\n",
    "    if text_col in memotion_df.columns:\n",
    "        for i, text in enumerate(memotion_df[text_col].head(3)):\n",
    "            print(f\"  {i+1}. {str(text)[:80]}...\")\n",
    "    \n",
    "    return memotion_df\n",
    "\n",
    "def quick_mustard_analysis(mustard_data):\n",
    "    \"\"\"Quick analysis function for MUStARD data only\"\"\"\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    mustard_records = []\n",
    "    for key, value in mustard_data.items():\n",
    "        record = {\n",
    "            'id': key,\n",
    "            'text': value.get('utterance', ''),\n",
    "            'sarcastic': 1 if value.get('sarcasm', False) else 0,\n",
    "            'show': value.get('show', ''),\n",
    "            'speaker': value.get('speaker', '')\n",
    "        }\n",
    "        mustard_records.append(record)\n",
    "    \n",
    "    mustard_df = pd.DataFrame(mustard_records)\n",
    "    \n",
    "    # Basic info\n",
    "    print(\"📊 MUStARD Dataset Quick Analysis\")\n",
    "    print(\"=\"*40)\n",
    "    print(f\"Total samples: {len(mustard_df):,}\")\n",
    "    print(f\"Columns: {list(mustard_df.columns)}\")\n",
    "    \n",
    "    # Sarcasm analysis\n",
    "    sarc_count = mustard_df['sarcastic'].sum()\n",
    "    sarc_rate = mustard_df['sarcastic'].mean() * 100\n",
    "    print(f\"Sarcastic samples: {sarc_count:,} ({sarc_rate:.1f}%)\")\n",
    "    \n",
    "    # Text analysis\n",
    "    lengths = [len(str(text).split()) for text in mustard_df['text'].fillna('')]\n",
    "    print(f\"Avg text length: {np.mean(lengths):.1f} words\")\n",
    "    print(f\"Text length range: {min(lengths)} - {max(lengths)} words\")\n",
    "    \n",
    "    # Show distribution\n",
    "    if 'show' in mustard_df.columns:\n",
    "        top_shows = mustard_df['show'].value_counts().head(5)\n",
    "        print(f\"\\n📺 Top 5 TV shows:\")\n",
    "        for show, count in top_shows.items():\n",
    "            print(f\"  {show}: {count} samples\")\n",
    "    \n",
    "    # Sample texts\n",
    "    print(f\"\\n📝 Sample texts:\")\n",
    "    for i, text in enumerate(mustard_df['text'].head(3)):\n",
    "        print(f\"  {i+1}. {str(text)[:80]}...\")\n",
    "    \n",
    "    return mustard_df\n",
    "\n",
    "# =============================================\n",
    "# Usage Instructions\n",
    "# =============================================\n",
    "\n",
    "def print_usage_instructions():\n",
    "    \"\"\"Print usage instructions\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"📋 USAGE INSTRUCTIONS\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"This script provides comprehensive analysis for MEMOTION and MUStARD datasets.\")\n",
    "    print(\"\\n🔧 MAIN FUNCTIONS:\")\n",
    "    print(\"1. main_analysis() - Complete analysis of both datasets\")\n",
    "    print(\"2. quick_memotion_analysis(labels_df, reference_df) - Quick MEMOTION analysis\")\n",
    "    print(\"3. quick_mustard_analysis(mustard_data) - Quick MUStARD analysis\")\n",
    "    \n",
    "    print(\"\\n📊 GENERATED VISUALIZATIONS:\")\n",
    "    print(\"• dataset_overview.png - Dataset sizes, distributions, categories\")\n",
    "    print(\"• sarcasm_analysis.png - Sarcasm patterns, text length analysis\")\n",
    "    print(\"• text_analysis.png - Word patterns, word clouds\")\n",
    "    print(\"• dataset_comparison.html - Interactive comparison\")\n",
    "    print(\"• sarcasm_distribution.html - Interactive sarcasm distribution\")\n",
    "    \n",
    "    print(\"\\n💡 QUICK START:\")\n",
    "    print(\"# For complete analysis:\")\n",
    "    print(\"memotion_df, mustard_df = main_analysis()\")\n",
    "    print(\"\")\n",
    "    print(\"# For individual dataset analysis:\")\n",
    "    print(\"memotion_df = quick_memotion_analysis(memotion_labels_df, memotion_reference_df)\")\n",
    "    print(\"mustard_df = quick_mustard_analysis(mustard_data)\")\n",
    "    \n",
    "    print(\"\\n📦 REQUIRED PACKAGES:\")\n",
    "    print(\"pip install pandas numpy matplotlib seaborn wordcloud plotly\")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    print_usage_instructions()\n",
    "    \n",
    "    # Uncomment the line below to run the analysis\n",
    "    # main_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0995481b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T16:39:48.102657Z",
     "iopub.status.busy": "2025-08-06T16:39:48.102295Z",
     "iopub.status.idle": "2025-08-06T16:40:00.556684Z",
     "shell.execute_reply": "2025-08-06T16:40:00.555825Z",
     "shell.execute_reply.started": "2025-08-06T16:39:48.102627Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "main_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2554000d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T16:46:55.306093Z",
     "iopub.status.busy": "2025-08-06T16:46:55.305743Z",
     "iopub.status.idle": "2025-08-06T16:46:59.092211Z",
     "shell.execute_reply": "2025-08-06T16:46:59.091313Z",
     "shell.execute_reply.started": "2025-08-06T16:46:55.306071Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Complete workflow for MEMOTION image visualization\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from textwrap import wrap\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =============================================\n",
    "# Step 1: Load and Merge Your Data\n",
    "# =============================================\n",
    "\n",
    "# Define your paths\n",
    "memotion_labels_path = \"/kaggle/input/memotion-dataset-7k/memotion_dataset_7k/labels.csv\"\n",
    "memotion_reference_path = \"/kaggle/input/memotion-dataset-7k/memotion_dataset_7k/reference.csv\"\n",
    "images_path = \"/kaggle/input/memotion-dataset-7k/memotion_dataset_7k/images/\"\n",
    "mustard_json_path = \"/kaggle/input/mustard-multimodal-sarcasm-detection-dataset/sarcasm_data.json\"\n",
    "\n",
    "print(\"📊 Loading MEMOTION datasets...\")\n",
    "\n",
    "# Load the datasets you already have\n",
    "memotion_labels_df = pd.read_csv(memotion_labels_path)\n",
    "memotion_reference_df = pd.read_csv(memotion_reference_path)\n",
    "\n",
    "# Load MUStARD dataset\n",
    "with open(mustard_json_path, 'r') as f:\n",
    "    mustard_data = json.load(f)\n",
    "\n",
    "print(f\"✅ MEMOTION Labels shape: {memotion_labels_df.shape}\")\n",
    "print(f\"✅ MEMOTION Reference shape: {memotion_reference_df.shape}\")\n",
    "print(f\"✅ MUStARD entries: {len(mustard_data)}\")\n",
    "\n",
    "# Merge MEMOTION datasets\n",
    "merged_df = pd.merge(memotion_labels_df, memotion_reference_df, on='image_name', how='inner')\n",
    "print(f\"✅ Merged MEMOTION shape: {merged_df.shape}\")\n",
    "\n",
    "print(\"\\n📋 Available columns in merged dataset:\")\n",
    "print(merged_df.columns.tolist())\n",
    "\n",
    "print(f\"\\n📋 First few rows preview:\")\n",
    "print(merged_df.head())\n",
    "\n",
    "# =============================================\n",
    "# Step 2: Simple Image Display Functions\n",
    "# =============================================\n",
    "\n",
    "def display_images_simple(df, images_base_path, n_images=6, save_name='simple_display.png'):\n",
    "    \"\"\"Simple function to display images with basic info\"\"\"\n",
    "    \n",
    "    # Check if images directory exists\n",
    "    if not os.path.exists(images_base_path):\n",
    "        print(f\"⚠️ Warning: Images directory not found at {images_base_path}\")\n",
    "        print(\"The function will show placeholder messages for missing images.\")\n",
    "    \n",
    "    # Sample images\n",
    "    if len(df) > n_images:\n",
    "        sample_df = df.sample(n=n_images, random_state=42)\n",
    "    else:\n",
    "        sample_df = df\n",
    "        n_images = len(sample_df)\n",
    "    \n",
    "    # Calculate grid\n",
    "    cols = 3\n",
    "    rows = (n_images + cols - 1) // cols\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(15, 5*rows))\n",
    "    fig.suptitle('MEMOTION Dataset Sample Images', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Handle single row case\n",
    "    if rows == 1:\n",
    "        if cols == 1:\n",
    "            axes = [axes]\n",
    "        else:\n",
    "            axes = axes\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "    \n",
    "    for idx, (_, row) in enumerate(sample_df.iterrows()):\n",
    "        if idx >= len(axes):\n",
    "            break\n",
    "            \n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Get image info\n",
    "        image_name = row['image_name']\n",
    "        image_path = os.path.join(images_base_path, image_name)\n",
    "        \n",
    "        # Try to display image\n",
    "        try:\n",
    "            if os.path.exists(image_path):\n",
    "                img = Image.open(image_path)\n",
    "                ax.imshow(img)\n",
    "                status = \"✅ Loaded\"\n",
    "            else:\n",
    "                # Create placeholder\n",
    "                ax.text(0.5, 0.5, f'❌ Image not found:\\n{image_name}', \n",
    "                       ha='center', va='center', transform=ax.transAxes,\n",
    "                       bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.7),\n",
    "                       fontsize=10)\n",
    "                status = \"❌ Missing\"\n",
    "        except Exception as e:\n",
    "            ax.text(0.5, 0.5, f'⚠️ Error loading:\\n{image_name}\\n{str(e)}', \n",
    "                   ha='center', va='center', transform=ax.transAxes,\n",
    "                   bbox=dict(boxstyle='round', facecolor='lightcoral', alpha=0.7),\n",
    "                   fontsize=8)\n",
    "            status = \"⚠️ Error\"\n",
    "        \n",
    "        # Get text and labels\n",
    "        text_col = 'text_corrected' if 'text_corrected' in row else 'text'\n",
    "        if text_col in row and pd.notna(row[text_col]):\n",
    "            text = str(row[text_col])[:60] + (\"...\" if len(str(row[text_col])) > 60 else \"\")\n",
    "        else:\n",
    "            text = \"No text available\"\n",
    "        \n",
    "        # Get labels\n",
    "        labels = []\n",
    "        for col in ['sarcastic', 'humour', 'offensive', 'motivational']:\n",
    "            if col in row and row[col] == 1:\n",
    "                labels.append(col.capitalize())\n",
    "        \n",
    "        labels_text = \", \".join(labels) if labels else \"No labels\"\n",
    "        \n",
    "        # Set title\n",
    "        title = f\"{status}\\n{text}\\nLabels: {labels_text}\"\n",
    "        ax.set_title(title, fontsize=9, pad=10)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for idx in range(len(sample_df), len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_name, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return sample_df\n",
    "\n",
    "def quick_sarcasm_comparison(df, images_base_path, n_each=3):\n",
    "    \"\"\"Quick comparison of sarcastic vs non-sarcastic images\"\"\"\n",
    "    \n",
    "    if 'sarcastic' not in df.columns:\n",
    "        print(\"❌ No 'sarcastic' column found in dataset\")\n",
    "        return\n",
    "    \n",
    "    # Get samples\n",
    "    sarcastic_samples = df[df['sarcastic'] == 1]\n",
    "    nonsarcastic_samples = df[df['sarcastic'] == 0]\n",
    "    \n",
    "    print(f\"📊 Found {len(sarcastic_samples)} sarcastic and {len(nonsarcastic_samples)} non-sarcastic samples\")\n",
    "    \n",
    "    if len(sarcastic_samples) == 0 or len(nonsarcastic_samples) == 0:\n",
    "        print(\"❌ Need both sarcastic and non-sarcastic samples for comparison\")\n",
    "        return\n",
    "    \n",
    "    # Sample data\n",
    "    n_each = min(n_each, len(sarcastic_samples), len(nonsarcastic_samples))\n",
    "    sarc_sample = sarcastic_samples.sample(n=n_each, random_state=42)\n",
    "    nonparc_sample = nonsarcastic_samples.sample(n=n_each, random_state=42)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, n_each, figsize=(5*n_each, 10))\n",
    "    fig.suptitle('Sarcastic vs Non-Sarcastic Memes', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    if n_each == 1:\n",
    "        axes = axes.reshape(2, 1)\n",
    "    \n",
    "    # Display sarcastic images\n",
    "    for idx, (_, row) in enumerate(sarc_sample.iterrows()):\n",
    "        ax = axes[0, idx]\n",
    "        display_single_image(ax, row, images_base_path, \"🤨 SARCASTIC\")\n",
    "    \n",
    "    # Display non-sarcastic images  \n",
    "    for idx, (_, row) in enumerate(nonparc_sample.iterrows()):\n",
    "        ax = axes[1, idx]\n",
    "        display_single_image(ax, row, images_base_path, \"😐 NON-SARCASTIC\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('sarcasm_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def display_single_image(ax, row, images_base_path, category_label):\n",
    "    \"\"\"Helper function to display a single image\"\"\"\n",
    "    \n",
    "    image_name = row['image_name']\n",
    "    image_path = os.path.join(images_base_path, image_name)\n",
    "    \n",
    "    try:\n",
    "        if os.path.exists(image_path):\n",
    "            img = Image.open(image_path)\n",
    "            ax.imshow(img)\n",
    "            \n",
    "            # Get text\n",
    "            text_col = 'text_corrected' if 'text_corrected' in row else 'text'\n",
    "            if text_col in row and pd.notna(row[text_col]):\n",
    "                text = str(row[text_col])\n",
    "                # Wrap text nicely\n",
    "                wrapped_text = '\\n'.join(wrap(text, width=40))[:200] + (\"...\" if len(text) > 200 else \"\")\n",
    "            else:\n",
    "                wrapped_text = \"No text available\"\n",
    "            \n",
    "            ax.set_title(f\"{category_label}\\n{wrapped_text}\", fontsize=10, pad=15)\n",
    "        else:\n",
    "            ax.text(0.5, 0.5, f'Image not found:\\n{image_name}', \n",
    "                   ha='center', va='center', transform=ax.transAxes,\n",
    "                   bbox=dict(boxstyle='round', facecolor='lightgray'))\n",
    "            ax.set_title(f\"{category_label}\\nImage not found\", fontsize=10)\n",
    "            \n",
    "    except Exception as e:\n",
    "        ax.text(0.5, 0.5, f'Error loading:\\n{str(e)}', \n",
    "               ha='center', va='center', transform=ax.transAxes,\n",
    "               bbox=dict(boxstyle='round', facecolor='lightcoral'))\n",
    "        ax.set_title(f\"{category_label}\\nError loading\", fontsize=10)\n",
    "    \n",
    "    ax.axis('off')\n",
    "\n",
    "# =============================================\n",
    "# Step 3: Dataset Analysis Functions\n",
    "# =============================================\n",
    "\n",
    "def analyze_dataset_images(df, images_base_path):\n",
    "    \"\"\"Analyze the dataset and show basic statistics\"\"\"\n",
    "    \n",
    "    print(\"🔍 DATASET ANALYSIS\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Total samples: {len(df):,}\")\n",
    "    \n",
    "    # Check image availability\n",
    "    available_images = 0\n",
    "    missing_images = 0\n",
    "    \n",
    "    print(\"📊 Checking image availability (sampling 100 images)...\")\n",
    "    sample_check = df.sample(n=min(100, len(df)), random_state=42)\n",
    "    \n",
    "    for _, row in sample_check.iterrows():\n",
    "        image_path = os.path.join(images_base_path, row['image_name'])\n",
    "        if os.path.exists(image_path):\n",
    "            available_images += 1\n",
    "        else:\n",
    "            missing_images += 1\n",
    "    \n",
    "    print(f\"✅ Available images: {available_images}/{len(sample_check)} ({available_images/len(sample_check)*100:.1f}%)\")\n",
    "    print(f\"❌ Missing images: {missing_images}/{len(sample_check)} ({missing_images/len(sample_check)*100:.1f}%)\")\n",
    "    \n",
    "    # Label analysis\n",
    "    print(f\"\\n🏷️ LABEL ANALYSIS:\")\n",
    "    for col in ['sarcastic', 'humour', 'offensive', 'motivational']:\n",
    "        if col in df.columns:\n",
    "            count = df[col].sum()\n",
    "            percentage = (count / len(df)) * 100\n",
    "            print(f\"   {col.capitalize()}: {count:,} samples ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Text analysis\n",
    "    text_col = 'text_corrected' if 'text_corrected' in df.columns else 'text'\n",
    "    if text_col in df.columns:\n",
    "        text_lengths = [len(str(text).split()) for text in df[text_col].fillna('')]\n",
    "        print(f\"\\n📝 TEXT ANALYSIS:\")\n",
    "        print(f\"   Average text length: {np.mean(text_lengths):.1f} words\")\n",
    "        print(f\"   Text length range: {min(text_lengths)} - {max(text_lengths)} words\")\n",
    "        print(f\"   Texts with content: {df[text_col].notna().sum()}/{len(df)} ({df[text_col].notna().mean()*100:.1f}%)\")\n",
    "    \n",
    "    # Show sample texts\n",
    "    print(f\"\\n📄 SAMPLE TEXTS:\")\n",
    "    if text_col in df.columns:\n",
    "        for i, text in enumerate(df[text_col].dropna().head(3)):\n",
    "            print(f\"   {i+1}. {str(text)[:100]}...\")\n",
    "\n",
    "# =============================================\n",
    "# Step 4: Main Execution\n",
    "# =============================================\n",
    "\n",
    "def main_image_visualization():\n",
    "    \"\"\"Main function to run the complete workflow\"\"\"\n",
    "    \n",
    "    print(\"🚀 Starting MEMOTION Image Visualization Workflow\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Step 1: Analyze the dataset\n",
    "    analyze_dataset_images(merged_df, images_path)\n",
    "    \n",
    "    # Step 2: Display some sample images\n",
    "    print(f\"\\n🖼️ Displaying sample images...\")\n",
    "    sample_df = display_images_simple(merged_df, images_path, n_images=6)\n",
    "    \n",
    "    # Step 3: Show sarcasm comparison if available\n",
    "    if 'sarcastic' in merged_df.columns:\n",
    "        print(f\"\\n🎭 Comparing sarcastic vs non-sarcastic images...\")\n",
    "        quick_sarcasm_comparison(merged_df, images_path, n_each=3)\n",
    "    else:\n",
    "        print(f\"\\n⚠️ No 'sarcastic' column found - skipping sarcasm comparison\")\n",
    "    \n",
    "    print(f\"\\n✅ Visualization completed!\")\n",
    "    return merged_df\n",
    "\n",
    "# =============================================\n",
    "# Quick Functions for Individual Use\n",
    "# =============================================\n",
    "\n",
    "def quick_preview(n_images=4):\n",
    "    \"\"\"Quick preview function - just run this!\"\"\"\n",
    "    print(\"📸 Quick Image Preview\")\n",
    "    print(\"-\" * 30)\n",
    "    return display_images_simple(merged_df, images_path, n_images=n_images, save_name='quick_preview.png')\n",
    "\n",
    "def show_sarcastic_only(n_images=6):\n",
    "    \"\"\"Show only sarcastic images\"\"\"\n",
    "    if 'sarcastic' not in merged_df.columns:\n",
    "        print(\"❌ No 'sarcastic' column found\")\n",
    "        return\n",
    "    \n",
    "    sarcastic_df = merged_df[merged_df['sarcastic'] == 1]\n",
    "    print(f\"📸 Showing {min(n_images, len(sarcastic_df))} sarcastic images out of {len(sarcastic_df)} total\")\n",
    "    return display_images_simple(sarcastic_df, images_path, n_images=n_images, save_name='sarcastic_only.png')\n",
    "\n",
    "def show_non_sarcastic_only(n_images=6):\n",
    "    \"\"\"Show only non-sarcastic images\"\"\"\n",
    "    if 'sarcastic' not in merged_df.columns:\n",
    "        print(\"❌ No 'sarcastic' column found\")\n",
    "        return\n",
    "    \n",
    "    non_sarcastic_df = merged_df[merged_df['sarcastic'] == 0]\n",
    "    print(f\"📸 Showing {min(n_images, len(non_sarcastic_df))} non-sarcastic images out of {len(non_sarcastic_df)} total\")\n",
    "    return display_images_simple(non_sarcastic_df, images_path, n_images=n_images, save_name='non_sarcastic_only.png')\n",
    "\n",
    "def show_category_samples(category='humour', n_images=6):\n",
    "    \"\"\"Show samples from a specific category\"\"\"\n",
    "    if category not in merged_df.columns:\n",
    "        print(f\"❌ No '{category}' column found\")\n",
    "        print(f\"Available columns: {merged_df.columns.tolist()}\")\n",
    "        return\n",
    "    \n",
    "    category_df = merged_df[merged_df[category] == 1]\n",
    "    print(f\"📸 Showing {min(n_images, len(category_df))} {category} images out of {len(category_df)} total\")\n",
    "    return display_images_simple(category_df, images_path, n_images=n_images, \n",
    "                                save_name=f'{category}_samples.png')\n",
    "\n",
    "# =============================================\n",
    "# Ready-to-use Commands\n",
    "# =============================================\n",
    "\n",
    "print(\"🎯 READY TO USE! Try these commands:\")\n",
    "print(\"=\"*50)\n",
    "print(\"1. quick_preview(4)                    # Show 4 random images\")\n",
    "print(\"2. show_sarcastic_only(6)              # Show 6 sarcastic images\")  \n",
    "print(\"3. show_non_sarcastic_only(6)          # Show 6 non-sarcastic images\")\n",
    "print(\"4. show_category_samples('humour', 4)  # Show 4 humorous images\")\n",
    "print(\"5. main_image_visualization()          # Run complete analysis\")\n",
    "print(\"\\n💡 The 'merged_df' variable is now available with your data!\")\n",
    "print(f\"   Shape: {merged_df.shape}\")\n",
    "print(f\"   Columns: {merged_df.columns.tolist()}\")\n",
    "\n",
    "# Show a quick preview automatically\n",
    "print(\"\\n🎬 Auto-running quick preview...\")\n",
    "quick_preview(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec10c6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T16:47:21.608718Z",
     "iopub.status.busy": "2025-08-06T16:47:21.608319Z",
     "iopub.status.idle": "2025-08-06T16:47:25.253013Z",
     "shell.execute_reply": "2025-08-06T16:47:25.251744Z",
     "shell.execute_reply.started": "2025-08-06T16:47:21.608677Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Quick preview of random images\n",
    "quick_preview(4)\n",
    "\n",
    "# Show sarcastic images only\n",
    "show_sarcastic_only(6)\n",
    "\n",
    "# Show non-sarcastic images only  \n",
    "show_non_sarcastic_only(6)\n",
    "\n",
    "# Show specific category (humour, offensive, motivational)\n",
    "show_category_samples('humour', 4)\n",
    "\n",
    "# Compare sarcastic vs non-sarcastic\n",
    "quick_sarcasm_comparison(merged_df, images_path, n_each=3)\n",
    "\n",
    "# Run complete analysis\n",
    "main_image_visualization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe2282b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 531544,
     "sourceId": 973292,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2638462,
     "sourceId": 4514628,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2440.407401,
   "end_time": "2025-08-20T06:46:54.640439",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-20T06:06:14.233038",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "01326d3e64274690a4854294fc592df9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1014a9e499c3429992e318c8dd56d5f1",
       "placeholder": "​",
       "style": "IPY_MODEL_20ed860afc0148009c76442108ff5a93",
       "tabbable": null,
       "tooltip": null,
       "value": " 239/239 [00:00&lt;00:00, 34.7kB/s]"
      }
     },
     "07ef233491254569bec2963b526cca3b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0aa0ce2ff49041d9a62cbb4b4779769d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "0dda7828ab804cc9b44c49418ae14ea5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "0f59c32970bd4d40a7f360c69f886b00": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_264bcba219d54d0aad9ef703d51c3fef",
       "placeholder": "​",
       "style": "IPY_MODEL_a83e023b334e4745beac98d773b279e2",
       "tabbable": null,
       "tooltip": null,
       "value": " 232k/232k [00:00&lt;00:00, 5.63MB/s]"
      }
     },
     "0fbbbfc0879a409daa7e4815449789a8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1014a9e499c3429992e318c8dd56d5f1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "11d43039380b4c4d8e9a410ad0a8afda": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1390ac6a9aaa45ed8ba22fa62d3368ff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "13a02549d7a84b279d3d539293e1a1fc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1771971875cf4be183ff92e399bb4daa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "179aebee913f4999917a4ee4966e56ab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "18c3dc2c8981415185dadea8bc14d762": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "19cdfd7828844d908bc3f18a01231785": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1a595a10bc2e43998a6bd3544d3ff3e3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1b2fb68f4d1e4c2aa15545fda4243445": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1b5d34cc2b9f47f8a0cbfee077fa0933": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1bf6a82668a14b51be531b343320326a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f87d4a4d7f1f4e0ab2baeef091c19892",
       "placeholder": "​",
       "style": "IPY_MODEL_95c567593b3a4f409f9e998b3c355f02",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json: 100%"
      }
     },
     "1c743802250f4256901a5f6c3a87e832": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "1f532f3e2a954257a53029956db9361f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "20d647e53438441f91ca8dadf4baa25c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "20dc98c304544ac0ba6d20c8cb7d5c04": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "20ed860afc0148009c76442108ff5a93": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2137a91452fe40dcbedefdc485070068": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d0a7eaa0728f4db8a7415f0227bd8665",
        "IPY_MODEL_24156244dfcf465f99b8b0da97777ca9",
        "IPY_MODEL_8d5b7da69e6e48c0b9a19d7aee823a92"
       ],
       "layout": "IPY_MODEL_b917d78bf19b44c8ac3a431283e162fd",
       "tabbable": null,
       "tooltip": null
      }
     },
     "225957a4b7284621a34b9de12668c99c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "235bc8521ef7458a9ae965f82a14deeb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "24156244dfcf465f99b8b0da97777ca9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_98642b3d1190436d921f4d47b75b9a7b",
       "max": 570.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_20dc98c304544ac0ba6d20c8cb7d5c04",
       "tabbable": null,
       "tooltip": null,
       "value": 570.0
      }
     },
     "260f7fd311d3490aa0b74e333b896775": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "264bcba219d54d0aad9ef703d51c3fef": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "26c2ccf8b1744adea6e6a9fac26be8b7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1771971875cf4be183ff92e399bb4daa",
       "max": 466062.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b9f6747f65294706a30bdc2f3f139559",
       "tabbable": null,
       "tooltip": null,
       "value": 466062.0
      }
     },
     "2c301c45bce642da9cde6e5676d95450": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_35c27c6e992646a28bd4d2d0f31cff7f",
        "IPY_MODEL_f779daa513114e6ba899f8c4043e41c2",
        "IPY_MODEL_9076de6ffa8143849100781a0555d489"
       ],
       "layout": "IPY_MODEL_aa72e24dfb334d3f92af80ae966c982b",
       "tabbable": null,
       "tooltip": null
      }
     },
     "2e8b54f1483f42dc98c8044d0ecfdb47": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "301e4a2e4bb94beb984a263ad9e51b67": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_260f7fd311d3490aa0b74e333b896775",
       "max": 294.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_dbb194f0a8ce4856af6e49ac5d801791",
       "tabbable": null,
       "tooltip": null,
       "value": 294.0
      }
     },
     "32049d31ef1142a19b4edd56452c59e7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "35541364da9545a3b574129883362135": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_18c3dc2c8981415185dadea8bc14d762",
       "placeholder": "​",
       "style": "IPY_MODEL_0fbbbfc0879a409daa7e4815449789a8",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     },
     "35c27c6e992646a28bd4d2d0f31cff7f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7a1188350b294866b9c32b726995101b",
       "placeholder": "​",
       "style": "IPY_MODEL_6cf71897fe814e59a7052bec27cf963b",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: "
      }
     },
     "37e47ad0d147449fa1bc81c41cc7d46b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "37fb7fe2b1e7430bb68871b9adb7b4a4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "39e29d0c5bf04984ae1e1fe128b65b3c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3a59f123a665456a98b3176f614cc73b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3c4b3ea67fff4a788024965860d6752f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_32049d31ef1142a19b4edd56452c59e7",
       "max": 239.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0aa0ce2ff49041d9a62cbb4b4779769d",
       "tabbable": null,
       "tooltip": null,
       "value": 239.0
      }
     },
     "42d5427e4c66459488f705d0f5aaabf3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "4707a7aae2984ffc82279e31c0496dc3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_df9beb30f40f465881021b4da725f214",
        "IPY_MODEL_c8bf8c3545e24d138fc6994753f0133d",
        "IPY_MODEL_ebf9cabbe62745638e872f9d0f1f7326"
       ],
       "layout": "IPY_MODEL_974177ff08c94f80a08d7558d217a9ca",
       "tabbable": null,
       "tooltip": null
      }
     },
     "4767e33231f144c3807d78992d98c9c8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4776442649c9473891b4081128f6d6aa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1bf6a82668a14b51be531b343320326a",
        "IPY_MODEL_301e4a2e4bb94beb984a263ad9e51b67",
        "IPY_MODEL_a4762f0f5f054434bb1a19a2a394bff2"
       ],
       "layout": "IPY_MODEL_37e47ad0d147449fa1bc81c41cc7d46b",
       "tabbable": null,
       "tooltip": null
      }
     },
     "49045a8092f04b41bc5dbae8898efe11": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_671896cafdb740f985f81c47633d22ea",
        "IPY_MODEL_5f95c879d5e5488db84d70f0ae6ced98",
        "IPY_MODEL_eb419f89f08a45fa9dad9ffae9b37dde"
       ],
       "layout": "IPY_MODEL_6ccbfa0328b547078273b5d07085ae0a",
       "tabbable": null,
       "tooltip": null
      }
     },
     "4d4d62fb28e647e3a923c25fa16eba38": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_70409044de3f47b7b6368f707f2dbc23",
        "IPY_MODEL_26c2ccf8b1744adea6e6a9fac26be8b7",
        "IPY_MODEL_ed9771ae99cd4c048264eb4b74ba86fe"
       ],
       "layout": "IPY_MODEL_5a780eafe06a426682c21d7560cf259a",
       "tabbable": null,
       "tooltip": null
      }
     },
     "4fe9c87fe3174dad88c6ca098d5f4b6a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5203f84b6e154cdc8550ad0aaf00adb3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_64c053d7602e4f27a492bb27dbfc84ea",
       "placeholder": "​",
       "style": "IPY_MODEL_7a4e34c08b5e44c99eda5cb3f70dd4bd",
       "tabbable": null,
       "tooltip": null,
       "value": " 48.0/48.0 [00:00&lt;00:00, 4.74kB/s]"
      }
     },
     "52a87709fd0746bd8ee5a776afe300b7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_624d52156f83422ea02517789f704a2b",
        "IPY_MODEL_881d18413b83423ca5f33f5eea3dbe70",
        "IPY_MODEL_0f59c32970bd4d40a7f360c69f886b00"
       ],
       "layout": "IPY_MODEL_7f8e2f749a0a441ca9df93d5fe3aa1e8",
       "tabbable": null,
       "tooltip": null
      }
     },
     "563ec83737fd46b0bf0cd84252c00411": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8b356d0fd67d4c30b2e4959ac15b20b0",
       "placeholder": "​",
       "style": "IPY_MODEL_89da84f3afba4be29f8815afbee41729",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     },
     "585890a1db734185859ffa5aa4866403": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5a780eafe06a426682c21d7560cf259a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5adfa04589e44155873eb9c08baaa84a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5dcb410e5f794f968fe41c17a79e7aaf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5f95c879d5e5488db84d70f0ae6ced98": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_810285e941da4bbeb61b6020aa9f1621",
       "max": 328544361.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1c743802250f4256901a5f6c3a87e832",
       "tabbable": null,
       "tooltip": null,
       "value": 328544361.0
      }
     },
     "624d52156f83422ea02517789f704a2b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1b2fb68f4d1e4c2aa15545fda4243445",
       "placeholder": "​",
       "style": "IPY_MODEL_8fd6239ae965459db5e19fe28cd04b60",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt: 100%"
      }
     },
     "64c053d7602e4f27a492bb27dbfc84ea": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "668bb03a87114b90a67e5b4b37af6100": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_afec653639f04b9c99db63f7405dba29",
       "max": 328511860.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_39e29d0c5bf04984ae1e1fe128b65b3c",
       "tabbable": null,
       "tooltip": null,
       "value": 328511860.0
      }
     },
     "671896cafdb740f985f81c47633d22ea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_235bc8521ef7458a9ae965f82a14deeb",
       "placeholder": "​",
       "style": "IPY_MODEL_7c001e82505b401180f873cde44b412f",
       "tabbable": null,
       "tooltip": null,
       "value": "pytorch_model.bin: 100%"
      }
     },
     "6cc9a04ca0e34827b1b50d0e51f5dc59": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6ccbfa0328b547078273b5d07085ae0a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6cf71897fe814e59a7052bec27cf963b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6d9e009008194c06886e33b1e5c404cf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "6fe7540bd0164615a04cb1b201714938": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_82c0c7e3dc0e4e10a0d70bca7a7a29a5",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_be226f32328741da87890c987fc2e28f",
       "tabbable": null,
       "tooltip": null,
       "value": 1.0
      }
     },
     "70409044de3f47b7b6368f707f2dbc23": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7286c81c34bd419f98f0613cb890fffd",
       "placeholder": "​",
       "style": "IPY_MODEL_8c281bea6459498fac6415a29e72fe1d",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer.json: 100%"
      }
     },
     "70c18dfe774941a39561d44e2468e3ac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_825ba4a5fefc475f9f239f5cb2c0e228",
        "IPY_MODEL_b92ea5dc55c14c81907fe92644cd2e09",
        "IPY_MODEL_5203f84b6e154cdc8550ad0aaf00adb3"
       ],
       "layout": "IPY_MODEL_3a59f123a665456a98b3176f614cc73b",
       "tabbable": null,
       "tooltip": null
      }
     },
     "7221e77152d046ed97218098e5a833d6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7286c81c34bd419f98f0613cb890fffd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "78097b8cd44346efa1d916a4ad223ff0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1f532f3e2a954257a53029956db9361f",
       "placeholder": "​",
       "style": "IPY_MODEL_f650e389dd724dabaebbbc627d8e0374",
       "tabbable": null,
       "tooltip": null,
       "value": " 1.36M/? [00:00&lt;00:00, 75.1MB/s]"
      }
     },
     "7a1188350b294866b9c32b726995101b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7a4e34c08b5e44c99eda5cb3f70dd4bd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7be91d5d94c34dbfb130d01d2f55fac9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_dc570b35cf964711b3ef995c0bff0fa0",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_8531b560c07c4f9fbb56781ac8b673c4",
       "tabbable": null,
       "tooltip": null,
       "value": 1.0
      }
     },
     "7c001e82505b401180f873cde44b412f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7c514f351ade4c2c948f15b95f131334": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7f8e2f749a0a441ca9df93d5fe3aa1e8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "810285e941da4bbeb61b6020aa9f1621": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "81e7ff07471e4ce1971de10d255b880e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e63dbc4da9aa4cb08542565911a6df5a",
       "placeholder": "​",
       "style": "IPY_MODEL_c90c5d0e787e4f53ad5bf6ac22161d5d",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer.json: "
      }
     },
     "825ba4a5fefc475f9f239f5cb2c0e228": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ded0ff28d3d3416f9ce2b2cf50334ab8",
       "placeholder": "​",
       "style": "IPY_MODEL_20d647e53438441f91ca8dadf4baa25c",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json: 100%"
      }
     },
     "82c0c7e3dc0e4e10a0d70bca7a7a29a5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "84dc27b736d84399ade56c6e014e3e61": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8531b560c07c4f9fbb56781ac8b673c4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "87a7695451944f5182fae9660c443836": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4fe9c87fe3174dad88c6ca098d5f4b6a",
       "placeholder": "​",
       "style": "IPY_MODEL_6cc9a04ca0e34827b1b50d0e51f5dc59",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json: 100%"
      }
     },
     "881d18413b83423ca5f33f5eea3dbe70": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b43b63cccf04476086ff2ea60dbb8965",
       "max": 231508.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b2499af6254c45458d2e5ab3adb8485f",
       "tabbable": null,
       "tooltip": null,
       "value": 231508.0
      }
     },
     "89da84f3afba4be29f8815afbee41729": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8b356d0fd67d4c30b2e4959ac15b20b0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8c281bea6459498fac6415a29e72fe1d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8c3ea397ce894b2aa221fb8bb3ec4620": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_bc8ec1e34f80461c901cfd83d9b7914a",
        "IPY_MODEL_6fe7540bd0164615a04cb1b201714938",
        "IPY_MODEL_9a06c9b147e744dba869c084fc223a01"
       ],
       "layout": "IPY_MODEL_e3bfc750dee940688d67be3541c0065e",
       "tabbable": null,
       "tooltip": null
      }
     },
     "8d5b7da69e6e48c0b9a19d7aee823a92": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4767e33231f144c3807d78992d98c9c8",
       "placeholder": "​",
       "style": "IPY_MODEL_bbab420645df4643a6edbaa40f770cc7",
       "tabbable": null,
       "tooltip": null,
       "value": " 570/570 [00:00&lt;00:00, 85.2kB/s]"
      }
     },
     "8fd6239ae965459db5e19fe28cd04b60": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9076de6ffa8143849100781a0555d489": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5adfa04589e44155873eb9c08baaa84a",
       "placeholder": "​",
       "style": "IPY_MODEL_a4c7ccc7ba324e30bd8772c27b45ca3f",
       "tabbable": null,
       "tooltip": null,
       "value": " 1.00k/? [00:00&lt;00:00, 118kB/s]"
      }
     },
     "9187781871fc4ae99294454e4d8c05a5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "95c567593b3a4f409f9e998b3c355f02": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "974177ff08c94f80a08d7558d217a9ca": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "98642b3d1190436d921f4d47b75b9a7b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "98d39bca1a8b471fa559641f8342af7a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9a06c9b147e744dba869c084fc223a01": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_dbfce79e9cc84789ba78c2ccb11599c7",
       "placeholder": "​",
       "style": "IPY_MODEL_225957a4b7284621a34b9de12668c99c",
       "tabbable": null,
       "tooltip": null,
       "value": " 456k/? [00:00&lt;00:00, 34.8MB/s]"
      }
     },
     "9bce57ef12b945e29d495a2b040cef96": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a45081ee6cca4539bec152db8906d287": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a4762f0f5f054434bb1a19a2a394bff2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1a595a10bc2e43998a6bd3544d3ff3e3",
       "placeholder": "​",
       "style": "IPY_MODEL_585890a1db734185859ffa5aa4866403",
       "tabbable": null,
       "tooltip": null,
       "value": " 294/294 [00:00&lt;00:00, 23.5kB/s]"
      }
     },
     "a4c7ccc7ba324e30bd8772c27b45ca3f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a625880b67224e2b82ed0bc8d7bcc432": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a77b8b2f11024a949de0186c3b7c9c85": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_563ec83737fd46b0bf0cd84252c00411",
        "IPY_MODEL_668bb03a87114b90a67e5b4b37af6100",
        "IPY_MODEL_ad0d8fbc4c234b688698f72e07d0138e"
       ],
       "layout": "IPY_MODEL_aaeeece208a34de4b037c01a6b927895",
       "tabbable": null,
       "tooltip": null
      }
     },
     "a83e023b334e4745beac98d773b279e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "aa72e24dfb334d3f92af80ae966c982b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "aadecd385e6a41a1a16685be73db873f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_87a7695451944f5182fae9660c443836",
        "IPY_MODEL_3c4b3ea67fff4a788024965860d6752f",
        "IPY_MODEL_01326d3e64274690a4854294fc592df9"
       ],
       "layout": "IPY_MODEL_2e8b54f1483f42dc98c8044d0ecfdb47",
       "tabbable": null,
       "tooltip": null
      }
     },
     "aaeeece208a34de4b037c01a6b927895": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ad0d8fbc4c234b688698f72e07d0138e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_07ef233491254569bec2963b526cca3b",
       "placeholder": "​",
       "style": "IPY_MODEL_7c514f351ade4c2c948f15b95f131334",
       "tabbable": null,
       "tooltip": null,
       "value": " 329M/329M [00:02&lt;00:00, 175MB/s]"
      }
     },
     "afec653639f04b9c99db63f7405dba29": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b2499af6254c45458d2e5ab3adb8485f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b290b085fade42e1957e0acb4f637651": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b43b63cccf04476086ff2ea60dbb8965": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b5a89858987a4ba9a1b6bb6fd0e57cad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b917d78bf19b44c8ac3a431283e162fd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b92ea5dc55c14c81907fe92644cd2e09": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_19cdfd7828844d908bc3f18a01231785",
       "max": 48.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1390ac6a9aaa45ed8ba22fa62d3368ff",
       "tabbable": null,
       "tooltip": null,
       "value": 48.0
      }
     },
     "b9f6747f65294706a30bdc2f3f139559": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "bbab420645df4643a6edbaa40f770cc7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "bc8ec1e34f80461c901cfd83d9b7914a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a625880b67224e2b82ed0bc8d7bcc432",
       "placeholder": "​",
       "style": "IPY_MODEL_0dda7828ab804cc9b44c49418ae14ea5",
       "tabbable": null,
       "tooltip": null,
       "value": "merges.txt: "
      }
     },
     "be226f32328741da87890c987fc2e28f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c5df86bc16324a93b0f33154a6d76360": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c823b3cf81d24562a25240b9d40a6a3c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_35541364da9545a3b574129883362135",
        "IPY_MODEL_d34347aaf419452a9ae5f15318c3cf1d",
        "IPY_MODEL_f1993f679fe04fecb13ca4f99621f47d"
       ],
       "layout": "IPY_MODEL_f14cac8b53f2487581ca9f4c338be7be",
       "tabbable": null,
       "tooltip": null
      }
     },
     "c8bf8c3545e24d138fc6994753f0133d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f6bfff420d67488dbcb801fea524ea83",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6d9e009008194c06886e33b1e5c404cf",
       "tabbable": null,
       "tooltip": null,
       "value": 1.0
      }
     },
     "c90c5d0e787e4f53ad5bf6ac22161d5d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d06de23efb36490e8f4ecb83b65c5511": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d0a7eaa0728f4db8a7415f0227bd8665": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a45081ee6cca4539bec152db8906d287",
       "placeholder": "​",
       "style": "IPY_MODEL_1b5d34cc2b9f47f8a0cbfee077fa0933",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "d34347aaf419452a9ae5f15318c3cf1d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_98d39bca1a8b471fa559641f8342af7a",
       "max": 440449768.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c5df86bc16324a93b0f33154a6d76360",
       "tabbable": null,
       "tooltip": null,
       "value": 440449768.0
      }
     },
     "dbb194f0a8ce4856af6e49ac5d801791": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "dbfce79e9cc84789ba78c2ccb11599c7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dc570b35cf964711b3ef995c0bff0fa0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "ded0ff28d3d3416f9ce2b2cf50334ab8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "df9beb30f40f465881021b4da725f214": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b290b085fade42e1957e0acb4f637651",
       "placeholder": "​",
       "style": "IPY_MODEL_d06de23efb36490e8f4ecb83b65c5511",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.json: "
      }
     },
     "e3bfc750dee940688d67be3541c0065e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e63dbc4da9aa4cb08542565911a6df5a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "eb419f89f08a45fa9dad9ffae9b37dde": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7221e77152d046ed97218098e5a833d6",
       "placeholder": "​",
       "style": "IPY_MODEL_179aebee913f4999917a4ee4966e56ab",
       "tabbable": null,
       "tooltip": null,
       "value": " 329M/329M [00:02&lt;00:00, 162MB/s]"
      }
     },
     "ebf9cabbe62745638e872f9d0f1f7326": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_13a02549d7a84b279d3d539293e1a1fc",
       "placeholder": "​",
       "style": "IPY_MODEL_5dcb410e5f794f968fe41c17a79e7aaf",
       "tabbable": null,
       "tooltip": null,
       "value": " 798k/? [00:00&lt;00:00, 37.2MB/s]"
      }
     },
     "ed9771ae99cd4c048264eb4b74ba86fe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_11d43039380b4c4d8e9a410ad0a8afda",
       "placeholder": "​",
       "style": "IPY_MODEL_9187781871fc4ae99294454e4d8c05a5",
       "tabbable": null,
       "tooltip": null,
       "value": " 466k/466k [00:00&lt;00:00, 8.80MB/s]"
      }
     },
     "f14cac8b53f2487581ca9f4c338be7be": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f1993f679fe04fecb13ca4f99621f47d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_84dc27b736d84399ade56c6e014e3e61",
       "placeholder": "​",
       "style": "IPY_MODEL_37fb7fe2b1e7430bb68871b9adb7b4a4",
       "tabbable": null,
       "tooltip": null,
       "value": " 440M/440M [00:01&lt;00:00, 345MB/s]"
      }
     },
     "f650e389dd724dabaebbbc627d8e0374": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f6bfff420d67488dbcb801fea524ea83": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "f779daa513114e6ba899f8c4043e41c2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_42d5427e4c66459488f705d0f5aaabf3",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b5a89858987a4ba9a1b6bb6fd0e57cad",
       "tabbable": null,
       "tooltip": null,
       "value": 1.0
      }
     },
     "f87d4a4d7f1f4e0ab2baeef091c19892": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fd174d0a3aeb47489532d0b8ca6df7b3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_81e7ff07471e4ce1971de10d255b880e",
        "IPY_MODEL_7be91d5d94c34dbfb130d01d2f55fac9",
        "IPY_MODEL_78097b8cd44346efa1d916a4ad223ff0"
       ],
       "layout": "IPY_MODEL_9bce57ef12b945e29d495a2b040cef96",
       "tabbable": null,
       "tooltip": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
